%!TEX root = main.tex

\section{The Delsarte Bound}

\subsection{$*$-algebras of matrices}

	Denote by $\mathcal{M}_n(\C)$ the $\C$-vector space of all $n \times n$ complex matrices.

	\begin{fdef}
		A subspace $\mathcal{A} \subseteq \mathcal{M}_n(\C)$ is said to be a \emph{$*$-algebra of matrices} if
		\begin{enumerate}
			\item $\mathcal{A}$ is closed under multiplication, in that if $A,B \in \mathcal{A}$, then $AB \in \mathcal{A}$, and
			\item $\mathcal{A}$ is closed under conjugate transposes, in that if $A = (a_{ij}) \in \mathcal{A}$, then $A^\dagger = (\overline{a_{ji}}) \in \mathcal{A}$.
			\item $\Id \in \mathcal{A}$.
		\end{enumerate}
	\end{fdef}

	That is, it is a subalgebra that is closed under conjugate transposes.


	Let $q$ be a prime power. Denote by $B_q(n)$ the set of all subspaces of $\F_q^n$ and $B_q(n,k)$ the set of all $k$-dimensional subspaces of $\F_q^n$. It is not too difficult to show that
	\[ |B_q(n,k)| = \binom{n}{k}_q = \frac{(q^n-1)(q^n-q)(q^n-q^2)\cdots(q^n-q^{n-k+1})}{(q^k-1)(q^k-q)(q^k-q^2)\cdots(q^k-q^{k-1})}. \]
	We had also considered this quantity $\binom{n}{k}_q$ in Section 1.4 of \href{https://amitrajaraman.github.io/notes/ma-861/main.pdf}{Combinatorics I}. Recall the $q$-Pascal recurrence
	\begin{equation}
		\label{eqn: q-pascal}
		\binom{n+1}{k}_q = \binom{n}{k-1}_q + q^k \binom{n}{k}_q
	\end{equation}
	for $n\ge 0, k \ge 1$ with $\binom{n}{0}_q = 1$ and $\binom{0}{k} = \delta_{0,k}$. Is there a way to see this recurrence more directly using the subspace perspective of the $q$-binomial coefficient? If we have a (size $k$) basis of a $k$-dimensional subspace of $\F_q^n$, and consider the $k \times n$ matrix with rows equal to the vectors in this basis, we may bring this matrix to a \emph{unique} row-reduced echelon form (independent of the basis used) using row operations wherein
	\begin{enumerate}[label=(\roman*)]
		\item all rows are nonzero,
		\item the first non-zero entry in every row is a $1$. Suppose this entry occurs in column $C_i$ in row $i$,
		\item $C_1 < C_2 < \cdots C_k$, and
		\item the submatrix comprising the $\{C_1,\ldots,C_k\}$ rows is a $k \times k$ identity matrix.
	\end{enumerate}
	So, we can count $k \times n$ matrices in RREF instead of subspaces. \Cref{eqn: q-pascal} then follows immediately by considering whether the last column is pivotal or not.

	\begin{fdef}
		Let $A$ be Hermitian. Then, $\langle A\rangle$, the $*$-algebra generated by $A$, is $\Span\{\Id,A,A^2,\ldots\}$.
	\end{fdef}

	Note that this algebra is abelian. Furthermore, by the spectral theorem, $\dim(\langle A\rangle)$ is the number of distinct eigenvalues of $A$.\\ % *** EXPLAIN ***

	For $A \in \mathcal{M}^n(\C)$ similar to a Hermitian matrix, that is, $PAP^{-1}$ is Hermitian for some $P$, $P\langle A\rangle P^{-1}$ is a $*$-algebra.
	
	\begin{fex}[$*$-algebras on graphs]
		\label{exmp: star-alg}
		Let $G = (V,E)$ be a graph and $A$ its adjacency matrix. $\langle A\rangle$ is called the \emph{adjacency algebra} of $G$. \\

		More specifically, consider the $n$-cube graph $C_n$ with vertex set $B(n)=2^{[n]}$ and an edge between $X,Y$ if $|X \triangle Y| = 1$. Although $\langle A\rangle$ is $*$-algebra of $2^n \times 2^n$ matrices, its dimension is only $n+1$. The fact that we only require $n+1$ parameters to describe an arbitrary element of $\langle A\rangle$ is key to the Delsarte bound on binary code size we shall study in this section.\\

		Let $k \le n/2$. The Johnson graph has vertex set $B(n,k) = \binom{[n]}{k}$ and an edge between $X,Y$ if $|X \cap Y| = k-1$. The dimension of this graph's adjacency algebra turns out to be $k+1$.\\

		The Grassmann graph $J_q(n,k)$ has vertex set $B_q(n,k)$ (see above the example for definition) with $X,Y \in B_q(n,k)$ adjacent iff $\dim(X \cap Y) = k-1$. It turns out that the dimension of this graph's adjacency algebra is $k+1$ as well. Interestingly, the proof for this ends up just being a ``$q$-analogue'' of the proof for the Johnson graph.\\

		The $q$-analogue of the $n$-cube $C_q(n)$ has vertex set $B_q(n)$ with $X,Y$ adjacent iff $|\dim X - \dim Y| = 1$. We do not know the dimension of this graph's adjacency algebra! The adjacency matrix seems difficult to study (and is perhaps not even the right object to study). We shall instead study a weighted adjacency matrix of $C_q(n)$.
	\end{fex}

	All the above examples are commutative. \href{https://amitrajaraman.github.io/notes/rep-th/main.pdf}{Recall} that a \emph{unitary representation} of a group $G$ is a group homomorphism $\varphi : G \to \mathcal{U}_n(\C)$.

	\begin{ftheo}
		Let $f$ be a unitary representation as above. Then,
		\[ \mathcal{A} = \{A \in \mathcal{M}_n(\C) : A \varphi(g) = \varphi(g) A \text{ for all } g \in G \} \]
		is a $*$-algebra called the \emph{commutant} of $\varphi$.
	\end{ftheo}
	\begin{proof}
		It is obvious that $\mathcal{A}$ is a subspace that is closed under multiplication. We have for $A \in \mathcal{A}, g \in G$ that
		\[ \varphi(g^{-1}) = \varphi(g)^{-1} = \varphi(g)^\dagger, \]
		so
		\[ A^\dagger \varphi(g) = (\varphi(g)^\dagger A)^\dagger = (\varphi(g^{-1}) A)^\dagger = (A \varphi(g)^{-1})^\dagger = \varphi(g) A^\dagger, \]
		which easily yields the desideratum.
	\end{proof}

	The above $*$-algebra may be possible be non-commutative. Suppose that $G$ acts on a set $S$. For each $g$, we can denote the group action by an $S \times S$ permutation matrix $\rho(g)$, with $(\rho(g))_{gs,s} = 1$. This gives a \emph{representation} $\rho : G \to \mathcal{U}_{S}(\C)$ -- any group action thus yields a $*$-algebra.\\
	We would like to analyze the set of matrices which commute with all $\rho(g)$. Let $G$ act on the sets $S,T$, and let $\rho : G \to \mathcal{U}_S(\C), \tau : G \to \mathcal{U}_T(\C)$ be the corresponding maps. Consider
	\[ \mathcal{A} = \left\{ M \in \mathcal{M}_{T \times S}(\C) : M \rho(g) = \tau(g) M \text{ for all $g \in G$} \right\}. \]
	Finally, we shall set $S = T$ so that it is a $*$-algebra, which we denote $\Hom_G(S,S)$.

	\begin{flem}
		Let $M \in \mathcal{M}_{T \times S}(\C)$. Defining $\mathcal{A}$ as above, $M \in \mathcal{A}$ iff $M_{t,s} = M_{gt,gs}$ for all $g \in G, t \in T,s \in S$.
	\end{flem}
	\begin{proof}
		The $t,s$th entry of $M\rho(g)$ is equal to $M_{t,gs}$, and that of $\tau(g)M$ is $M_{g^{-1}t,s}$. The required follows.
	\end{proof}

	Now, the two actions induce an action on $T \times S$. $M$ belongs to $\mathcal{A}$ iff it is constant on the orbits of this action. Consequently, the dimension of $\mathcal{A}$ is the number of orbits of the action of $G$ on $T \times S$, with a basis being the set of matrices $M_j$ which are equal to $1$ on precisely those cells in the same orbit $\theta_j$ and $0$ elsewhere.\\
	This basis of $\mathcal{A}$ is called its \emph{orbital basis}.

	\begin{flem}[Gelfand's Lemma]
		\label{lem: gelfands lemma}
		Let $T = S$ in the above discussion. If each $M_j$ is symmetric, $\mathcal{A}$ is commutative.
	\end{flem}
	\begin{proof}
		Since each $M_j$ is symmetric and orthogonal, all matrices in $\mathcal{A}$ are symmetric. We are done if we show that a $*$-algebra of symmetric matrices is commutative. Indeed, $MN = (MN)^\top = N^\top M^\top = NM$.
	\end{proof}

	Note that the converse does \emph{not} hold; we shall see a counterexample later. Let us get back to our earlier discussion in \Cref{exmp: star-alg}. Think of $B(n)$ as $\{0,1\}^n$. Consider the \emph{hyperoctahedral group} $H(n)$, which has base set equal to $S_2^n \times S_n$, with elements denoted $(\sigma_1,\sigma_2,\ldots,\sigma_n,\pi)$. This group acts on $B(n)$ by first permuting the $n$ coordinates according to $\pi$, then deciding whether or not to flip the entries based on the $(\sigma_i)$. Note that adjacency is preserved under the group action. In fact, $H(n)$ is the set of all permutations that preserve adjacency.\\
	The group action can be thought of as first taking the vertex to any other arbitrary vertex, then permuting the $n$ outgoing edges in some manner -- these two together further determine the group element.\\

	Let $\alpha,\beta,\alpha',\beta' \in B(n)$. We denote by $d(\alpha,\beta)$ the set of coordinates where $\alpha,\beta$ differ. We write $(\alpha,\beta) \sim (\alpha',\beta')$ if the two are in the same $H(n)$-orbit.

	\begin{flem}
		$(\alpha,\beta)$ and $(\alpha',\beta')$ are in the same $H(n)$-orbit iff $d(\alpha,\beta) = d(\alpha',\beta')$.
	\end{flem}
	\begin{proof}
		The forward direction is straightforward -- permuting the coordinates leaves the distance the same and flipping a select set of coordinates of both also leaves the distance unchanged.\\
		For the backward direction, suppose $d(\alpha,\beta) = d(\alpha',\beta') = k$. Consider the permutation applied to $\alpha$ which has all $0$s at the start then all $1$s. Then, flip all the $1$s in $\alpha$. Consider the element $\beta''$ obtained by performing the same operations on $\beta$. Due to the first part, $\beta''$ has exactly $k$ $1$s. Next, permute the coordinates of $\beta''$ to get $\beta'''$, which has all $0$s at the start then all $1$s. $(0,\beta''')$ is in the same orbit as $(\alpha,\beta)$. By performing similar operations, it is also in the same orbit as $(\alpha',\beta')$, completing the proof. 
	\end{proof}

	Let $A_0,A_1,\ldots,A_n$ be the $n$ orbital bases of $B(n) \times B(n)$ under the group action $H(n)$, defined by
	\[ A_j(\alpha,\beta) = \begin{cases} 1, & d(\alpha,\beta) = j, \\ 0, & \text{otherwise.} \end{cases} \]
	Going back to the perspective of $B(n)$ containing subsets of $[n]$,
	\[ A_j(X,Y) = \begin{cases} 1, & |X\triangle Y| = j, \\ 0, & \text{otherwise.} \end{cases} \]
	Note that $A_1$ is the adjacency matrix $A$ of the $n$-cube graph $C(n)$!
	% CAL A HAS SOME SPECIAL NAME HERE, CHECK NOTES
	\begin{fprop}
		\label{prop: ncube-adj-eigenvals}
		It holds that $\langle A\rangle = \Span\{A_0,A_1,\ldots,A_n\}$.
	\end{fprop}
	\begin{proof}
		Denote by $\mathcal{A}$ the algebra on the right, which is the commutant of the $H(n)$ action on $B(n)$. Because $A_1 = A$ is in $\mathcal{A}$, $\langle A\rangle \subseteq \mathcal{A}$. It remains to show the reverse containment, which is implied if we show that $A_j \in \langle A\rangle$ for each $j$. If $A_j \in \langle A\rangle$, then $AA_j$ is just some linear combination of $A_0,A_1,\ldots,A_{j+1}$ (with a positive coefficient on $A_{j+1}$), completing the proof.
	\end{proof}

	\begin{fcor}
		The adjacency matrix $A$ of the $n$-cube graph has $n+1$ distinct eigenvalues.
	\end{fcor}

	A natural next question is: what are these $n+1$ eigenvalues, and what are each of their eigenspaces and multiplicities?\\
	As a little spoiler, we answer these questions: the eigenvectors are $n-2k$ for $k=0,1,\ldots,n$, with $n-2k$ having multiplicity $\binom{n}{k}$. We shall prove this later in *** SEC ? ***. \\

	Let us next go back to the example of $B(n,k)$. $S_n$ acts on $B(n,k)$ with $\pi \cdot \{i_1,\ldots,i_k\} = \{\pi(i_1),\ldots,\pi(i_k)\}$. What are the orbits of this $S_n$-action on $B(n,k) \times B(n,k)$?

	\begin{flem}
		Let $(X,Y), (X',Y') \in B(n,k) \times B(n,k)$. Then, $(X,Y) \sim (X',Y')$ iff $|X \cap Y| = |X' \cap Y'|$.
	\end{flem}
	The proof of the above is straightforward, and we omit it. Note in particular that $(X,Y) \sim (Y,X)$, so each orbital matrix is symmetric. Therefore,
	\[ \mathcal{A} = \Hom_{S_n}(B(n,k),B(n,k)) \]
	is commutative. We have for any sets $X,Y$ of size $k$ that
	\[ \max\{0,2k-n\} \le |X \cap Y| \le k. \]
	Therefore, $\dim \mathcal{A} = 1 + \min\{k,n-k\}$. Let $\{A_k,A_{k-1},\ldots,A_{\max\{0,2k-n\}}\}$ be the orbital basis of $\mathcal{A}$ with $A_j(X,Y) = 1$ if $|X \cap Y| = j$ and $0$ otherwise. Then,$A_k = \Id$ and $A_{k-1} = A$ is the adjacency matrix of the Johnson graph $J(n,k)$!

	\begin{fprop}
		\label{prop: johnson-adj-eigenvals}
		It holds that $\langle A\rangle = \Span\{A_k,A_{k-1},\ldots,A_{\max\{0,2k-n\}}\}$.
	\end{fprop}
	The proof is very similar to that of \Cref{prop: ncube-adj-eigenvals}.

	\begin{fcor}
		The adjacency matrix $A$ of the Johnson graph $J(n,k)$ has $1+\min\{k,n-k\}$ distinct eigenvalues.
	\end{fcor}
	In the case where $k \le n-k$, the multiplicities of the eigenvalues of the graph are $\binom{n}{0}, \binom{n}{1} - \binom{n}{0}, \binom{n}{2} - \binom{n}{1}, \ldots, \binom{n}{k}-\binom{n}{k-1}$. We shall prove this and find the corresponding eigenspaces later in *** SEC ? ***.\\

	When we deal with $B_q(n,k)$, the collection of $k$-dimensional subspaces of $\F_q^n$, we shall take the action of $\GL_n(\F_q)$ defined by
	\[ MX = M(X) = \{Mv : v \in X\} \]
	Once more, we get results as in the Johnson graph.

	\begin{flem}
		Let $(X,Y), (X',Y') \in B_q(n,k) \times B_q(n,k)$. Then, $(X,Y) \sim (X',Y')$ iff $\dim(X \cap Y) = \dim(X' \cap Y')$.
	\end{flem}
	So, the Grassmann graph with adjacency matrix $A$ and corresponding adjacency algebra $\mathcal{A}$ has $\dim \mathcal{A} = 1+\max\{k,n-k\}$ as well. Letting $\{A_k,A_{k-1},\ldots,A_{\max\{0,2k-n\}}\}$ be the orbital basis of $\mathcal{A}$ with $A_j(X,Y) = 1$ if $\dim(X \cap Y) = j$ and $0$ otherwise, we again get that $\langle A\rangle = \Span\{A_k,\ldots,A_{\max\{0,2k-n\}}\}$.

	\begin{fprop}
		\label{prop: johnson-adj-eigenvals}
		It holds that $\langle A\rangle = \Span\{A_k,A_{k-1},\ldots,A_{\max\{0,2k-n\}}\}$.
	\end{fprop}

	\begin{fcor}
	 	The adjacency matrix $A$ of the Grassmann graph $J_q(n,k)$ has $1+\min\{k,n-k\}$ distinct eigenvalues. 
	 \end{fcor}
	 
	 The multiplicity of the eigenvalues (when $k \le n/2$) end up being $\binom{n}{0}_q, \binom{n}{1}_q-\binom{n}{0}_q, \binom{n}{2}_q-\binom{n}{1}_q, \ldots, \binom{n}{k}_q-\binom{n}{k-1}_q$.\\

	 So far, all examples have been commutative.

	 \begin{fex}[Non-commutative $*$-algebras]
	 	Consider the action of $S_n$ on $B(n)$, with $\pi \{i_1,\ldots,i_k\} = \{\pi(i_1),\ldots,\pi(i_k)\}$. Similar to what we have already seen, $(X,Y) \sim (X',Y')$ iff $|X| = |X'|$, $|Y| = |Y'|$, and $|X \cap Y| = |X' \cap Y'|$. Consider the $B(n) \times B(n)$ matrix $M_{i,j,t}$ defined by
	 	\[
	 	M_{i,j,t}(X,Y) =
	 	\begin{cases}
	 		1, & |X|=i, |Y|=j, |X \cap Y| = t, \\ 0, & \text{otherwise,}
	 	\end{cases}
	 	\]
	 	for any choice of $i-t\ge 0$, $j-t\ge 0$, and $i+j-t \le n$. The number of ways of choosing such $i,j,t$ is $\binom{n+3}{3}$ -- we would like to find the number of solutions to $(i-t) + (j-t) + t + r = n$, where $i-t,j-t,t,r \ge 0$.\\
	 	Therefore, setting $\mathcal{A} = \Hom_{S_n}(B(n),B(n))$, we have $\dim \mathcal{A} = \binom{n+3}{3}$. Further note that $\mathcal{A}$ is non-commutative. Indeed, $M_{2,3,1} M_{3,4,2} \ne 0$ but $M_{3,4,2} M_{2,3,1} = 0$.\\

	 	The $q$-analogue of the above example is as follows. Let $\GL_n(\F_q)$ act on $B_q(n)$, and define $M_{i,j,t}(q)$ by
	 	\[ M_{i,j,t}(q)(X,Y) = \begin{cases} 1, & \dim X = i, \dim Y = j, \dim (X \cap Y) = t, \\ 0, & \text{otherwise.} \end{cases} \]
	 	Again, we have $\dim \mathcal{A} = \binom{n+3}{3}$.
	 \end{fex}

	So far, this idea of translating proofs to proofs in the setting of $q$-analogues seems pretty straightforward. However, things don't work out as well when we try to go from $C(n)$ to $C_q(n)$. The issue is that $H(n)$ does not have a neat $q$-analogue. Later, we shall look at a $q$-analogue of $\Hom_{H(n)}(B(n),B(n))$ that does not come from a graph action.

	\begin{fex}
		Let $G$ be a finite group. $G \times G$ acts on $G$ by $(g,h) \cdot a = gah^{-1}$. What is the orbital basis of the commutant of this action?\\
		Let $(a,b),(c,d) \in G \times G$. Then, $(a,b) \sim (c,d)$ iff $ab^{-1}$ and $cd^{-1}$ are conjugates in $G$.\\
		The former is true iff for some $g,h \in G$, $gah^{-1} = c$ and $gbh^{-1} = d$. Equivalently, $ga = ch$ and $b^{-1}g^{-1} = h^{-1}d^{-1}$. Multiplying the two, this implies that $gab^{-1}g^{-1} = cd^{-1}$, that is, $ab^{-1}$ and $cd^{-1}$ are conjugates. For the backward direction, if we have $gab^{-1}g^{-1} = cd^{-1}$. Setting $h = gac^{-1}$, the previous equation implies that $h = d^{-1}gb$. This directly implies that $gah^{-1} = c$ and $gbh^{-1} = d$.\\
		Let the conjugacy classes of $G$ be $C_1,\ldots,C_t$. Consider the $G \times G$ matrices $A_j$ by
		\[ A_j(g,h) = \begin{cases} 1, & gh^{-1} \in C_j, \\ 0, & \text{otherwise.} \end{cases} \]
		In the case where each element of the group is conjugate to its inverse, we can use \nameref{lem: gelfands lemma} to conclude that each $A_j$ is symmetric so $\mathcal{A}$ is abelian. An example of such a group is the symmetric group $S_n$, and the dimension of the resulting $\mathcal{A}$ is $p(n)$, the number of number partitions of $n$. However, it turns out that $\mathcal{A}$ is commutative for \emph{any} $G$! This shows that Gelfand's lemma is sufficient but not necessary. *** EXERCISE ***
	\end{fex}

	\begin{fex}
		Consider $K_{2n}$, the complete graph on $2n$ vertices. It is not too difficult to show that the number of perfect matchings of $K_{2n}$ is $\frac{(2n)!}{n!2^n} = (2n)!!$. Denote the set of all perfect matchings on $K_{2n}$ by $\PM_{2n}$. $S_{2n}$ acts on $\PM_{2n}$ in an obvious manner, by mapping the matching $\{i_1j_1,i_2j_2,\ldots,i_nj_n\}$ to $\{\pi(i_1)\pi(i_2),\ldots,\pi(i_n)\pi(j_n)\}$. What are the $K_{2n}$ orbits on $\PM_{2n} \times \PM_{2n}$?\\
		Let $M_1,M_2 \in \PM_{2n}$. It is not too difficult to see that $M_1 \cup M_2$ comprises of ``alternating cycles'', namely even cycles whose edges alternate between being in $M_1,M_2$ (such a cycle may also be a $2$-cycle with two edgees between two vertices, one of which is in $M_1$ and the other in $M_2$).  This induces a number partition of $n$, based on the number of cycles of size $2k$ for $1 \le k \le n$. Call this partition $d(M_1,M_2)$.\\
		
		We claim that $(M_1,M_2) \sim (M_3,M_4)$ iff $d(M_1,M_2) = d(M_3,M_4)$.\\
		The forward direction is direct since if we have $\pi (M_1,M_2) = (M_3,M_4)$, then $\pi$ applied to the vertices of the multigraph $M_1 \cup M_2$ gives $M_3 \cup M_4$ while having the same graph (up to isomorphism), so the partition remains the same. For the backward direction, just match up $M_1 \cup M_2$ and $M_3 \cup M_4$ in a way that cycle sizes agree.\\

		Therefore, the dimension of this $*$-algebra is $p(n)$, the number of partitions of $n$. Recall that this is the same as the number of partitions as the previous example when $G = S_n$. Further, since $d(M_1,M_2) = d(M_2,M_1)$, this algebra is abelian by \nameref{lem: gelfands lemma}.
	\end{fex}

	Much like the spectral theorem of normal matrices, there is a spectral theorem of $*$-algebras which ``diagonalizes'' them.

	\begin{ftheo}[Spectral theorem for commutative $*$-algebras]
		Let $\mathcal{A} \subseteq \mathcal{M}_n(\C)$ be a commutative $*$-algebra. Then, there exists an $n \times n$ unitary matrix $U$ and positive integers $q_1,\ldots,q_m$ (determined up to permutation) such that $U^\dagger \mathcal{A} U$ is the set of all \emph{$(q_0,\ldots,q_m)$-block diagonal matrices}, that is, the set of all matrices
		\[ \begin{pmatrix} C_1 & & & \\ & C_2 & & \\ & & \ddots & \\ & & & C_m \end{pmatrix}, \]
		where $C_k$ is a $q_k \times q_k$ scalar matrix. In particular, any element of $U^\dagger \mathcal{A} U$ is determined by the $m$ scalars corresponding to these blocks, so $\dim \mathcal{A} = m$ and $q_1 + \cdots + q_m = n$.
	\end{ftheo}
	\begin{proof}
		
	\end{proof}

	\begin{corollary}
		Let $\mathcal{A}$ be a commutative $*$-algebra. Then there exist subspaces $W_1,\ldots,W_m$ of $\C^n$ that are (common) eigenspaces of any $A \in \mathcal{A}$.
	\end{corollary}

	There is also a more general spectral theorem for (not necessarily commutative) $*$-algebras, that we state without proof.

	\begin{ftheo}[Spectral theorem for $*$-algebras]
		Let $\mathcal{A} \subseteq \mathcal{M}_n(\C)$ be a commutative $*$-algebra. Then, there exists an $n \times n$ unitary matrix $U$ and positive integers $p_1,\ldots,p_m$ and $q_1,\ldots,q_m$ (determined up to permutation) such that $U^\dagger \mathcal{A} U$ is the set of all \emph{$((p_0,q_0),\ldots,(p_m,q_m))$-block diagonal matrices}, that is, the set of all matrices
		\[ U^\dagger \mathcal{A} U = \begin{pmatrix} C_1 & & & \\ & C_2 & & \\ & & \ddots & \\ & & & C_m \end{pmatrix}, \]
		where $C_k$ is a block diagonal matrix
		\[ C_k = \begin{pmatrix} B_k & & & \\ & B_k & & \\ & & \ddots & \\ & & & B_k \end{pmatrix} \]
		consisting of $q_k$ repeated blocks of a $p_k \times p_k$ matrix $B_k$.	
		Furthermore, $\dim \mathcal{A} = p_1^2 + \cdots + p_m^2$ and $n = p_1q_1 + \cdots + p_mq_m$.
	\end{ftheo}

	In either spectral theorem, we say that we have a \emph{diagonalization} of $\mathcal{A}$ if we know the images $A \mapsto U^\dagger A U$ explicitly, and an \emph{explicit diagonalization} if we further know $U$.

\subsection{A primer on representation theory}

	\begin{fdef}
		A \emph{representation} of a group $G$ is a group homomorphism $\varphi : G \to \GL(V)$ for some finite-dimensional vector space $V$ over $\C$. Given such a representation, we say that $V$ is a \emph{$G$-module}.
	\end{fdef}
	The image of $g$ under $\varphi$ is denoted $\varphi_g$, but we usually abuse notation it like a group action. That is, we denote $(\varphi(g))(v)$ as $\varphi_g(v)$ or merely $g \cdot v$ or even $gv$ when the representation is clear from context.

	\begin{fex}
		Let $G$ be a group and $S$ a finite set such that $G$ acts on $S$. Consider the \emph{linearization} of $S$ or the \emph{permutation module} corresponding to $S$, which is the vector space with $S$ as a basis, that is,
		\[ \C[S] = \left\{ \sum_{s \in S} \alpha_s s : \alpha_s \in \C \right\}. \]
		The action of $G$ induces a representation on $\C[S]$, namely
		\[ g \cdot \left( \sum_s \alpha_s s \right) = \sum_s \alpha_s (g \cdot s). \] 
	\end{fex}

	\begin{fdef}
		Given a $G$-module $V$, a subspace $W \subseteq V$ is said to be a \emph{submodule} of $V$ if for all $w \in W$ and $g \in G$, $gw \in W$.
	\end{fdef}
	That is, it is invariant with respect to the representation.

	\begin{fdef}
		A $G$-module $V$ is said to be \emph{irreducible} if $\dim V > 0$ and it has no submodules other than $\{0\}$ and $V$.
	\end{fdef}
	More succinctly, an irreducible $G$-module is one with exactly two submodules. In particular, any one-dimensional module is irreducible

	\begin{fex}
		Consider the obvious action of $S_n$ on $X = [n]$. Considering the permutation module $\C[X]$, the subspaces
		\begin{align*}
			V_1 &= \Span\{1+2+\cdots+n\} \text{ and}
			V_2 &= \{c_11 + c_22 + \cdots + c_nn : c_1 + \cdots + c_n = 0\}.
		\end{align*}
		Clearly, $V_1$ is irreducible. It turns out that $V_2$ is irreducible as well! Suppose instead that $W \ne 0$ is a submodule of $V_2$, containing $w = c_11 + \cdots + c_nn$ for some $(c_i)$ adding up to $0$. Suppose that $c_1 \ne 0$. We must have that some other $c_i$ is also nonzero and unequal to $c_1$; suppose that $c_2$ is so. Then,
		\begin{align*}
			w &= c_1 1 + c_2 2 + \cdots + c_nn \in W \\
			(1\; 2) w &= c_2 1 + c_1 2 + \cdots + c_n n \in W
		\end{align*}
		since $W$ is a submodule. Subtracting the two, we get that $(1-2) \in W$. Applying $(2\; j)$ for $j \ge 3$, we get that $(1-j) \in W$ for any $j = 2,3,\ldots,n$. Therefore, $\dim W = n-1$ so $W$ must be $V_2$.
	\end{fex}

	Ideally, we would like some result in the spirit of the prime factorization theorem, saying that any module can be decomposed into a direct sum of irreducible submodules in a ``unique'' fashion. We shall spend the remainder of this section developing this theorem.

	\begin{fdef}
		Let $V$ be a finite-dimensional vector space with an inner product $\langle \cdot,\cdot\rangle$. A \emph{unitary} representation is a group homomorphism $\varphi : G \to U(V)$. In such a case, $V$ is called a \emph{unitary $G$-module}.
	\end{fdef}
	Above $U(V)$ is the subgroup of matrices in $\GL(V)$ under which the inner product is preserved. That is, $U(V)$ is the set of all matrices $A$ such that for any $v,w \in V$, $\langle v,w\rangle = \langle Av,Aw\rangle$.

	\begin{flem}
		Let $V$ be a unitary $G$-module. Then, $V$ is a direct sum of irreducible submodules.
	\end{flem}
	\begin{proof}
		If $V$ is irreducible, we are done. Suppose otherwise, and let $W \ne 0$ be a proper irreducible submodule of $V$. Consider $W^\perp = \{ v \in V : \langle v,w\rangle = 0 \}$.
	\end{proof}