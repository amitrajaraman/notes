\section{An \texorpdfstring{$\mathcal{O}^*(n^7)$}{} Algorithm for Volume Computation}

While the basic ideas of volume computation introduced here are similar to those described in the previous section, there are several important results that are worth discussing separately.

\subsection{Measure-Theoretic Markov Chains and Conductance}
\label{subsec: measure theoretic markov chains}

\subsubsection{Some Basic Definitions}

\begin{fdef}
Let $\Omega$ be a non-empty set and $\mathcal{A}$ a $\sigma$-algebra on $\Omega$. For every $u\in\Omega$, let $P_u$ be a probability measure on $\Omega$. Also assume that as a function of $u$, $P_u(A)$ is measurable for any $A\in\mathcal{A}$. We call the triple $(\Omega,\mathcal{A},\{P_u:u\in\Omega\})$ a \textit{Markov scheme}. Together, with an initial distribution $Q_0$ on $\Omega$, this defines a \textit{Markov chain}.
\end{fdef}

A Markov chain is just a sequence of random variables $w_0,w_1,\ldots$ such that $w_0$ is drawn from $Q_0$ and $w_{i+1}$ is drawn from $P_{w_i}$ (independently of the values of $w_0,\ldots,w_{i-1}$). Therefore,
\[ \Pr[w_{i+1}\in A \mid w_1=u_1,\ldots,w_i=u_i] = \Pr[w_{i+1}\in A\mid w_i=u_i] = P_{u_i}(A). \]
Let $f:\Omega\times\Omega\to\R$ be an integrable function (with respect to the product measure $\mu\times\mu$) such that $\int_\Omega f(u,v)\d{\mu}(v)=1$ for all $u\in\Omega$. $f$ then defines a Markov scheme as
\[ P_u(A) = \int_A f(u,v)\d{\mu}(v). \]
In this case, $f$ is known as the \textit{transition function} of the Markov scheme. The transition function is said to be \textit{symmetric} if $f(x,y)=f(y,x)$.\\

A probability measure $Q$ on $\Omega$ is said to be the \textit{stationary distribution} of the Markov scheme if for all $A\in\mathcal{A}$,
\[ \int_{\Omega}P_u(A)\d{Q}(u) = Q(A). \]
This just means that every $w_i$ has the same distribution as that of $Q$.\\

Now, consider the inner product space $L^2 = L^2 (\Omega,\mathcal{A},Q)$ with inner product
\[ \langle f,g\rangle = \int_\Omega f g\d{Q}. \]
Suppose we have some function $g\in L^2$. Then note that the expectation of $g(w_{i+1})$ (as a function of $w_i = u$) defines a positive linear operator\footnote{a linear operator $A$ such that $\langle Ax,x\rangle\geq 0$ for any $x$.} $M:L^2\to L^2$ by
\[ (Mg)(u) = \int_\Omega g(v)\d{P_u}(v). \]
Further note that $(M^k g)(u)$ represents the expectation of $g(w_{i+k})$ given that $w_i=u$.

Now, consider a Markov chain where the first element is drawn from the stationary distribution. Then observe that for any function $g\in L^2$,
\begin{align*}
    \expec[g(w_i)] &= \expec[g(w_0)] = \langle g,1\rangle \\
    \expec[g(w_i)^2] &= \expec[g(w_0)^2] = \langle g,g\rangle \\
    \expec[g(w_i)g(w_{i+k)}] &= \expec[g(w_0)g(w_k)] = \langle g,M^k g\rangle
\end{align*}

A Markov chain is said to be \textit{time-reversible} if for any $A,B\in\mathcal{A}$, the probability of going from $A$ to $B$ is the same as that of going from $B$ to $A$. That is,
\[ \int_B P_u(A)\d{Q}(u) = \int_A P_u(B) \d{Q}(u). \]
It is easy to see that it suffices to have the above for all disjoint sets $A$ and $B$. The above can be rewritten in an even more symmetric fashion as
\[ \int_B \int_A 1\d{P}_u(v)\d{Q}(u) = \int_A \int_B 1\d{P}_u(v)\d{Q}(u). \]
This is equivalent to saying that for any function $g:\Omega\times\Omega\to\R$ (assuming both sides are well-defined),
\begin{equation}
\label{eqn: time reversible function formulation}
    \int_\Omega \int_\Omega F(u,v)\d{P}_u(v)\d{Q}(u) = \int_\Omega \int_\Omega F(v,u)\d{P}_u(v)\d{Q}(u).
\end{equation}
It is equivalent to say that the operator $M$ is self-adjoint.\footnote{an operator $A$ such that $\langle Ax,y\rangle=\langle x,A y\rangle$ for any $x,y$.} If the Markov scheme can be described by a transition function $f$ (with respect to $Q$), then time-reversibility is equivalent to the symmetry of $f$.\\
If the Markov scheme is time-reversible, then for any $g\in L^2$,
\begin{align}
    \langle g,g\rangle - \langle g,M g\rangle &= \int_{\Omega} f^2\d{Q} - \int_\Omega\int_\Omega f(u)f(v)\d{P_u}(v)\d{Q}(u) \nonumber \\
    &= \int_{\Omega}\int_\Omega f^2(u)\d{P_u}(v)\d{Q} - \int_\Omega\int_\Omega f(u)f(v)\d{P_u}(v)\d{Q}(u) \nonumber \\
    &= \frac{1}{2} \left(\int_{\Omega}\int_\Omega (f^2(u)+f^2(v))\d{P_u}(v)\d{Q} - \int_\Omega\int_\Omega 2f(u)f(v)\d{P_u}(v)\d{Q}(u)\right) & (\text{by \Cref{eqn: time reversible function formulation}}) \nonumber \\
    &= \frac{1}{2}\int_\Omega\int_\Omega (f(u)-f(v))^2\d{P_u}(v)\d{Q}(u) \geq 0. \label{eqn: self-adjoint spectral radius 1}
\end{align}
Therefore, the spectral radius\footnote{the largest absolute value of its eigenvalues.} of $M$ is exactly $1$.

\begin{definition}[Laziness]
A Markov chain is said to be \textit{lazy} if for each $u$,
\[ P_u(\{u\})\geq\frac{1}{2}. \]
\end{definition}

There are two main, albeit minor and technical, reasons for desiring laziness:
\begin{itemize}
    \item Sometimes, a lack of laziness can cause parity issues which result in the limit distribution of a chain not converging to the stationary distribution.
    \item In the time-reversible case, it makes the operator $M$ positive semidefinite, thus making it far easier to analyze.
\end{itemize}
To see why the latter occurs, note that if $M$ is self-adjoint, then so is $2M-I$ and by a proof exactly like that of \Cref{eqn: self-adjoint spectral radius 1},
\[ \langle f,M f\rangle = \frac{1}{2}\langle f,f\rangle + \frac{1}{2}\langle f,(2M-I)f\rangle \geq 0. \]
Any Markov scheme can be made lazy easily by flipping a (fair) coin at each step and making a move only if it lands on tails.

\begin{lemma}
Let $w_1,w_2,\ldots$ be a time-reversible Markov chain generated by a lazy Markov scheme $\mathcal{M}$ with $w_0$ drawn from the stationary distribution $Q$ of $\mathcal{M}$. Then for any function $g\in L^2$,
\[ \expec[g(w_i)g(w_j)] \geq \expec[g(w_i)]\expec[g(w_j)] = \expec[g(w_0)^2]. \]
\end{lemma}
\begin{proof}
Assume without loss of generality that $j>i$ and $j-i=k$. Then for any function $h$, the positive semidefiniteness of $M$ implies that
\[ \expec[h(w_i)h(w_j)] = \langle h, M^k h\rangle \geq 0. \]
Applying this to $(g - \expec[g(w_0)])$ yields the result.
\end{proof}

\subsubsection{Conductance}

\begin{definition}[Ergodic Flow]
Define the \textit{ergodic flow} $\Phi:\mathcal{A}\to[0,1]$ of a Markov scheme by
\[ \Phi(A) = \int_A P_u(\Omega \setminus A) \d{Q}(u). \]

\end{definition}

This just measures how likely $w_1$ is to leave the subset $A$ if $w_0$ is initially drawn from $Q$. Observe that since $Q$ is stationary,
\begin{align*}
    \Phi(A) - \Phi(\Omega\setminus A) &= \int_A P_u(\Omega\setminus A)\d{Q}(u) - \int_{\Omega\setminus A} P_u(A)\d{Q}(u) \\
    &= Q(A) - \int_A P_u(A)\d{Q}(u) - \int_{\Omega\setminus A} P_u(A)\d{Q}(u) & (\text{since } P_u(\Omega\setminus A)=1-P_u(A)) \\
    &= Q(A) - \int_\Omega P_u(A)\d{Q}(u) = 0.
\end{align*}
Even conversely, if for some probability distribution $Q'$, the function $\Phi':\mathcal{A}\to[0,1]$ defined by
\[ A\mapsto \int_A P_u(\Omega\setminus A)\d{Q}(u) \]
is invariant under complementation, then $Q'$ is stationary.\\

\begin{fdef}
The \textit{conductance} of the Markov scheme is then defined as
\[ \Phi = \inf_{0<Q(A)<1/2} \frac{\Phi(A)}{Q(A)}. \]
For $0\leq s\leq 1$, the \textit{$s$-conductance} is defined as
\[ \Phi_s = \inf_{s < Q(A) \leq 1/2} \frac{\Phi(A)}{Q(A)-s}. \]
\end{fdef}

The lower the conductance is, the more likely the Markov chain is to ``get stuck" somewhere.\\

For any $u$, $1-P_u(\{u\})$ is called the \textit{local conductance} of the Markov chain at $u$. If $Q(u)>0$,\footnote{it is an atom.} then the local conductance is an upper bound on the conductance.\\
More generally, let
\[ H_t = \{u\in\Omega:P_u(\{u\}) > 1-t\} \]
and $s=Q(H_t)$. Then
\[ \Phi(H_t) = \int_{H_t} P_u(\Omega\setminus H_t)\d{Q}(u) < t Q(H_t). \]
Therefore, the $(s/2)$-conductance is at most $2t$.

The main use of defining conductance is that it is closely related to how fast Markov chains converge to their stationary distribution.\\
Suppose that $Q_k$ is the distribution in the $k$th step of the chain ($Q_k(A)=\Pr[w_k\in A]$). It turns out that if for all $A\in\mathcal{A}$ such that $Q(A)>0$, $\Phi(A)>0$, then $Q_k\to Q$ (in the $\ell_1$ distance). This naturally provides a bound on the speed of convergence.\\
Let us consider the following particular distance function.

\subsubsection{A Distance Function}

\begin{fdef}
For $x\in[0,1]$, consider all measurable functions $g:\Omega\to[0,1]$ such that
\[ \int_{\Omega} g\d{Q} = x. \]
We then define the \textit{distance function} of $Q$ and $Q_k$ by
\[ h_k(x) = \sup_g \int_\Omega g(\d{Q}_k-\d{Q}) = \sup_g \int_\Omega g\d{Q}_k - x. \]
\end{fdef}

For example, it is easily shown that for a finite Markov chain with $N$ states and uniform stationary distribution, $h_k(j/N)$ is the sum of the $j$ largest $\left(Q_k(\omega)-\frac{1}{n}\right)$.\\

There are a few things to note.
\begin{itemize}
    \item For any $x$, $0\leq h_k\leq 1-x$. The lower bound is because one can consider the constant function $x$ on $\Omega$. The upper bound is because $\int_\Omega g\d{Q}_k$ is bounded above by $1$. In particular, $h_k(1)=0$.
    \item $h_k$ is a convex function of $x$. We shall see below in \Cref{hk distance supremum attained} that the supremum in the definition of $h_k$ is attained. Then, for any $a,b,\lambda\in[0,1]$, set $x=\lambda a+(1-\lambda)b$ and let $g_1,g_2$ be the functions that attain the supremums for $h_k(a)$ and $h_k(b)$. Then,
    \[ \sup_g \int_\Omega g\d{Q}_k - x \geq \int_\Omega (\lambda g_1 + (1-\lambda)g_2) \d{Q}_k = \lambda h_k(a) + (1-\lambda) h_k(b). \]
\end{itemize}

This definition might seem quite artificial at the moment, but we hope to give more context to it with the following few lemmas.

\begin{lemma}
For every set $A\in\mathcal{A}$ with $Q(A)=x$,
\[ -h_k(1-x) \leq Q_k(A) - Q(A) \leq h_k(x). \]
\end{lemma}
\begin{proof}
The upper bound is immediate from the definition of the distance function by taking $g = \indic_A$ (the indicator function on $A$). The similar upper bound for $\Omega\setminus A$ immediately gives the result.
\end{proof}

\begin{lemma}
\label{hk distance supremum attained}
For every $0<x<1$, there exists a function $G$ that is $0$-$1$ valued except possibly on a $Q$-atom\footnote{a $Q$-atom is a set $V\in\mathcal{A}$ such that $Q(V)>0$ and for any $V'\subseteq V$, either $Q(V')=Q(V)$ or $Q(V')=0$.} that attains the supremum in the definition of $h_k(x)$.
\end{lemma}
\begin{proof}
Let $U\in\mathcal{A}$ such that $Q(U)=0$ and $Q_k(U)$ is maximum. Let $Q'$ and $Q_k'$ be the restrictions of $Q$ and $Q_k$ to $\Omega\setminus U$. Clearly, the way we have defined $U$ implies that $Q_k'$ is absolutely continuous with respect to $Q'$. Thus, let $\phi$ be the Radon-Nikodym derivative of $Q_k'$ with respect to $Q'$.\\
Now, let $x\in[0,1]$ and $g:\Omega\to[0,1]$ such that $\int_\Omega g\d{Q} = x$.\\
For $t\geq 0$, define
\[ A_t = U \cup \{u \in \Omega\setminus U : \phi(u) \geq t\}\text{ and }s=\inf\{t\geq 0 : Q(A_t) \leq x\}. \]
Observe that since $A_s = \bigcap_{t<s}A_t$, upper semicontinuity implies that $Q(A_s)\geq x$. Also define
\[ A' = \bigcup_{t>s} A_t = U \cup \{u \in \Omega\setminus U : \phi(u) > s\}. \]
Lower semicontinuity implies that $Q(A')\leq x$. We also have that $A'\subseteq A_s$ and for every $u\in A_s\setminus A'$, $\phi(u)=s$.\\
Now, choose a $B\in\mathcal{A}$ such that $A'\subseteq B\subseteq A_s$, $Q(B)\leq x$, and $Q(B)$ is maximum.\\
We first show that if $Q(B)=x$, then the indicator function on $B$ suffices. Indeed, in this case,
\begin{align*}
    \int_\Omega g\d{Q}_k &= \int_U g\d{Q}_k + \int_{B\setminus U} g\phi\d{Q} + \int_{\Omega\setminus B} g\phi\d{Q} \\
    &= \int_U g\d{Q}_k + \int_{B\setminus U} (g-1)\phi\d{Q} + \int_{B\setminus U} \d{Q}_k + \int_{\Omega\setminus B} g\phi\d{Q} \\
    &\leq \int_U \d{Q}_k + s\int_{B\setminus U} (g-1)\d{Q} + \int_{B\setminus U} \d{Q}_k + s\int_{\Omega\setminus B} g \d{Q} & \text{(since $0\leq g\leq 1$ and $\phi\leq s$ almost everywhere on $\Omega\setminus B$)} \\
    &= Q_k(B) + s\int_{\Omega\setminus U} g\d{Q} - s\int_{B\setminus U}\d{Q} \\
    &= Q_k(B) + s(x - Q(B)) = Q_k(B).
\end{align*}
We also see that the supremum is attained when $g=\indic_B$.\\
Next, assume that $Q(B)<x$. Then for every $W\subseteq A_s\setminus B$, either $Q(W)=0$ or $Q(W)>x-Q(B)$. That is, the measure on $A'\setminus B$ is concentrated at atoms. Let $V$ be one such atom. As shown above,
\[ \int_\Omega g\d{Q}_k \leq Q_k(B) + s(x-Q(B)). \]
To show that this bound is attained, let $g=\indic_B+\lambda\indic_{V}$ where $\lambda = (x-Q(B))/Q(V)$. Clearly, $0\leq g\leq 1$. Further,
\[ \int_\Omega g\d{Q} = Q(B) + \lambda Q(V) = x \]
and
\[ \int_\Omega g\d{Q}_k = Q_k(B)+\lambda Q_k(V) = Q_k(B) + s(x-Q(B)) \]
where the last step follows since $\phi(u)=s$ for all $u\in V\subseteq A_s\setminus A'$.
\end{proof}

\begin{lemma}
If $Q$ is atom-free, then
\[ h_k(x) = \sup_{\substack{A\in\mathcal{A} \\ Q(A)=x}} \left(Q_k(A) - Q(A)\right). \]
\end{lemma}
This follows directly from the previous lemma.\\
Although we did say what a rapidly mixing random walk is earlier in \Cref{def: rapidly mixing random walks}, we now define it more generally.\\
First, observe that
\[ \sup_{x} h_k(x) = \sup_{A\in\mathcal{A}} |Q_k(A) - Q(A)| = \frac{1}{2}\norm{Q_k - Q}_1. \]

Let us now get on to the main subject of this section, namely that of bounding the speed of convergence of rapidly mixing Markov chains.

\subsubsection{Rapidly Mixing Markov Chains}

\begin{fdef}[Rapidly Mixing Markov Chain]
A Markov chain is said to be \textit{rapidly mixing} if for some $\theta<1$, $\sup_x h_k(x)$ is $\mathcal{O}(\theta)^k$.
\end{fdef}

\begin{theorem}
For $k\geq 1$, if $s\leq x\leq 1/2$, then
\[ h_k(x) \leq \frac{1}{2} \left(h_{k-1}(x-2\Phi_s(x-s)) + h_{k-1}(x+2\Phi_s(x-s))\right) \]
and if $1/2 \leq x\leq 1-s$, then
\[ h_k(x) \leq \frac{1}{2} \left(h_{k-1}(x-2\Phi_s(1-x-s)) + h_{k-1}(x+2\Phi_s(1-x-s))\right). \]
\end{theorem}
\begin{proof}
We prove the first inequality alone. First of all, note that the functions on both sides are concave.
Therefore, it suffices to prove it the extreme point(s) of the function on the left (the point where the extremum, in this case, maximum is attained). 

By \Cref{hk distance supremum attained}, let $A$ be a set such that $Q(A)=x$ and $h_k(x)=Q_k(A)-Q(A)$. Define $g_1,g_2:\Omega\to[0,1]$ by
\[ g_1(u) = 
\begin{cases}
2P_u(A) - 1, & u\in A, \\
0, & \text{otherwise,}
\end{cases}
\quad
% \text{ and }
g_2(u) = 
\begin{cases}
1, & u\in A, \\
2P_u(A), & \text{otherwise.}
\end{cases}
\]
The functions map into $[0,1]$ because the chain is lazy.\\
Also, let $x_1 = \int_\Omega g_1\d{Q}$ and $x_2 = \int_\Omega g_2\d{Q}$. Observe that $x_1 + x_2 = \int_\Omega 2P_u(A)\d{Q}(u) = 2x$. We have
\begin{align*}
    h_k(x) &= Q_k(A) - Q(A) \\
    &= \frac{1}{2} \left( \left(\int_\Omega g_1\d{Q}_{k-1} - x_1\right) + \left( \int_\Omega g_2\d{Q}_{k-1} - x_2 \right) \right) \\
    &\leq h_{k-1}(x_1) + h_{k-1}(x_2).
\end{align*}
We also have
\[ x_2-x = x-x_1 = \int_A (2-2P_u(A))\d{Q}(u) = 2\Phi(A) \geq 2\Phi_s(x-s). \]
\end{proof}

The next result is analogous to \Cref{large conductance implies rapidly mixing} and is our main tool in bounding the speed of convergence using the conductance.

\begin{ftheo}
Let $0\leq s\leq 1/2$ and suppose we have $c_1,c_2$ such that for $s\leq x\leq 1-s$,
\[ h_0(x) \leq c_1 + c_2\min\{\sqrt{x-s},\sqrt{1-s-x}\}. \]
Then for every $k\geq 0$ and $s\leq x\leq 1-s$,
\[ h_k(x) \leq c_1 + c_2\min\{\sqrt{x-s},\sqrt{1-s-x}\} \left(1-\frac{\Phi_s^2}{2}\right)^k. \]
\end{ftheo}
\begin{proof}
We prove this via induction. It clearly holds for $k=0$. Suppose that $k\leq 1$ and $s\leq x\leq 1/2$. Using induction,
\begin{align*}
    h_k(x) &\leq \frac{1}{2} \left(h_{k-1}(x-2\Phi_s(x-s)) + h_{k-1}(x+2\Phi_s(x-s))\right) \\
    &\leq c_1 + \frac{c_2}{2} \left(1-\frac{\Phi_s^2}{2}\right)^{k-1} \left(\sqrt{x-2\Phi_s(x-s)-s} + \sqrt{x+2\Phi_s(x-s)-s}\right) \\
    &= c_1 + \frac{c_2}{2} \sqrt{x-s} \left(1-\frac{\Phi_s^2}{2}\right)^{k-1} \left(\sqrt{1-2\Phi_s} + \sqrt{1+2\Phi_s}\right) \\
    &\leq c_1 + \frac{c_2}{2}\sqrt{x-s}\left(1-\frac{\Phi_s^2}{2}\right)^{k-1} \left(1-\frac{2\Phi_s}{2}-\frac{4\Phi_s^2}{8} + 1+\frac{2\Phi_s}{2}-\frac{4\Phi_s^2}{8}\right) \\
    &= c_1 + c_2 \sqrt{x-s} \left(1-\frac{\Phi_s^2}{2}\right)^k \qedhere
\end{align*}
\end{proof}

Writing the above in a slightly more useful form,

\begin{corollary}

\end{corollary}