\section{Introduction}

\begin{exercise}
	Recall that the number of $k$-subsets of $[n]$ is $\binom{n}{k}$. Given a $k$-subset $S = \{x_1,\ldots,x_k\}$ of $[n]$, we write $S_< = \{x_1,\ldots,x_k\}_<$ to denote that $x_1<x_2<\cdots<x_k$. Determine the number of $k$-subsets $\{x_1,\ldots,x_k\}_<$ of $[n]$ such that $x_i \cong i \mod 2$.
\end{exercise}
For example, for $n=6$ and $k=3$, we have the subsets $\{1,4,5\},\{1,2,3\},\{1,2,5\},\{3,4,5\}$.


Broadly, there are three types of ``answers'': a formula, a recurrence, and a generating function. A great example of the second and third is the following.\\
% Euler's Theorem
$p(n)$, the number of number partitions of $n$, is given by the generating function
\[ \sum_{n \ge 0} p(n) x^n = \prod_{i \ge 1} \frac{1}{1-x^i}. \]
Using this, a recursion may be obtained as well.
We do \emph{not} plug in values for $x$ in the above. We merely look at the coefficient of $x^n$ in it. We want the coefficient to be a finite sum for all $n$. If it is an infinite sum, convergence issues may arise.

% www.math.iitb.ac.in/~krishnan/phd-2022/

% The number of derangements of $[n]$ is the integer closest to $n!/e$.
% Bell number B_n (number of set partitions of $[n]$) : \sum_{n \ge 0} B_n x^n / n! = e^{e^x - 1}.

\subsection{Counting in \texorpdfstring{$\mathfrak{S}_n$}{Sn}}

	Recall that $\mathfrak{S}_n$ is generated by transpositions. A transposition $(i,j)$ is a permutation $\sigma$ defined by
	\[ \sigma(k) = \begin{cases} j, & k=i, \\ i, & k=j, \\ k, & \text{otherwise.} \end{cases} \]
	In fact, $\mathfrak{S}_n$ is generated by the set of just ``adjacent transpositions'' $S_i = (i,i+1)$ for $1 \le i < n$.
	We have
	\begin{align*}
		S_i^2 &= \Id \\
		S_i S_{i+1} S_i &= S_{i+1} S_i S_{i+1} \\
		S_i S_j &= S_j S_i \text{ if $|i-j| > 2$.}
	\end{align*}


	\begin{fdef}
		Given a permutation $\pi \in \mathfrak{S}_n$, define the \emph{length} $\ell(\pi)$ of $\pi$ to be the smallest $k$ such that there exist adjacent transpositions $\sigma_1,\cdots,\sigma_k$ such that $\pi = \sigma_1\cdots\sigma_k$.
	\end{fdef}
	% PRESENT PROOF THAT WE CAN WRITE IT IN THIS WAY ON TUESDAY -- 02/08/2022
	% DONE.

	\begin{fprop}
		Consider the \emph{inversion number} $\inv(\pi)$ of a permutation, defined by
		\[ \inv(\pi) = \left|\{ 1 \le i \le j \le n : \pi_i > \pi_j \}\right|. \]
		Then, $\ell(\pi) = \inv(\pi)$.
	\end{fprop}

	\begin{fdef}
		The \emph{sign} of a permutation $\pi$ is defined by $\sign(\pi) = (-1)^{\inv(\pi)}$. Equivalently,
		\[ \sign(\pi) = \frac{\prod_{1 \le i < j \le n} (x_{pi_i} - x_{\pi_j})}{\prod_{1 \le i < j \le n} (x_i - x_j)}. \]
	\end{fdef}

	% LATER, STUDY NUMBER OF ``REDUCED'' PRODUCTS? (NUMBER OF WAYS IN WHICH PI CAN BE WRITTEN AS A PRODUCT OF L(PI) ADJ TRANSPOSITIONS)


	It is straightforward to see that for all $\pi \in \mathfrak{S}_n$, $0 \le \inv(\pi) \le \binom{n}{2}$.
	\begin{fprop}
		\label{prop: inv n}
		Consider $\inv_n(q) = \sum_{\pi \in \mathfrak{S}_n} q^{\inv(\pi)}$. Then,
		\[ \inv_n(q) = \prod_{1 \le m \le n} [n]_q, \]
		where
		\[ [m]_q = \begin{cases} 1 + q + \cdots + q^{m-1}, & m \ge 1, \\ 0, & m = 0. \end{cases} \]
	\end{fprop}
	This quantity $[m]_q$ is called the $q$-analogue of $m$, and similarly, the $q$-analogue of $n!$ is $\prod_{i=1}^n [m]_q$ (this is slightly vague).
	Note in particular that $n! = \inv_n(1)$.
	\begin{proof}
		We prove this by induction. It is easily verified for $n = 2$.\\
		Take $\sigma \in \mathfrak{S}_{n-1}$. There are $n$ ``gaps'' where $n$ can be ``placed'' in $\sigma$ to get a permutation in $\mathfrak{S}_n$. If we place it in the $i$th position from the end (for $0 \le i \le n-1$), the inversion number of the newly obtained permutation is $i$ more than the inversion number of $\sigma$.\\
		As a result,
		\[ \inv_n(q) = \inv_{n-1}(q) + q \inv_{n-1}(q) + q^2 \inv_{n-1}(q) + \cdots + q^{n-1} \inv_{n-1}(q) = [n]_q \inv_{n-1}(q), \]
		where the $q^i \inv_{n-1}(q)$ term corresponds to the case where $n$ is placed in the $i$th position from the end. The required follows by the inductive hypothesis.
	\end{proof}

	\begin{definition}[Descent]
		For $\pi \in \mathfrak{S}_n$, define the \emph{descents} $\DES(\pi) = \{i \in [n-1] : \pi_i > \pi_{i+1}\}$, $\des(\pi) = |\DES(\pi)|$, and $\maj(\pi) = \sum_{i \in \DES(\pi)} i$. 
	\end{definition}
	There are central limit theorems for many of these parameters, which we shall not study.\\
	A permutation $\pi$ has $\des(\pi) + 1$ many ``increasing runs''.

	For example, for the permutation $\pi = (1\mapsto 5,2\mapsto1,3\mapsto2,4\mapsto6,5\mapsto4,6\mapsto3) \in \mathfrak{S}_6$, $\DES(\pi) = \{1,4,5\}$, $\des(\pi) = 3$, and $\maj(\pi) = 10$.

	\begin{fprop}
		\label{prop: maj n}
		The distribution of $\maj(\pi)$ over $\mathfrak{S}_n$ is the same as that of $\inv(\pi)$. Equivalently,
		\[ \maj_n(q) = \sum_{\pi \in \mathfrak{S}_n} q^{\maj(\pi)} = \prod_{m=1}^n [m]_q = \inv_n(q). \] 
	\end{fprop}
	This result took nearly 50 years to prove!
	\begin{proof}
		The strategy is similar to that of \Cref{prop: inv n}. Let $\pi \in \mathfrak{S}_{n-1}$. As before, there are $n$ positions to insert $n$.
		% An insertion increases $\maj$ (compared to $\pi$) only if it is placed in the middle of an increasing run. That is, we must place it  Further, in this case, it increases $\des$ by $1$. What is the sum of $\maj$ increases over all possible insertions? 
		\begin{itemize}
			\item Label the positions of descents of $\sigma$ and the last position from right ot left as $0,1,\ldots,\des(\pi)$.
			\item Label the remaining positions from left to right as $\des(\pi)+1,\ldots,n-1$.
		\end{itemize}
		We claim that inserting $n$ at a position increases $\maj$ by the labelled amount.\\
		If inserted anywhere, all the descent positions starting from there increase by $1$. This explains why the increase is equal to the labelled quantity for positions that are descents, since no new descents are introduced. In the case where we insert it in a position of non-descent, we further introduce a new descent at the position of insertion of $n$, which explains why the increase is equal tot he labelled quantity for positions that are not descents.\\
		The remainder of the proof is identical to that of \Cref{prop: inv n}, since the increases are in bijection with $[n-1]_0$.
	\end{proof}

	\begin{definition}
		A parameter $f : \mathfrak{S}_n \to \R$ of permutations such that
		\[ \sum_{\pi \in \mathfrak{S}_n} q^{f(\pi)} = \prod_{1 \le m \le n} [m]_q \]
		is said to be \emph{Mahonian}.
	\end{definition}

	As we saw in \Cref{prop: inv n,prop: maj n}, both $\inv$ and $\maj$ are Mahonian.

	\begin{problem*}
		Count the number of spanning trees in an arbitrary (finite) graph $G$.
	\end{problem*}

	This was solved by Kirchhoff using the Matrix Tree Theorem.
	
	\begin{ftheo}[Matrix Tree Theorem]
		Consider the \emph{Laplacian} $L = D-A$ of a graph $G$, where $A$ is its adjacency matrix and $D$ is a diagonal matrix with the diagonal entries being the degrees of the vertices. The determinant of any $(n-1)\times(n-1)$ submatrix of $L$ obtained by omitting any arbirary row and column is equal to the number of spanning trees of $G$.
	\end{ftheo}

	% oriented incidence matrix is totally unimodular -- poincare

	In particular, when $G = K_n$, we end up getting the following.

	\begin{ftheo}[Cayley's Theorem]
		\label{theo: cayleys theorem}
		The number of spanningtrees in $K_n$ is $n^{n-2}$.
	\end{ftheo}
	One proof by Pr\"{u}fer gives an explicit bijection between spanning trees and sequences $(v_1,\ldots,v_{n-2})$ of vertices in $G$.\\
	Another proof is of course using the matrix tree theorem, which reduces it to a simple determinant calculation.\\
	Joyal gave another bijection between elements of the form $(T,u,v)$ where $T$ is a spanning tree and $u,v$ are vertices in $G$, and functions from $[n] \to [n]$.\\

	The proof we give uses exponential generating functions. Recall the following result, which we give without proof. Interested readers may consult Corollary 5.1.6 from \cite{ec2} for further details.

	\begin{ftheo}[Exponential Formula]
		\label{ec2: egf sum over partitions}
		Let $\{f_n\}$ be a sequence with exponential generating function
		\[ F(x) = \sum_{n \ge 1} f_n \frac{x^n}{n!}. \]
		Define the sequence $h_n$ by
		\[ h_n = \sum_{\substack{\pi \in \operatorname{SetPartn}([n]) \\ \pi = \{S_1,\ldots,S_k\}}} f_{|S_1|} f_{|S_2|} \cdots f_{|S_k|}  \]
		and $h_0 = 1$, and let
		\[ H(x) = \sum_{n \ge 0} h_n \frac{x^n}{n!}. \]
		Then,
		\[ H(x) = \exp(F(x)) \]
	\end{ftheo}
	Note that the summation of $F$ is for $n \ge 1$, because we may assume that $f_0 = 0$ since $f_0$ does not appear in the expression of any $h_n$.\\

	\begin{fdef}[Compositional inverse]
		Generating functions $F$ and $G$ are said to be \emph{compositional inverses} if $F(G(x)) = G(F(x)) = x$.
	\end{fdef}

	At long last, let us return to \Cref{theo: cayleys theorem}.

	\begin{proof}[Proof of \nameref{theo: cayleys theorem}]
		Instead of looking at the number $\text{T}_n$ of spanning trees, we shall look at $\text{RT}_n$, the number of \emph{rooted} spanning trees. Clearly, $\text{RT}_n = n \text{T}_n$.\\
		Define $\text{RF}_n$ to be the number of rooted forests on $[n]$ and let
		\begin{align*}
			\operatorname{RF}(x) &= \sum_{n \ge 0} \text{RF}_n \frac{x^n}{n!} \\
			\operatorname{RT}(x) &= \sum_{n \ge 0} \text{RT}_n \frac{x^n}{n!}.
		\end{align*}

		Using \Cref{ec2: egf sum over partitions}, it is not too difficult to see that
		\begin{equation}
			\label{eqn 1}
			\operatorname{RF}(x) = \exp(\operatorname{RT}(x)).
		\end{equation}

		\textbf{Claim} (Polya). $\text{RT}_{n+1} = (n+1) \text{RF}_n$.\\
		Indeed, any rooted tree on $K_{n+1}$ may be obtained from a rooted forest $F$ on $K_n$ by adding a new vertex $v$, adding the edge between each root in $F$ and $v$ to the spanning tree, removing the ``root status'' from all vertices except $v$. $v$ can be labelled in $n+1$ ways, so we are done.\\

		As a result,
		\begin{equation}
			\label{eqn 2}
			\operatorname{RF}(x) = \sum_{n\ge 0} \frac{\operatorname{RT}_{n+1}}{n+1} \cdot \frac{x^n}{n!} = \frac{1}{x} \operatorname{RT}(x).
		\end{equation}
		Combining \Cref{eqn 1,eqn 2},
		\[ \operatorname{RT}(x) = x \exp(\operatorname{RT}(x)). \]
		That is, $\operatorname{RT}$ is the compositional inverse of $x \mapsto xe^{-x}$. We are almost done.

	\end{proof}
