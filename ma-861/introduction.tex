\section{Introduction}

\begin{exercise}
	Recall that the number of $k$-subsets of $[n]$ is $\binom{n}{k}$. Given a $k$-subset $S = \{x_1,\ldots,x_k\}$ of $[n]$, we write $S_< = \{x_1,\ldots,x_k\}_<$ to denote that $x_1<x_2<\cdots<x_k$. Determine the number of $k$-subsets $\{x_1,\ldots,x_k\}_<$ of $[n]$ such that $x_i \cong i \mod 2$.
\end{exercise}
For example, for $n=6$ and $k=3$, we have the subsets $\{1,4,5\},\{1,2,3\},\{1,2,5\},\{3,4,5\}$.


Broadly, there are three types of ``answers'': a formula, a recurrence, and a generating function. A great example of the second and third is the following.\\
% Euler's Theorem
$p(n)$, the number of number partitions of $n$, is given by the generating function
\[ \sum_{n \ge 0} p(n) x^n = \prod_{i \ge 1} \frac{1}{1-x^i}. \]
Using this, a recursion may be obtained as well.
We do \emph{not} plug in values for $x$ in the above. We merely look at the coefficient of $x^n$ in it. We want the coefficient to be a finite sum for all $n$. If it is an infinite sum, convergence issues may arise.

% www.math.iitb.ac.in/~krishnan/phd-2022/

% The number of derangements of $[n]$ is the integer closest to $n!/e$.
% Bell number B_n (number of set partitions of $[n]$) : \sum_{n \ge 0} B_n x^n / n! = e^{e^x - 1}.

\subsection{Counting in \texorpdfstring{$\mathfrak{S}_n$}{Sn}}

	Recall that $\mathfrak{S}_n$ is generated by transpositions. A transposition $(i,j)$ is a permutation $\sigma$ defined by
	\[ \sigma(k) = \begin{cases} j, & k=i, \\ i, & k=j, \\ k, & \text{otherwise.} \end{cases} \]
	In fact, $\mathfrak{S}_n$ is generated by the set of just ``adjacent transpositions'' $S_i = (i,i+1)$ for $1 \le i < n$.
	We have
	\begin{align*}
		S_i^2 &= \Id \\
		S_i S_{i+1} S_i &= S_{i+1} S_i S_{i+1} \\
		S_i S_j &= S_j S_i \text{ if $|i-j| > 2$.}
	\end{align*}


	\begin{fdef}
		Given a permutation $\pi \in \mathfrak{S}_n$, define the \emph{length} $\ell(\pi)$ of $\pi$ to be the smallest $k$ such that there exist adjacent transpositions $\sigma_1,\cdots,\sigma_k$ such that $\pi = \sigma_1\cdots\sigma_k$.
	\end{fdef}
	% PRESENT PROOF THAT WE CAN WRITE IT IN THIS WAY ON TUESDAY -- 02/08/2022
	% DONE.

	\begin{fprop}
		Consider the \emph{inversion number} $\inv(\pi)$ of a permutation, defined by
		\[ \inv(\pi) = \left|\{ 1 \le i \le j \le n : \pi_i > \pi_j \}\right|. \]
		Then, $\ell(\pi) = \inv(\pi)$.
	\end{fprop}

	\begin{fdef}
		The \emph{sign} of a permutation $\pi$ is defined by $\sign(\pi) = (-1)^{\inv(\pi)}$. Equivalently,
		\[ \sign(\pi) = \frac{\prod_{1 \le i < j \le n} (x_{\pi_i} - x_{\pi_j})}{\prod_{1 \le i < j \le n} (x_i - x_j)}. \]
	\end{fdef}

	% LATER, STUDY NUMBER OF ``REDUCED'' PRODUCTS? (NUMBER OF WAYS IN WHICH PI CAN BE WRITTEN AS A PRODUCT OF L(PI) ADJ TRANSPOSITIONS)


	It is straightforward to see that for all $\pi \in \mathfrak{S}_n$, $0 \le \inv(\pi) \le \binom{n}{2}$.
	\begin{fprop}
		\label{prop: inv n}
		Consider $\inv_n(q) = \sum_{\pi \in \mathfrak{S}_n} q^{\inv(\pi)}$. Then,
		\[ \inv_n(q) = \prod_{1 \le m \le n} [n]_q, \]
		where
		\[ [m]_q = \begin{cases} 1 + q + \cdots + q^{m-1}, & m \ge 1, \\ 0, & m = 0. \end{cases} \]
	\end{fprop}
	This quantity $[m]_q$ is called the $q$-analogue of $m$, and similarly, the $q$-analogue of $n!$ is $\prod_{i=1}^n [m]_q$ (this is slightly vague).
	Note in particular that $n! = \inv_n(1)$.
	\begin{proof}
		We prove this by induction. It is easily verified for $n = 2$.\\
		Take $\sigma \in \mathfrak{S}_{n-1}$. There are $n$ ``gaps'' where $n$ can be ``placed'' in $\sigma$ to get a permutation in $\mathfrak{S}_n$. If we place it in the $i$th position from the end (for $0 \le i \le n-1$), the inversion number of the newly obtained permutation is $i$ more than the inversion number of $\sigma$.\\
		As a result,
		\[ \inv_n(q) = \inv_{n-1}(q) + q \inv_{n-1}(q) + q^2 \inv_{n-1}(q) + \cdots + q^{n-1} \inv_{n-1}(q) = [n]_q \inv_{n-1}(q), \]
		where the $q^i \inv_{n-1}(q)$ term corresponds to the case where $n$ is placed in the $i$th position from the end. The required follows by the inductive hypothesis.
	\end{proof}

	\begin{definition}[Descent]
		\label{def: descent}
		For $\pi \in \mathfrak{S}_n$, define the \emph{descents} $\DES(\pi) = \{i \in [n-1] : \pi_i > \pi_{i+1}\}$, $\des(\pi) = |\DES(\pi)|$, and $\maj(\pi) = \sum_{i \in \DES(\pi)} i$. 
	\end{definition}
	Some books define the number of descents as $\des(\pi)+1$ instead.\\
	There are central limit theorems for many of these parameters, which we shall not study.\\
	A permutation $\pi$ has $\des(\pi) + 1$ many ``increasing runs''.

	For example, for the permutation $\pi = (1\mapsto 5,2\mapsto1,3\mapsto2,4\mapsto6,5\mapsto4,6\mapsto3) \in \mathfrak{S}_6$, $\DES(\pi) = \{1,4,5\}$, $\des(\pi) = 3$, and $\maj(\pi) = 10$.

	\begin{fprop}
		\label{prop: maj n}
		The distribution of $\maj(\pi)$ over $\mathfrak{S}_n$ is the same as that of $\inv(\pi)$. Equivalently,
		\[ \maj_n(q) = \sum_{\pi \in \mathfrak{S}_n} q^{\maj(\pi)} = \prod_{m=1}^n [m]_q = \inv_n(q). \] 
	\end{fprop}
	This result took nearly 50 years to prove!
	\begin{proof}
		The strategy is similar to that of \Cref{prop: inv n}. Let $\pi \in \mathfrak{S}_{n-1}$. As before, there are $n$ positions to insert $n$.
		% An insertion increases $\maj$ (compared to $\pi$) only if it is placed in the middle of an increasing run. That is, we must place it  Further, in this case, it increases $\des$ by $1$. What is the sum of $\maj$ increases over all possible insertions? 
		\begin{itemize}
			\item Label the positions of descents of $\sigma$ and the last position from right ot left as $0,1,\ldots,\des(\pi)$.
			\item Label the remaining positions from left to right as $\des(\pi)+1,\ldots,n-1$.
		\end{itemize}
		We claim that inserting $n$ at a position increases $\maj$ by the labelled amount.\\
		If inserted anywhere, all the descent positions starting from there increase by $1$. This explains why the increase is equal to the labelled quantity for positions that are descents, since no new descents are introduced. In the case where we insert it in a position of non-descent, we further introduce a new descent at the position of insertion of $n$, which explains why the increase is equal tot he labelled quantity for positions that are not descents.\\
		The remainder of the proof is identical to that of \Cref{prop: inv n}, since the increases are in bijection with $[n-1]_0$.
	\end{proof}

	\begin{definition}
		A parameter $f : \mathfrak{S}_n \to \R$ of permutations such that
		\[ \sum_{\pi \in \mathfrak{S}_n} q^{f(\pi)} = [n]_q! = \prod_{1 \le m \le n} [m]_q \]
		is said to be \emph{Mahonian}.
	\end{definition}

	As we saw in \Cref{prop: inv n,prop: maj n}, both $\inv$ and $\maj$ are Mahonian.

\subsection{Counting spanning trees}

	\begin{problem*}
		Count the number of spanning trees in an arbitrary (finite) graph $G$.
	\end{problem*}

	This was solved by Kirchhoff using the Matrix Tree Theorem.
	
	\begin{ftheo}[Matrix Tree Theorem]
		Consider the \emph{Laplacian} $L = D-A$ of a graph $G$, where $A$ is its adjacency matrix and $D$ is a diagonal matrix with the diagonal entries being the degrees of the vertices. The determinant of any $(n-1)\times(n-1)$ submatrix of $L$ obtained by omitting any arbitrary row and column is equal to the number of spanning trees of $G$.
	\end{ftheo}

	% oriented incidence matrix is totally unimodular -- poincare

	In particular, when $G = K_n$, we end up getting the following.

	\begin{ftheo}[Cayley's Theorem]
		\label{theo: cayleys theorem}
		The number of spanning trees in $K_n$ is $n^{n-2}$.
	\end{ftheo}
	One proof by Pr\"{u}fer gives an explicit bijection between spanning trees and sequences $(v_1,\ldots,v_{n-2})$ of vertices in $G$.\\
	Another proof is of course using the matrix tree theorem, which reduces it to a simple determinant calculation.\\
	Joyal gave another bijection between elements of the form $(T,u,v)$ where $T$ is a spanning tree and $u,v$ are vertices in $G$, and functions from $[n] \to [n]$.\\

	The proof we give uses exponential generating functions. Recall the following result, which we give without proof. Interested readers may consult Corollary 5.1.6 of \cite{ec2} for further details.

	\begin{ftheo}[Exponential Formula]
		\label{ec2: egf sum over partitions}
		Let $\{f_n\},\{g_n\}$ be a sequence with exponential generating functions
		\[ F(x) = \sum_{n \ge 1} f_n \frac{x^n}{n!} \text{ and } G(n) = \sum_{n \ge 0} g_n \frac{x^n}{n!} . \]
		Define the sequence $h_n$ by
		\[ h_n = \sum_{\substack{\pi \in \operatorname{SetPartn}([n]) \\ \pi = \{S_1,\ldots,S_k\}}} f_{|S_1|} f_{|S_2|} \cdots f_{|S_k|} g(k)  \]
		and $h_0 = 1$, and let
		\[ H(x) = \sum_{n \ge 0} h_n \frac{x^n}{n!}. \]
		Then,
		\[ H(x) = G(F(x)). \]
	\end{ftheo}

	\begin{ftheo}[Permutation Formula II]
		\label{ec2: egf sum over perms}
		Let $\{f_n\}$ be a sequence and define the sequence $h_n$ by
		\[ h_n = \sum_{\substack{\pi \in \mathfrak{S}_n \\ \pi \text{ has cycles } \{C_1,\ldots,C_k\}}} f_{|C_1|} f_{|C_2|} \cdots f_{|C_k|}  \]
		and $h_0 = 1$, and let
		\[ H(x) = \sum_{n \ge 0} h_n \frac{x^n}{n!}. \]
		Then,
		\[ H(x) = \exp \left( \sum_{n \ge 1} f_n \frac{x^n}{n} \right) . \]
	\end{ftheo}
	Note that the summation of $F$ is for $n \ge 1$, because we may assume that $f_0 = 0$ since $f_0$ does not appear in the expression of any $h_n$.\\

	\begin{fdef}[Compositional inverse]
		Generating functions $F$ and $G$ are said to be \emph{compositional inverses} (of each other) if $F(G(x)) = G(F(x)) = x$.
	\end{fdef}

	Let
	\[ F(x) = \sum_{n \ge 0} f_n x^n \text{ and } G(x) = \sum_{n \ge 0} g_n x^n \]
	be compositional inverses of each other. It is reasonably straightforward to show that $f_0 = g_0 = 0$ and $f_1,g_1 \ne 0$. The first condition implies that the coefficient of any $x^n$ in $F\circ G$ (or $G \circ F$) is finite. 

	\begin{ftheo}[Lagrange Inversion Theorem]
		\label{theo: lagrange inversion}
		Let
		\[ F(x) = \sum_{n \ge 0} f_n x^n \text{ and } G(x) = \sum_{n \ge 0} g_n x^n \]
		be compositional inverses of each other. Then, $ng_n$ is the coefficient of $1/x$ in $(1/F(x))^n$.
	\end{ftheo}
	Equivalently, $ng_n$ is the coefficient of $x^{n-1}$ in $(x/F(x))^n$.
	\begin{proof}
		We have
		\[ x = G(F(x)) = \sum_{i \ge 0} g_i F(x)^i. \]
		Differentiating,
		\[ 1 = \sum_{i \ge 0} g_i i F(x)^{i-1} F'(x). \]
		As a result,
		\[ \left(\frac{1}{F(x)}\right)^n = \sum_{i \ge 0} g_i i F(x)^{i-1-n} F'(x).  \]
		Whenever $i \ne n$, the coefficient of $1/x$ in $F(x)^{i-1-n} F'(x) = \left(F(x)^{i-n}/(i-n)\right)'$ is zero. Indeed, recall that the coefficient of $1/x$ in the derivative of any power series with possibly negative exponents is zero.\\
		As a result, the coefficient of $1/x$ in $(1/F(x))^n$ is equal to the coefficient of $1/x$ in $g_n n F'(x) / F(x)$.
		% , which is the constant term in $n g_n x F'(x) / F(x)$ -- observe that there cannot be a $x^{-m}$ term for any $m \ge 2$.
		We have
		\[ \frac{F'(x)}{F(x)} = \frac{f_1 + 2f_2x + \cdots}{f_1x + f_2x^2 + \cdots}. \]
		The coefficient of $1/x$ in this is $f_1/f_1 = 1$, and the desideratum follows. 
	\end{proof}

	At long last, let us return to \nameref{theo: cayleys theorem}.

	\begin{proof}[Proof of \nameref{theo: cayleys theorem}]
		Instead of looking at the number $\text{T}_n$ of spanning trees, we shall look at $\text{RT}_n$, the number of \emph{rooted} spanning trees. Clearly, $\text{RT}_n = n \text{T}_n$.\\
		Define $\text{RF}_n$ to be the number of rooted forests on $[n]$ and let
		\begin{align*}
			\operatorname{RF}(x) &= \sum_{n \ge 0} \text{RF}_n \frac{x^n}{n!} \\
			\operatorname{RT}(x) &= \sum_{n \ge 0} \text{RT}_n \frac{x^n}{n!}.
		\end{align*}

		Using \Cref{ec2: egf sum over partitions}, it is not too difficult to see that
		\begin{equation}
			\label{eqn 1}
			\operatorname{RF}(x) = \exp(\operatorname{RT}(x)).
		\end{equation}

		\textbf{Claim} (Polya). $\text{RT}_{n+1} = (n+1) \text{RF}_n$.\\
		Indeed, any rooted tree on $K_{n+1}$ may be obtained from a rooted forest $F$ on $K_n$ by adding a new vertex $v$, adding the edge between each root in $F$ and $v$ to the spanning tree, removing the ``root status'' from all vertices except $v$. $v$ can be labelled in $n+1$ ways, so we are done.\\

		As a result,
		\begin{equation}
			\label{eqn 2}
			\operatorname{RF}(x) = \sum_{n\ge 0} \frac{\operatorname{RT}_{n+1}}{n+1} \cdot \frac{x^n}{n!} = \frac{1}{x} \operatorname{RT}(x).
		\end{equation}
		Combining \Cref{eqn 1,eqn 2},
		\[ \operatorname{RT}(x) = x \exp(\operatorname{RT}(x)). \]
		That is, $\operatorname{RT}$ is the compositional inverse of $x \mapsto xe^{-x}$.
		Now, we use the \nameref{theo: lagrange inversion} to get that $n\text{RT}_n/n!$ is equal to the coefficient of $x^{n-1}$ in $(x/xe^{-x})^n = e^{nx}$, which is $n^{n-1}/(n-1)!$. Therefore, $\text{T}_n = \text{RT}_n/n = n^{n-2}$ and we are done.
	\end{proof}

	% cool fact: matching polynomial of any graph has real roots.

\subsection{Chebyshev polynomials}

	We would like a polynomial $T_n(x)$ such that $T_n(\cos\theta) = \cos(n\theta)$. Why does such a polynomial even exist? Recall that
	\[ (\cos \theta + \iota \sin \theta)^n = \cos n\theta + \iota \sin n\theta. \]
	Since the real part of the left only has even powers of $\sin$, we can convert it to a polynomial of $\cos\theta$s alone.\\
	For example,
	\begin{align*}
		T_0(x) &= 1, \\
		T_1(x) &= x, \\
		T_2(x) &= 2x^2-1.
	\end{align*}

	\begin{fprop}
		\label{prop: recurrence of Tn}
		\[ T_n(x) = \begin{cases} 1, & n=0, \\ x, & n=1, \\ 2xT_{n-1}(x) - T_{n-2}(x), & n \ge 2. \end{cases} \]
	\end{fprop}
	We give the proof of the above in the solution to \Cref{problem: recurrence of Chebyshev of the first kind}.

	\begin{fprop}
		\label{problem: recurrence of Chebyshev of the first kind}
		$T_0(x) = 1$, $T_1(x) = x$, and for $n \ge 2$,
		\[ T_n(x) = 2xT_{n-1}(x) - T_{n-2}(x). \]
	\end{fprop}
	\begin{proof}
		Let $\cos \theta = x$. We have
		\begin{align*}
			T_n(x) = \cos n\theta &= \cos (n-1)\theta \cos \theta - \sin (n-1)\theta \sin \theta \\
				&= x T_{n-1}(x) - ( \sin (n-2)\theta \cos\theta + \cos (n-2)\theta \sin\theta ) \sin\theta \\
				&= x T_{n-1}(x) - T_{n-2}(x) (1-x^2) - x (\sin\theta \sin (n-2)\theta) \\
				&= x T_{n-1}(x) + x^2 T_{n-2}(x) - T_{n-2}(x) - x (\cos\theta \cos (n-2)\theta - \cos (n-1)\theta) \\
				&= 2x T_{n-1}(x) - T_{n-2}(x). \qedhere
		\end{align*}
	\end{proof}


	% % PSHEET 2 EXERCISE 1
	% \begin{ftheo}
	% 	Show that
	% 	\[ T_n(x) = 2xT_{n-1}(x) - T_{n-2}(x). \]
	% 	when $n \ge 2$, and $T_0(x) = 1, T_1(x) = x$.
	% \end{ftheo}

	\begin{fdef}[Chebyshev polynomials]
		The $n$th \emph{Chebyshev polynomial of the first kind} $T_n$ is defined as above.\\
		The $n$th \emph{Chebyshev polynomial of the second kind} $U_n$ is defined by
		\[ U_n(x) = \begin{cases} 1, & n=0, \\ 2x, & n=1, \\ 2xU_{n-1}(x) - U_{n-2}(x), & n \ge 2. \end{cases} \]
	\end{fdef}


	% \begin{exercise}
	% 	Show that
	% 	\begin{enumerate}
	% 		\item \phantom{pain}
	% 		\begin{enumerate}[label=\alph*)]
	% 			\item $T_n(1) = 1$.
	% 			\item $T_n(-1) = (-1)^n$
	% 		\end{enumerate}
	% 		\item \phantom{pain}
	% 		\begin{enumerate}[label=\alph*)]
	% 			\item $U_n(1) = n+1$.
	% 			\item $U_n(-1) = (-1)^n(n+1)$
	% 		\end{enumerate}
	% 		\item $U_n(\iota/2)/\iota^{n}$ is the $(n+1)$th Fibonacci number.
	% 		\item if $m,n \ge 1$,
	% 		\[ T_{m+n}(x) = T_m(x)U_n(x) - T_{m-1}(x)U_{n-1}(x) \]
	% 	\end{enumerate}
	% \end{exercise}

	Consider the number of tilings of a $1\times n$ board $B_n$ using squares ($1\times 1$ pieces) and dimers ($1\times 2$ pieces). It is not too difficult to show that this corresponds to the Fibonacci numbers.\\
	Now, instead consider a \emph{weighted} version of this problem, where we give squares a weight of $2x$ and dimers a weight of $-1$. The weight $\wt(T)$ of a given tiling $T$ is equal to the product of the weights of the pieces used. Then, the Chebyshev polynomial $U_n$ is just the sum of the weights of all tilings of $B_n$!
	\[ U_n(x) = \sum_{\text{tilings $T$ of $B_n$}} \wt(T). \]
	Similar to this, we can get a combinatorial model for $T_n$ as well, with the only difference being that a square piece has weight $x$ if it is at the lefmost $(1,1)$ position.

	Given a tiling $T$, let $S(T)$ and $D(T)$ be the number of squares and dimers in the tiling respectively.
	In general, define
	\begin{equation}
		\label{eqn: board tiling polynomial}
		F_n(s,t) = \sum_{\text{tilings $T$ of $B_n$}} s^{S(T)} t^{D(T)}.
	\end{equation}

	Then,
	\begin{align*}
		F_0(s,t) &= 1, \\
		F_1(s,t) &= s, \\
		F_n(s,t) &= sF_{n-1}(s,t) + tF_{n-2}(s,t).
	\end{align*}

\subsection{More on $q$-analogues}

	Recall the definition of $[n]_q! = \prod_{i=1}^n [i]_q$. Inspired by this, define
	\[ \binom{n}{k}_q = \frac{[n]_q!}{[k]_q![n-k]_q!}. \]
	This is clearly a rational function of $q$. It turns out that this is a polynomial in $q$! For example,
	\[ \binom{5}{2}_q = \frac{[5]_q[4]_q}{[2]_q[1]_q} = 1 + q + 2q^2 + 2q^3 + 2q^4 + q^5 + q^6. \]

	Recall that
	\[ \binom{n}{k} = \binom{n-1}{k-1} + \binom{n-1}{k}. \]


	% \begin{exerc}
	% 	Show that
	% 	\[ \binom{n}{k}_q = q^k \binom{n-1}{k}_q + \binom{n-1}{k-1}_q = \binom{n-1}{k}_q + q^{n-k} \binom{n-1}{k-1}_q . \]
	% \end{exerc}
	\begin{fprop}[$q$-Pascal's recurrences]
		It holds that
		\[ \binom{n}{k}_q = q^k \binom{n-1}{k}_q + \binom{n-1}{k-1}_q = \binom{n-1}{k}_q + q^{n-k} \binom{n-1}{k-1}_q . \]
	\end{fprop}
	\begin{proof}
		We show only the first recurrence. The second follows similarly.
		\begin{align*}
			q^k \binom{n-1}{k}_q + \binom{n-1}{k-1}_q &= q^k \frac{[n-1]_q!}{[k]_q! [n-k-1]_q!} + \frac{[n-1]_q!}{[k-1]_q![n-k]_q!} \\
				&=  q^k \binom{n}{k}_q \frac{[n-k]_q}{[n]_q} + \binom{n}{k}_q \frac{[k]_q}{[n]_q} \\
				&= \binom{n}{k}_q \left( \frac{q^k[n-k]_q + [k]_q}{[n]_q} \right) = \binom{n}{k}_q. 
		\end{align*}
	\end{proof}

	\begin{fcor}
		$\binom{n}{k}_q$ is a polynomial in $q$ with non-negative coefficients.
	\end{fcor}
	It turns out that the coefficients of the polynomial are unimodal and symmetric! We do not prove this, the reader can see \_ for more details.
	% zeinberger, AMM (katyohara?) !!!*** ADD CITATION ***!!!

	% sperner's theorem(?) : maximal UNIQUE antichain is the binom(n)(n/2) in the middle of the poset

	A natural question to ask then is: what do the coefficients of this polynomial count?\\
	Let $\binom{n}{k}_q = f_{n,k}(q) = \sum_{r \ge 0} a_{n,k}^{(r)} q^r$.
	Can we have
	\[ \binom{n}{k}_q = \sum_{T \in \binom{[n]}{k}} q^{\operatorname{parameter}(T)}? \]
	$a_{n,k}^{(r)}$ then just counts the number of $T$ with the given parameter value.\\
	Recall that $\binom{n}{k}$ is the number of paths from $(0,0)$ to $(n-k,k)$ if only upwards and rightwards movements on the integer lattice $\Z^2$ are allowed. Let $P$ be such a path.\\
	% \prod q^{(x_{i+1}-x_i-1)}
	% number partitions -- ``ferrer's diagram''
	Consider the portion of the box above $P$. This can be viewed as the Ferrer diagram of some number partition $\lambda(P)$. $\lambda(P)$ has at most $k$ parts, and no part is of size more than $n-k$. In fact, \emph{all} such partitions correspond to some path!\\
	What number is $\lambda(P)$ a number partition of? Denote this number as $|\lambda(P)|$. Let $\mathcal{S}_{n,k}$ be the set of all paths of the mentioned form. 

	\begin{ftheo}
		\[ \sum_{P \in \mathcal{S}_{n,k}} q^{|\lambda(P)|} = \binom{n}{k}_q. \]
	\end{ftheo}
	Perhaps surprisingly, the proof of the above is near-straightforward using the $q$-Pascal recurrence -- merely consider two cases depending on whether the first step of the path is right or upwards.

\subsection{Derivative polynomials}

	We begin this section by recalling the following rather interesting result.\\
	Define the \emph{Bell polynomial} $B_{n,k}$ by
	\[ B_{n,k}(x_1,x_2,\ldots,x_{n-k+1}) = \sum \frac{n!}{j_1! (1!)^{j_1} j_2! (2!)^{j_2} \cdots j_{n-k+1}! ((n-k+1)!)^{n-k+1}} \cdot x_1^{j_1} x_2^{j_2} \cdots x_{n-k+1}^{j_{n-k+1}}, \]
	where the summation is taken over all indices $j_1,\ldots,j_{n-k+1}$ of non-negative integers such that
	\begin{align*}
		k &= j_1 + j_2 + \cdots + j_{n-k+1} \text{ and} \\
		n &= j_1 + 2j_2 + 3j_3 + \cdots + (n-k+1)j_{n-k+1}.
	\end{align*}
	This has a natural correspondence to the Stirling numbers of the second kind, with $j_i$ representing the number of partitions of size $i$. In particular, the sum of coefficients of $B_{n,k}$ is $S_{n,k}$.

	\begin{fprop}[Fa\`{a} di Bruno's Formula,\cite{faadibruno}]
		\[ D^n f(g(x)) = \sum f^{(k)}(g(x)) \cdot B_{n,k} (g'(x), g''(x), \ldots, g^{(n-k+1)}(x)). \]
	\end{fprop}

	To illustrate this better, let us look at the first few derivatives explicitly. Dropping the $(x)$ on the right to make the notation more succinct, we have
	\begin{align*}
		Df(g(x)) &= f'(g) g' \\
		D^2f(g(x)) &= f''(g) (g')^2 + f'(g) g'' \\
		D^3f(g(x)) &= f'''(g) (g')^3 + 3 f''(g) g' g'' + f''(g) g'''.
	\end{align*}
	Consider the partitions of $\{1,2,3\}$, given by $1|2|3$, $12|3$, $13|2$, $23|1$, and $123$. The number of partitions of $[n]$ with $n_i$ parts of size $i$ for each $i$ neatly corresponds to the coefficient of $\prod_i (g^{(i)})^{n_i}$!

	% Faa di Bruno's formula
	% Df(g(x)) = f'(g) g'
	% D^2 = f''(g)(g')^2 + f'(g)g''
	% D^3 = f'''(g) (g')^3 + 3 f''(g)(g')(g'') + f''(g)g''' -- 1|2|3 ; 12|3 13|2 12|3 ; 123
	% coefficients relate to Bell numbers!
	% even a multivariate version that relates to multivariate partitions (?)

	Let $y = f(x)$. If $Dy = p(f(x))$ for some polynomial $p$, then $D^ny$ is a polynomial of $f$ as well.\\
	Suppose that $D^ny = p_n(y)$ for some sequence of polynomials $(p_n)$.
	% \begin{exerc}
	% 	Show that
	% 	\begin{align*}
	% 		p_0(y) &= y \\
	% 		p_n(y) &= \begin{cases} y & n=0 \\ p_{n-1}(y) \cdot p_1(y) & n \ge 1. \end{cases}
	% 	\end{align*}
	% \end{exerc}
	It is straightforward to see that
	\begin{align*}
		p_0(y) &= y \\
		p_n(y) &= \begin{cases} y & n=0 \\ p_{n-1}(y) \cdot p_1(y) & n \ge 1. \end{cases}
	\end{align*}


	For the remainder of this section, set $y = \tan x$ and $z = \sec x$. Then, $Dy = 1+y^2 = z^2$ and $Dz = yz$. It is not difficult to see that
	\begin{align*}
		D^2y &= 2yz^2 \\
		D^3y &= 4y^2z^2 + 2z^4 \\
		D^4y &= 8y^3z^2 + 16yz^4
	\end{align*}

	\begin{exercise}
		With $y,z$ defined as above, show that
		\begin{enumerate}
			\item $D^ny$ is a homogeneous polynomial in $y,z$ of degree $(n+1)$.
			\item $D^ny$ has only terms with even exponents of $z$.
		\end{enumerate}
	\end{exercise}

	\begin{fcor}
		We can write $D^ny = \sum_{k=0}^{\lfloor (n-1)/2 \rfloor} W_{n,k} z^{2k+2} y^{n-2k-1}$.
	\end{fcor}

	% \begin{exerc}
	% 	Prove or disprove that
	% 	\[ \sum W_{n,k} = n!. \]
	% \end{exerc}
	Again, we ask the question: is there some parameter on $\pi \in \mathfrak{S}_n$ such that
	\[ W_n(x) = \sum_{k = 0}^{\lfloor (n-1)/2 \rfloor} W_{n,k} x^k = \sum_{\pi \in \mathfrak{S}_n} x^{\operatorname{parameter}(\pi)}? \]

	\begin{fdef}[Peak]
		Given a permutation $\pi \in \mathfrak{S}_n$, we say that $i \in [n] \setminus \{1,n\}$ is a \emph{peak} of $\pi$ if $\pi_i > \pi_{i-1}$ and $\pi_i > \pi_{i+1}$. Denote the set of peaks of $\pi$ by $\Peak(\pi)$, $\pk(\pi) = |\Peak(\pi)|$ the number of peaks.
	\end{fdef}

	\begin{lemma}
		\label{lem: Wnk recurrence}
		For $n,k \ge 1$,
		\[ W_{n,k} = (2k+2) W_{n-1,k} + (n-2k) W_{n-1,k-1}. \]
	\end{lemma}
	\begin{proof}
		We have
		\begin{align*}
			D^{n}y &= D \sum_{k=0}^{\lfloor (n-2)/2 \rfloor} W_{n-1,k} z^{2k+2} y^{n-2k-2} \\
				&= \sum_{k=0}^{\lfloor (n-2)/2 \rfloor} (2k+2) W_{n-1,k} z^{2k+1} \cdot zy \cdot y^{n-2k-2} + (n-2k-2) W_{n-1,k} z^{2k+2} y^{n-2k-3} \cdot z^2 \\
				&= \sum_{k=0}^{\lfloor (n-2)/2 \rfloor} (2k+2) W_{n-1,k} z^{2k+2} y^{n-2k-1} + (n-2k-2) z^{2k+4} y^{n-2k-3}.
		\end{align*}
		The required follows.
	\end{proof}

	\begin{ftheo}
		\[ W_n(x) = \sum_{\pi \in \mathfrak{S}_n} x^{\pk(\pi)}. \]
	\end{ftheo}
	\begin{proof}
		Let $Y_n$ be the polynomial on the right, and let $Y_{n,k}$ be its coefficients. It is easily checked that $Y_{n,k}$ and $W_{n,k}$ are equal for $n=0$ or $k=0$. To prove the statement, we shall merely show that $Y_{n,k}$ satisfies the recurrence of \Cref{lem: Wnk recurrence} too.\\
		Similar to what we did in earlier proofs such as those of \Cref{prop: inv n,prop: maj n}, let $\sigma$ be a permutation in $\mathfrak{S}_{n-1}$.\\ We shall use it to get a permutation $\pi \in \mathfrak{S}_n$ by ``inserting'' $n$ at one of the $n$ possible positions. If we insert it at the position of a non-peak of $\sigma$, the number of peaks increases by one. If we insert it before or after the position of a peak, the number of peaks stays the same. Since peaks cannot occur immediately after each other, we can insert it at precisely $2k+2$ positions while ensuring that the number of peaks does not increase (the extra $2$ is for the extreme positions), and so at $n-2k-2$ positions which increases the number of peaks by one. Therefore,
		\[ Y_{n,k} = (2k+2)Y_{n-1,k} + (n-2(k-1)-2)Y_{n-1,k-1} = (2k+2) Y_{n-1,k} + (n-2k)Y_{n-1,k-1}. \qedhere \]
	\end{proof}

	\begin{fcor}
		It is true that
		\[ \sum_k W_{n,k} = n!. \]
	\end{fcor}

	% \begin{exerc}
	% 		\item Show that
	% 		\[ W_{n,k} = \_ W_{n-1,k} + \_ W_{n-1,k-1}. \]
	% \end{exerc}

	% z = sec x, Dz = yz.

\subsection{Matching theory}

	\begin{fdef}[Matching]
		Given a graph $G = (V,E)$, a \emph{matching} in $G$ is a collection $M \subseteq E$ of edges such that for any distinct $e_1,e_2 \in M$, $e_1 \cap e_2 = \emptyset$.\\
		The number of $k$-sized matchings is denoted $m_k(G)$. Define the \emph{matching polynomial}
		\[ \Match_G(x) = \sum_{k \ge 0} (-1)^k m_k(G) x^{n-2k} \]
		% \[ \Match_G(x) = \sum_{k \ge 0} m_k(G) x^{k}. \]
	\end{fdef}
	Some books call the above the ``defect'' matching polynomial, taking the actual matching polynomial as $p(x) = \sum_k m_k(G) x^k$. Note that $\Match_G(x) = x^n p(-1/x^2)$. 
	% Some authors also define the polynomial as
	% \[ N_G(x) = \sum_{k \ge 0} (-1)^k m_k(G) x^{n-2k}. \]
	
	Clearly, $\Match_G(x) = x^n \cdot p(-1/x^2)$.\\

	There is a very rich literature regarding matching theory. One work that set off a frenzy of results in related areas was \cite{Edmonds1965MaximumMA}, which gave a polynomial-time algorithm to get a maximum weight matching in any graph. It does so by looking at the polytope in $\R^{E}$ that is the convex hull of the indicator functions of all matchings.
	It is worth noting that while there is a polynomial time algorithm to find a maximum weight matching, the problem of determining the number of maximum matchings in a graph is \textsf{\#P}-complete. Consequently, no polynomial time algorithm is known to determine $m_k(G)$ given a graph $G$.\\

	Before moving on, we give some simple lemmas about the matching polynomial.
	\begin{flem}
		\label{lem: matching polynomial basic results}
		\phantom{pain}
		\begin{enumerate}[label=(\alph*)]
			\item If $G$ and $H$ are vertex-disjoint graphs,
			\[ \Match_{G \cup H}(x) = \Match_G(x) \Match_H(x). \]
			\item Given a graph $G$ and vertex $v \in G$,
			\[ \Match_G(x) = x \Match_{G - \{v\}}(x) - \sum_{u : u \adj v} \Match_{G - \{u,v\}} (x). \]
			\item Given a graph $G$ and edge $e = \{u,v\} \in G$,
			\[ \Match_G(x) = \Match_{G-e}(x) - \Match_{G-\{u,v\}}(x). \]
		\end{enumerate}
	\end{flem}
	\begin{proof}
		We omit the proof of (a) as it is straightforward.
		\begin{itemize}
			\item[(b)] Let $M$ be a matching of size $k$ on $G$. If $M$ does not have an edge incident on $v$, it is a matching of size $k$ on $G - \{v\}$. Otherwise, there is some edge $e = \{u,v\} \ni M$, and $M \setminus \{e\}$ is a matching on $G - \{u,v\}$. As a result,
			\[ m_k(G) = m_k(G- \{v\}) + \sum_{u : u \adj v} m_{k-1}(G-\{u,v\}). \]
			Multiplying with $(-1)^k x^{n-2k}$ and summing over $k$,
			\begin{align*}
				\Match_G(x) &= \sum_k (-1)^k x \cdot x^{(n-1)-2k} m_k(G - \{v\}) - \sum_{u : u \adj v} (-1)^{k-1} x^{(n-2)-2(k-1)} m_k(G - \{u,v\}) \\
					&= x\Match_{G-\{v\}} - \sum_{u : u \adj v} \Match_{G - \{u,v\}} (x).
			\end{align*}
			\item[(c)] Similar to (b), let $M$ be a matching of size $k$ on $G$. If $M$ does not have $e$, it is a matching of size $k$ on $G - e$. Otherwise, $M \setminus \{e\}$ is a matching on $G - \{u,v\}$. So,
			\[ m_k(G) = m_k(G - e) + m_{k-1}(G - \{u,v\}). \]
			Multiplying with $(-1)^k x^{n-2k}$ and summing over $k$,
			\begin{align*}
				\Match_G(x) &= \sum_k (-1)^k x^{n-2k} m_k(G-e) - (-1)^{k-1} x^{(n-2)-2(k-1)} m_{k-1}(G-\{u,v\}) \\
					&= \Match_{G-e}(x) - \Match_{G-\{u,v\}}(x). \qedhere
			\end{align*}
		\end{itemize}
	\end{proof}


	\begin{fprop}
		\phantom{pain}
		\begin{enumerate}
			\item $m_k(P_n) = \binom{n-k}{k}$.
			\item $m_k(C_n) = \frac{n}{n-k} \binom{n-k}{k}$.
			\item $m_k(K_n) = \binom{n}{2k} \cdot \frac{(2k)!}{2^kk!}$.
			\item $m_k(K_{n,n}) = \binom{n}{k}^2 k!$.
		\end{enumerate}
	\end{fprop}
	\begin{proof}
		\phantom{pain}
		\begin{enumerate}
			\item Collapse every edge in a matching to its left endpoint, and ``mark'' the collapsed vertices. This results in a path with $n-k$ vertices with $k$ marked vertices. This process of marking the vertices using the matching is reversible, and $m_k(G) = \binom{n-k}{k}$.
			\item Fix some edge $e$. $e$ is absent in exactly $(n-k)/n$ of the $k$-matchings of $C_n$. In this case, the remaining matching forms a matching on $C_n - e$, which is isomorphic to $P_n$. Therefore, $(n-k)/n m_k(C_n) = m_k(P_n) = \binom{n-k}{k}$.
			\item A $k$-matching of $K_n$ is obtained by choosing $2k$ vertices (done in $\binom{n}{2k}$) ways, putting the $2k$ vertices in $k$ indistinguishable ``boxes'' by putting $2$ in each (this can be done in $(2k)!/k!2^k$ ways).
			\item A $k$-matching is obtained by choosing $k$ vertices from each side of the bipartite graph (done in $\binom{n}{k}^2$ ways), then assigning each vertex on the left side a vertex on the right that it is joined to in the matching (done in $k!$ ways). \qedhere
		\end{enumerate}
	\end{proof}

	% \begin{exerc}
	% 	Show that
	% 	\begin{enumerate}
	% 		\item $m_k(C_n) = n/(n-k) \binom{n-k}{k}$.
	% 		\item $m_k(K_n) = \binom{n}{2k} \cdot (2k!)/(2^k k!)$.
	% 		\item $m_k(K_{n,n}) = \binom{n}{k} k!$.
	% 	\end{enumerate}
	% \end{exerc}

	% \begin{exerc}
	% 	Given a graph $G$ and edge $e \in G$,
	% 	\[ \Match_G(x) = ? \]
	% \end{exerc}

	\begin{ftheo}
		\label{theo: roots of matching polynomial real}
		Given a graph $G$, all roots of $\Match_G(x)$ are real.
	\end{ftheo}
	The version of the proof of the above we give is due to Godsil \cite{godsil-matching-poly-real-roots}.
	\begin{proof}
		Using \Cref{lem: matching polynomial basic results}(a), we may assume that $G$ is connected.\\
		We first prove the result for the case where $G$ is a tree $T$. To prove this, we shall prove that $\Match_T(x)$ is the characteristic polynomial $\det(xI-A)$ of the adjacency matrix $A$ of $T$(!); the result then follows since $A$ is a real symmetric matrix and thus has real eigenvalues.\\
		Let $xI - A = (b_{ij})$. We have
		\[ \Charpoly(A) = \sum_{\pi \in \mathfrak{S}_n} \sign(\pi) \prod_{i=1}^n b_{i\pi(i)}. \]
		First, we claim that if $\pi \in \mathfrak{S}_n$ has a cycle of length greater than $2$, then the term corresponding to $\pi$ on the right will be zero. In other words, the term is zero if $\pi$ is not an involution. Indeed, this follows immediately since $G$ has no cycles (of length $\ge 3$). As a result, if $(i_1,i_2,\ldots,i_t)$ were a cycle in $\pi$, then there must be some $j$ such that $\{i_j i_{j+1}\}$ is not an edge in $G$ and $b_{i_j \sigma(i_j)} = 0$.\\
		Suppose that some $\pi \in \mathfrak{S}_n$ has $k$ $2$-cycles and $(n-2k)$ fixed points, and also has the term on the right being nonzero. We have $\sign(\pi) = (-1)^{(n- (k + n-2k))} = (-1)^k$. Suppose that the $k$ $2$-cycles are $(i_1,j_1),(i_2,j_2),\ldots,(i_k,j_k)$. We have $b_{i_rj_r} = b_{j_ri_r} = (-1)$ so $b_{i_rj_r}b_{j_ri_r} = 1$, and also that no $i_r$ (or $j_r$) is equal to any other $i_s$ (or $j_s$). That is, the edges constituted by $\{i_r,j_r\}$ form a matching of size $k$! Therefore,
		\[ \Charpoly(A) = \sum_{\substack{\pi \in \mathfrak{S}_n \\ \text{$\pi$ an involution}}} \sign(\pi) \prod_{i=1}^n b_{i\pi(i)} = \sum_{\substack{\pi \in \mathfrak{S}_n \\ \text{$\pi$ an involution}}} (-1)^k x^{n-2k} = \sum_{\text{matchings $M$}} (-1)^{|M|} x^{n-2|M|} = \Match_T(x). \]

		For a general graph, we come up with a tree $T_a(G)$ that depends on a ``starting vertex'' $a \in G$. We then show that the matching polynomial of our graph divides the matching polynomial of the tree.\\
		To define $T_a$, we need paths starting at $a$ in $G$ without repeated vertices. These paths are the vertices of $T_a(G)$. There is an edge between two paths if one is an extension of another by a single vertex -- for example, the paths $abdc$ and $abdce$ would have an edge between them.\\
		It is straightforward to see that $G$ is isomorphic to $T_a(G)$ for any vertex $a \in G$ if $G$ is a tree. Indeed, there is precisely one path from $a$ to any vertex $b$ in the tree.
		% possibly insert diagram of the graph given at http://www.math.iitb.ac.in/~krishnan/phd-2022/matching-poly.pdf
		The heart of the argument is the fact that for any $a\in G$,
		\begin{equation}
			\frac{\Match_{G - a}(x)}{\Match_G(x)} = \frac{\Match_{T_a(G)-a}(x)}{\Match_{T_a(g)}(x)}. \label{eqnmatch1}
		\end{equation}
		To prove this, we use induction on the number of vertices $n$. The base case is $n=2$, which forces $G$ to be a tree. Now,
		\begin{align*}
			\frac{\Match_G(x)}{\Match_{G-a}(x)} &= \frac{x\Match_{G-a}(x) - \sum_{b\adj a} \Match_{G-a-b}(x)}{\Match_{G-a}(x)} \\
				&= x - \sum_{b \adj a} \frac{\Match_{G-a-b}(x)}{\Match_{G-a}(x)}.
		\end{align*}
		By the inductive hypothesis,
		\begin{equation}
			\frac{\Match_{G-a-b}(x)}{\Match_{G-a}(x)} =  \frac{\Match_{T_b(G-a)-b}(x)}{\Match_{T_b(G-a)}(x)}. \label{eqnmatch2}
		\end{equation}
		Now, very carefully observe that
		\begin{align*}
			T_b(G-a)-b &= \bigcup_{\substack{c \adj b \\ c \ne a}} T_c(G-a) \\
			T_a(G)-a &= \bigcup_{c\adj a} T_c(G-a) \\
			T_a(G)-a-ab &= \left(\bigcup_{\substack{c\adj a \\ a \ne b}} T_c(G-a)\right) \cup \left(\bigcup_{\substack{c\adj b \\ c \ne a}} T_c(G-a-b)\right) = \left(\bigcup_{\substack{c\adj a \\ a \ne b}} T_c(G-a)\right) \cup \left(T_b(G-a)-b\right)
		\end{align*}

		We can then use \Cref{lem: matching polynomial basic results}(a) to get that
		\begin{align*}
			\Match_{T_a(G)-a}(x) &= \prod_{c\adj a} \Match_{T_c(G-a)}(x). \\
			\Match_{T_a(G)-a-ab}(x) &= \prod_{\substack{c \adj a \\ c \ne b}} \Match_{T_c(G-a)}(x) \times \Match_{T_b(G-a)-b}(x).		
		\end{align*}
		Dividing the two,
		\begin{equation}
			\frac{\Match_{T_a(G)-a-ab}(x)}{\Match_{T_a(G)-a}(x)} = \frac{\Match_{T_b(G-a)-b}(x)}{\Match_{T_b(G-a)}}. \label{eqnmatch3}
		\end{equation}
		Combining \Cref{eqnmatch2,eqnmatch3},
		\[ \frac{\Match_{G-a-b}(x)}{\Match_{G-a}(x)} = \frac{\Match_{T_a(G)-a}(x)}{\Match_{T_a(G)-a-ab}(x)} \]
		and
		\begin{align*}
			\frac{\Match_G(x)}{\Match_{G-a}(x)} &= x - \sum_{b\adj a} \frac{\Match_{T_a(G)-a-ab}(x)}{\Match_{T_a(G)-a}}(x) \\
				&= \frac{ x\Match_{T_a(G)-a}(x) - \sum_{b \adj a} \Match_{T_a(G)-a-ab}(x) }{\Match_{T_a(G)-a}(x)} \\
				&= \frac{\Match_{T_a(G)}(x)}{\Match_{T_a(G)-a}(x)}. & \text{(by \Cref{lem: matching polynomial basic results}(b))}
		\end{align*}

		Now, to complete the proof, we shall show that $\Match_{T_a(G)}(x)$ divides $\Match_{G}(x)$. We do so by induction. To do this, by \Cref{eqnmatch1}, it suffices to show that $\Match_{G-a}(x)$ divides $\Match_{T_a(G)-a}(x)$. Recalling that $T_a(G)-a = \bigcup_{b \adj a} T_b(G-a)$, the inductive hypothesis implies that $\Match_{G-a}(x)$ divides each $\Match_{T_b(G-a)}(x)$, so divides their product $\Match_{T_a(G)-a}(x)$ as well, completing the proof.
	\end{proof}

	% QUIZ 1 ON 1 SEP (THURSDAY)
	
	This result has some consequences.

	\begin{fdef}[Log-concave]
		A sequence $(a_n)_{n\ge0}$ is said to be \emph{log-concave} if $a_n^2 \ge a_{n-1} a_{n+1}$ for all $n$.
	\end{fdef}

	\begin{fex}
		For a fixed $n$, $\binom{n}{k}$ as $k$ varies is log-concave. Indeed,
		\[ \binom{n}{k}^2 = \frac{(n!)^2}{(k!)!((n-k)!)^2} \ge \frac{(n!)^2}{(k-1)!(k+1)! \cdot (n-k-1)! (n-k+1)!} = \binom{n}{k-1} \binom{n}{k+1}. \]
	\end{fex}

	% \begin{exerc}
	% 	Show that for a fixed $n$, $\binom{n}{k}$ as $k$ varies is log-concave.
	% \end{exerc}

	The Stirling numbers of the first and second kind are also log-concave.

	\begin{fprop}
		If $A(x) = \sum_{i=0}^n a_i x^i$ is a polynomial with all real roots, then the sequence of coefficients of $A$ is log-concave.
	\end{fprop}

	\begin{exercise}
		Prove the above.
	\end{exercise}

	The above has an even stronger version.

	% add citation for this!
	\begin{fprop}
		If $A(x) = \sum_{i=0}^n a_i x^i$ is a polynomial with all real roots, then $\left(a_i/\binom{n}{i}\right)_{i \ge 0}$ is log-concave. This is referred to as \emph{ultralogconcavity}.
	\end{fprop}

	\begin{fcor}
		For any graph $G$, $(m_k(G))_{k\ge 0}$ is log-concave. That is, for all $k$, $m_k(G)^2 \ge m_{k-1}(G)m_{k+1}(G)$.
	\end{fcor}

	% log-concavity is important! june huh won the fields medal this year for showing that some sequence is log-concave

	% convex hull of (01) vectors of matchings in R^{|E|} due to edmonds. this is linear program, so we can get a non-linear programming way. this gives a method to get a maximum weight matching!!! (place any weights you want on edges)
	% counting number of matchings is #P-complete though.



\subsection{Colorings}

	\begin{fdef}
		Given a graph $G=(V,E)$, a $k$-\emph{coloring} (sometimes called \emph{proper coloring}) is a function $c:V(G)\to[k]$ such that if $u\adj v$, $c(u) \ne c(v)$.\\
		The \emph{chromatic number} $\chi(G)$ of a graph is the minimum number of colours required to colour it.
		We denote by $c_k(G)$ the number of $k$-colorings of $G$.
	\end{fdef}

	Determining the chromatic number of a graph is (or rather, determining if there exists a $k$-coloring) is $\mathsf{NP}$-hard. The best known algorithm today outputs a colouring which is a $n/\text{polylog}(n)$-approximation of the minimum coloring.

	\begin{prop}
		A graph $G$ has chromatic number $1$ iff it is an empty graph. It has chromatic number $\le 2$ iff it is bipartite.
	\end{prop}

	It is difficult to approximate a minimum colouring of even $3$-colorable graphs!

	\begin{ftheo}[Four-Color Theorem, \cite{4ct}]
		A planar graph is $4$-colorable.
	\end{ftheo}
	We omit the proof of the above (for reasons obvious to anyone familiar with the result).

	\begin{ftheo}
		For any graph $G$, there exists a polynomial $\Chrom_G$, known as the \emph{chromatic polynomial}, such that $\Chrom_G(k) = c_k(G)$.
	\end{ftheo}
	For example, $\Chrom_{\overline{K_n}}(x) = x^n$. For any tree $T$ on $n$ vertices, $\Chrom_T(x) = t(t-1)^{n-1}$.\\
	Observe that the chromatic polynomial is unique for a given graph since we know its value at an infinite number of points.
	
	The proof of the above follows near-directly from the following result using an inductive argument on the number of edges -- both $G\setminus E$ and $G-e$ have fewer edges than $G$.

	\begin{fprop}[Deletion-contraction recurrence]
		\label{prop: deletion contraction recurrence}
		For any graph $G$, we have for $e \in G$ that
		\[ \Chrom_G(x) = \Chrom_{G-e}(x) - \Chrom_{G\setminus e}(x) \]
	\end{fprop}
	\begin{proof}
		Take any $k$-coloring of $G-e$. If the endpoints of $e$ have the same colour, it corresponds to a $k$-colouring of $G\setminus e$, and if the endpoints have distinct colours, it corresponds to a $k$-coloring of $G$. Therefore,
		\[ c_k(G) = c_k(G-e) = c_k(G\setminus e) \]
		and the result follows.
	\end{proof}
	This leads to a method to find the chromatic polynomial of any graph. Since we know the chromatic polynomial of the empty graph, we can repeatedly delete and contract edges until from our graph until we get to an empty graph.\\
	A natural question based on what we've done so far is: what do the coefficients of the chromatic polynomial mean?
	% We state some known results about the chromatic polynomial.

	% http://www.math.iitb.ac.in/~krishnan/phd-2022/nbc.pdf
	\begin{fdef}
		Let $G = (V,E)$ be a graph and $<$ a total order on $E$. Given a cycle $C$, the corresponding \emph{broken circuit} $B$ is given by $E(C) \setminus \{e\}$, where $e$ is the smallest edge in $E(C)$ in the total order. A set $A$ of edges is said to be an \emph{NBC set} (no broken circuit) if $B \not\subseteq A$ for any broken circuit $B$. Also let
		\[ \NBC_k(G) = \{ A \subseteq E : |A| = k \text{ and $A$ is an NBC set} \} \]
		and $\nbc_k(G) = |\NBC_k(G)|$.\\
	\end{fdef}

	\begin{ftheo}
		\label{theo: coeffs of chrom poly nbc}
		If $|V| = n$, then for any ordering of $E$,
		\[ \Chrom_G(t) = \sum_{k=0}^n (-1)^k \nbc_k(G) t^{n-k}. \]	
	\end{ftheo}
	\begin{proof}
		Fix some $t$. For each $A \in \NBC_k(A)$, consider the corresponding subgraph with edge set $A$. This describes a forest on $V$ with $n-k$ components. The number of functions $c : V \to [t]$ such that $c$ is constant on components of $A$ is $t^{n-k}$. Call such a coloring an $A$-improper coloring. For each such pair $(A,c)$, assign the sign $\sign(A,c) = (-1)^k$. Denote the set of all such pairs by $S$. \\
		We would like to show that
		\[ \sum_{(A,c) \in S} (-1)^{\sign(A)} = \Chrom_G(t) = c_t(G). \]
		Observe that $(\emptyset,c) \in S$ for any proper coloring $c$, so it suffices to show that the summation of the remaining terms is $0$. Call this set of remaining terms $S'$. We shall come up with an sign-reversing involution $\iota$ on $S'$ to prove that the sum of signs is $0$.\\
		Observe that given any $(A,c) \in S'$, there must exist edges that are monochromatic. Let $e$ be the smallest such edge, and let $\iota(A,c) = (A\triangle \{e\},c) = (A',c)$. It is evident that $\iota$ is sign-reversing, and it is an involution because $c$ does not change, so the smallest monochromatic edge $e$ does not either. We are done if we manage to show that the expression on the right is indeed in $S$.\\
		If $A' = A \setminus \{e\}$, then it is clearly an NBC set and the coloring is $A'$-improper (since it is $A$-improper). If $A' = A \cup \{e\}$, since $e$ joined two vertices of the same color, $c$ is $A'$-improper. Suppose instead that $A'$ is not an NBC set. Then, it contains a broken circuit $B$ such that $e \in B$. Let $C$ be the cycle causing $B$ to be a broken circuit. Because $c$ is $A'$-improper, all vertices in $C$ have the same colour. However, $e$ is the smallest monochromatic edge in $C$, contradicting the fact that a smaller edge was removed to get $B$ and completing the proof.
	\end{proof}

	\begin{fcor}
		$\Chrom_G$ is a monic polynomial with coefficients of alternating sign.
	\end{fcor}

	Another question (that is not so natural) is: is $\Chrom_G(x)$ meaningful for $x\not\in\N$?

	\begin{fdef}
		Given a graph $G = (V,E)$, an \emph{acyclic orientation} of $G$ is obtained by replacing each edge $uv$ with one of the directed arcs $\vv{uv}$ or $\vv{vu}$.
	\end{fdef}

	\begin{ftheo}
		$\Chrom_G(-1) = (-1)^n a(G)$, where $n = |V(G)|$ and $a(G)$ is the number of acyclic orientations of $G$.
	\end{ftheo}
	Also observe that by \Cref{theo: coeffs of chrom poly nbc}, $a(G)$ is equal to the number of NBC sets in $G$.
	\begin{proof}
		Let $e=\{u,v\}$ be an arbitrary edge in the graph. Using the \nameref{prop: deletion contraction recurrence}, it suffices to show that
		\[ a(G) = a(G-e) + a(G\setminus e). \]
		Let $A(G)$ be the set of acyclic orientations on $G$, so $a(G) = |A(G)|$.\\
		Define $f : A(G) \to A(G-e)$ as the natural restriction map. We claim that $f$ is surjective.\\
		Suppose instead that some $O' \in A(G-e)$ is not in the image of $f$. Consider the two orientations $O_1,O_2$ which are identical to $O'$ except that the edge $e$ has orientation $u\to v$ or $v\to u$ respectively. Since neither of these is in $A(G)$, there must be a directed path $v \to u$ in $O'$ (because $O_1$ has a cycle) and another directed path $u \to v$ in $O'$ (because $O_2$ has a cycle). Concatenating the two, we get a directed closed walk which must contain a cycle, contradicting the fact that $O' \in A(G-e)$.\\
		
		Because $f$ is a restriction map, for any $O' \in A(G-e)$, $|f^{-1}(O')| \in \{1,2\}$. Let $X$ and be the set of all $O'$ with $f^{-1}(O') = 1$ and $Y$ the set of all $O'$ with $f^{-1}(O') = 2$. Also let $x = |X|$ and $y = |Y|$.\\
		We have $a(G-e) = x+y$ and $a(G) = x+2y$, so we are done if we show that $a(G\setminus e) = y$.\\

		Because we can orient $e$ in either way for any $O' \in A(G-e)$ to get an orientation in $A(G)$, there is no directed path from $u$ to $v$ or $v$ to $u$ in $O'$. In particular, when merging $u$ and $v$ in $O'$ to get an orientation of $A(G\setminus e)$, there is no issue in assigning orientations (there cannot be a vertex $w$ such that $\vv{uw}$ and $\vv{wv}$ are edges).\\
		This merging procedure can be reversed as well, so there is a bijection between $Y$ and $A(G\setminus e)$ and we are done.
	\end{proof}

	This idea of plugging negative values into polynomials of interest has led to the fascinating subject of combinatorial reciprocity. This includes the idea of ``running recurrences backward''. For example, we have the Fibonacci numbers defined by $f_0 = 0, f_1 = 1$, and $f_{n+1} = f_n + f_{n-1}$. Can we extend this to negative numbers such that $f_{m-1} = f_{m+1} - f_{m}$, where $m-1$ is negative. This leads to a signed version of the Fibonacci numbers, with $f_{-n} = (-1)^{n+1} f_n$ for $n > 0$.\\
	
	We encourage the reader to try \Cref{binomial recurrence backwards} to get that on running the binomial recurrence backwards (for negative $n$), one gets
	\[ \binom{-(n+1)}{k} = (-1)^k \binom{n+k}{k}. \]

	\begin{exercise}
		Run the recurrence of $S_{n,k}$ backwards (to negative $n,k$).
	\end{exercise}
	\begin{proof}
		We have $S_{n,k} = S_{n-1,k-1} + k S_{n-1,k}$. For negative $n$,
		\[ S_{-(n+1),k} = S_{-n,k+1} - (k+1) S_{-(n+1),k+1}. \]
		For $k=-1$, we get $S_{-(n+1),-1} = S_{-n,0}$. In particular, $S_{-1,-1} = 1$.
	\end{proof}

	The interested reader may refer to \cite{crt} for more details on reciprocity theorems.

\subsection{Increasing spanning forests}

	\begin{fdef}[Increasing spanning forest]
		Let $G = (V,E)$ and let the elements of $V$ be totally ordered. Let $F$ be a forest in $G$. Root each connected component $T$ of $F$ at its minimum vertex. $F$ is called an \emph{increasing spanning forest} if each tree is increasing, that is, the ``children'' of any vertex in the tree with respect to the rooting are larger than the vertex. Equivalently, any path from a root to a vertex in the tree is increasing.\\
		Let $\isf_m(G)$ be the number of increasing spanning forests on $G$ with $m$ edges, and define
		\[ \ISF_G(x) = \sum_{m \ge 0} (-1)^m \isf_m(G) x^{n-m}. \]
	\end{fdef}

	\begin{flem}
		\label{lemma: isf}
		Let $G = (V=[n],E)$ with the total order on $V$ being the natural order. For each $k \in V$, let
		\[ E_k = \{ \{i,k\} \in E : i<k \}. \]
		$F$ is an increasing spanning forest of $G$ iff it has at most one edge from each $E_k$. 
	\end{flem}
	Observe that the $E_k$ are mutually disjoint and their union is all of $E$.
	\begin{proof}
		Suppose that there are two edges $\{i,k\}$ and $\{j,k\}$ in some $E_k$ in an isf $E$, where $i<j$. Then, the root of the tree containing $\{i,j,k\}$ is at most $i$. In particular, one of the paths from this root to $i$ or $j$ must contain the subpath $ikj$ or $jki$, which contradicts the fact that it is increasing.\\
		
		On the other hand, let $F \subseteq E$ such that $|F \cap E_k| \le 1$ for each $k$.\\
		First, let us show that $F$ is acyclic. Suppose instead that $v_1v_2\cdots v_rv_1$ is a cycle, and let $v_j = \max_{1 \le i \le r} v_i$. Then, both $v_{j-1}v_j$ and $v_{j+1}v_j$ are edges in $E_{v_j}$, contradicting the fact that $|F \cap E_{v_j}| \le 1$.\\
		Now, we must show that it is increasing. Suppose instead that $v_1v_2\cdots v_r$ is a non-increasing path in $F$, with $v_1 \le v_i$ for $i > 1$, and that $v_{j-1} < v_j > v_{j+1}$. This again contradicts the fact that $|F \cap E_{v_j}| \le 1$, completing the proof.
	\end{proof}

	\begin{ftheo}
		\label{theo: isf}
		With $E_i$ defined as above,
		\[ \ISF_G(x) = \sum_{i=1}^n (x-|E_i|). \]
	\end{ftheo}
	\begin{proof}
		Let the polynomial on the right be $p$. Then, the coefficient of $x^{n-m}$ in $p$ is
		\[ \sum_{\{i_1,\ldots,i_m\} \subseteq [n]} |E_{i_1}| |E_{i_2}| \cdots |E_{i_m}|. \]
		This is precisely equal to $\isf_m(G)$ by \Cref{lemma: isf}.
	\end{proof}

	It has been observed that for certain classes of graphs and orderings, this is equal to the chromatic polynomial -- the interested reader may look at \cite{sagan} for more details.
	% combinatorics: the art of counting -- bruce sagan(?)

\subsection{Linear recurrences and rational generating functions}

	Consider sequences $(a_n)$ such that
	\[ A(x) = \sum a_n x^n = \frac{p(x)}{q(x)}, \]
	where $q$ is a polynomial of degree $d$ and $p$ is a polynomial of degree $<d$.	
	\begin{fdef}
		A sequence $(a_n)_{n \ge 0}$ of reals is said to satisfy a \emph{linear constant term recurrence} (of length $d$) if there exist complex numbers $c_1,\ldots,c_d$ with $c_d \ne 0$ such that
		\[ a_{n+d} + c_1 a_{n+d-1} + \cdots + c_d a_n = 0 \]
		for all $n \ge 0$.
	\end{fdef}

	A simple example of this is the recurrence satisfied by the Fibonacci numbers. Given $f_{n+2} - f_{n+1} - f_n = 0$, the recurrence is
	\[ F(x) = \frac{p(x)}{1-x-x^2}, \]
	where $p$ depends on the initial values. Observe that the coefficients $1,-1,-1$ in the denominator match those in the recurrence!

	\begin{ftheo}
		\label{theo: linear const term recurrence}
		Let $(a_n)_{n\ge 0}$ be a sequence with generating function $A$. The following are equivalent.
		\begin{enumerate}[label=(\alph*)]
			\item $(a_n)_{n \ge 0}$ satisfies a linear constant term recurrence of length $d$ with constants $c_1,\ldots,c_d$.
			\item There exist 
			\[ A(x) = \sum a_n x^n = \frac{p(x)}{q(x)}, \]
			where $q(x) = 1 + c_1x + \cdots + c_dx^d$ and $\deg(p) < d$.
			\item If the roots of the polynomial $q$ in (b) are $(1/r_i)_{i=1}^k$, with $(1/r_i)$ having multiplicity $d_i$, then there are polynomials $(p_i)_{i=1}^k$ of degree $<d_i$ such that
			\[ a_n = \sum_{i=1}^k p_i(n) r_i^n \]
			for all $n \ge 0$.
		\end{enumerate}
	\end{ftheo}
	\begin{proof}
		\phantom{pain}
		\begin{itemize}
			\item[(a)$\Rightarrow $(b)] Multiply the linear constant term recurrence by $x^{n+d}$ and sum over all $n \ge 0$. Setting $c_0 = 1$, we get
			\[ 0 = \sum_{t=0}^{d} c_t x^t \left( A(x) - \sum_{i=1}^{d-t-1} a_i x^i \right), \]
			so
			\[ A(x) = \frac{\sum_{t=0}^d c_t x^t \left( \sum_{i=1}^{d-t-1} a_i x^i \right) }{\sum_{t=0}^d c_t x^t} = \frac{p(x)}{q(x)}, \]
			where $\deg(p) < d$.

			\item[(b)$\Rightarrow$(a)] We have $q(x) A(x) = p(x)$. Because $\deg(p) < d$, the coefficient of $x^{n+d}$ on the right hand side is zero. On the left, this coefficient is precisely equal to the left hand side of the desired recurrence.

			\item[(b)$\Leftrightarrow$(c)] Let us check that (b) implies (c) first. We have
			\[ A(x) = \frac{p(x)}{\prod_{i=1}^k (1-r_ix)^{d_i}}. \]
			Checking that (c) holds true amounts to expanding the denominator to the numerator and matching coefficients. The argument is reversible as well, so (c) implies (b). \qedhere
		\end{itemize}
	\end{proof}

	Also observe that running a linear constant term recurrence backwards (extending it to negative $n$) gives another linear constant term recurrence!

	\begin{ftheo}
	 	Let $(a_n)_{n \ge 0}$ be a sequence satisfying a linear constant term recurrence. Obtain $a(-n)$ by running the recurrence backwards, and set
	 	\[ A^\mathsf{rev}(x) = \sum_{n \ge 1} a(-n) x^n. \]
	 	Then,
	 	\[ A^\mathsf{rev}(x) = -A\left( \frac{1}{x} \right). \]
	 \end{ftheo}
	 % proof in next class (this has been written 05-09-2022)
	 \begin{proof}
	 	
	 \end{proof}

	 There are numerous multivariate extensions of this proved by Stanley.

\subsection{Exponential Generating Functions}

	\begin{fdef}
		Given a sequence $(a_n)_{n \ge 0}$, its \emph{exponential generating function} (egf) is defined by
		\[ A(x) = \sum_{n\ge 0} \frac{a_n x^n}{n!}. \]
	\end{fdef}

	\begin{flem}
		\label{lem: product of egfs}
		If $A(x)$ and $B(x)$ are the egfs of $(a_n)$ and $(b_n)$ respectively, then $A(x)B(x)$ is the egf of $(c_n)_{n \ge 0}$ defined by
		\[ c_n = \sum_{k=0}^n \binom{n}{k} a_k b_{n-k}. \]
	\end{flem}
	The above is very simple to prove, and we omit the proof.

	Let us use the above to determine the egf for $d_n$, the number of derangements in $\mathfrak{S}_n$. Take by convention that $d_0 = 1$.
	\begin{prop}
		It is true that
		\[ \sum_{k=0}^n \binom{n}{k} d_{n-k} = n!. \]
	\end{prop}
	\begin{proof}
		Given a bijection $\pi \in \mathfrak{S}_n$, let $S \subseteq [n]$ be the set of fixed points $\{ i : \pi_i = i \}$ of the permutation. This results in a derangement of $[n] \setminus S$, and this idea results in a bijection between
		\[ \mathfrak{S}_n \text{ and } \{ (S,\sigma) : S \subseteq [n], \sigma\text{ is a derangement of $[n] \setminus S$} \}. \]
	\end{proof}

	\begin{fcor}
		The egf of $(d_n)_{n \ge 0}$ is equal to 
		\[ D(x) = \frac{1}{e^x(1-x)}. \]
	\end{fcor}
	\begin{proof}
		By the previous proposition,
		\[ n! = \sum_{k = 0} \binom{n}{k} \cdot d_{n-k} \cdot 1. \]
		The egf of the constant sequence $1$ is $e^x$ and the egf of $(n!)$ is $1/(1-x)$. By \Cref{lem: product of egfs}, $D(x) e^x = 1/(1-x)$, completing the proof.
	\end{proof}


	\begin{prop}
		If $(a_n)_{n \ge 0}$ has egf $A(x)$, then
		\[ A'(x) = \sum_{n \ge 0} a_n \frac{x^{n-1}}{(n-1)!}. \]
	\end{prop}

	We now encourage the reader to do \Cref{prob: euler numbers}.

\subsection{Another equidistributed pair of parameters}

	Recall how we had seen in \Cref{prop: maj n} a pair of parameters that have the same distribution. Now, we shall look at another such pair of parameters.\\
	Recall descents in $\mathfrak{S}_n$ from \Cref{def: descent}.\\
	\begin{fdef}[Eulerian polynomial]
		\label{def: eulerian poly}
		Define the \emph{Eulerian polynomial}
		\begin{equation}
			A_n(t) = \sum_{\pi \in \mathfrak{S}_n} t^{\des(\pi)}. \label{eulerian polynomial}
		\end{equation}
	\end{fdef}
	For example, $A_3(t) = 1+4t+t^2$. Let $A_{n,k}$ be the coefficient of $x^k$ in $A_n$ -- this is the number of $\pi \in \mathfrak{S}_n$ with $\des(\pi) = k$. One gets the recurrence
	\[ A_{n,k} = (k+1)A_{n-1,k} + (n-k)A_{n-1,k-1} \]
	for $n \ge 1$ with $A_{0,0} = 1$. This may be proved by the (hopefully) now standard trick of seeing how the number of descents changes on inserting $n+1$ at various positions in $\pi \in \mathfrak{S}_n$.\\

	% \begin{exerc}
	% 	Prove the above recurrence.
	% \end{exerc}
	Also observe that on reversing a permutation, we have $\des(\pi^\mathsf{rev}) = (n-1) - \des(\pi)$. This means that the coefficients of $A_n$ are palindromic. Further, descents and ``ascents'' are equidistributed.

	\begin{fdef}[Excedances]
		Given $\pi \in \mathfrak{S}_n$, define the set of \emph{excedances}
		\[ \EXC(\pi) = \{ i \in [n] : \pi_i > i \} \]
		and the number of excedances $\exc(\pi) = |\EXC(\pi)|$.
	\end{fdef}

	Excedances are something of a cyclic counterpart of descents. % how do I frame this lol

	\begin{ftheo}
		\label{theo: desc and exc}
		Descents and excedances are equidistributed. Equivalently,
		\[ A_n(t) = \sum_{\pi \in \mathfrak{S}_n} t^{\exc(\pi)}. \]
	\end{ftheo}
	Similar to excedances, consider non-excedances -- points where $\pi_i < i$.
	\begin{exercise}
		Show that $\exc(\pi) = \operatorname{nonexc}(\pi^{-1})$.
	\end{exercise}
	\begin{proof}
		
	\end{proof}
	\begin{proof}[Proof of \Cref{theo: desc and exc}]
		% Note that one can cyclically permute elements of $c_i$ and write the $c_i$s in any order
		Let $\pi \in \mathfrak{S}_n$ have cycles $c_1,\ldots,c_k$. For each $i$, let $m_i$ be the maximal element of $c_i$, and assume that $c_i$ is written starting with $m_i$. ALso assume that we write the cycles in increasing order of $m_i$. We refer to this as the \emph{canonical} cycle decomposition of $\pi$. Suppose we write the permutation in this form, as
		\[ ( (c_1)_1 (c_1)_2 \cdots (c_1)_{r_1} ) \cdots ( (c_k)_1 (c_k)_2 \cdots (c_k)_{r_k} ). \]
		Observe that the parenthesising is redundant! Reading the string $(c_1)_1 (c_1)_2 \cdots (c_1)_{r_1} \cdots (c_k)_1 (c_k)_2 \cdots (c_k)_{r_k}$ from left to right, we can recover the cycles -- a certain position is the beginning of a cycle iff it is greater than all the elements before it. This gives a bijection between canonical cycle representations and $\mathfrak{S}_n$ (which is not the obvious one). Therefore, composing the two maps, let $\Phi : \mathfrak{S}_n \to \mathfrak{S}_n$ be the map that given a permutation, reads it from left to right to get a canonical cycle decomposition, and yields as output the permutation corresponding to this cycle decomposition.\\
		% For example, if $\pi = 3,5,1,4,6,2 \in \mathfrak{S}_n$
		This map gives some sort of conversion from a linear form to a cyclic form. Recall how excedances were something of the cyclic analogue of the linear phenomenon of descents.\\

		We claim that $\nonexc(\Phi(\pi)) = \des(\pi)$ for any $\pi \in \mathfrak{S}_n$.\\
		Let $\pi \in \mathfrak{S}_n$ and $\sigma = \Phi(\pi)$. Let $i \in \DES(\pi)$. That is, $\pi_i > \pi_{i+1}$. Observe that $\pi_i,\pi_{i+1}$ are forced to be in the same cycle in $\sigma$ (due to the ``left to right maxima'' conversion). That is, $\sigma(\pi_i) = \pi_{i+1}$. Because this is less than $\pi_i$, any descent in $\pi$ map to a non-excedance in $\sigma$.\\
		It remains to show that ascents do not map to non-excedances. If $\pi_{i} < \pi_{i+1}$, then $\pi_i,\pi_{i+1}$ are either
		\begin{itemize}
			\item in different cycles of $\sigma$, in which case it is either an excedance if the size of the cycle is $>1$ (because it maps to the first element of the cycle, which is the maximum) or a fixed point otherwise, or
			\item within a cycle, in which case they contribute to $\exc(\sigma)$ (and so definitely not $\nonexc(\sigma)$),
		\end{itemize}
		completing the proof.
	\end{proof}

	Consider a \emph{palindromic polynomial}
	\[ f(t) = f_0 + f_1 t + \cdots + f_dt^d, \]
	where $f_r = f_{d-r}$. Let $k$ be the ``center of palindromicity'' which is roughly $d/2$. For a fixed $d$, observe that the sum of palindromic polynomials is palindromic, and the scalar multiple of a palindromic polynomial is palindromic as well. That is, the set of palindromic polynomials form a vector space.\\
	One obvious basis of this vector space is
	\[ \{ t^r + t^{d-r} : 0 \le r \le k \}. \]
	Another (less obvious) basis of this space is
	\[ \Span\left\{ t^j (1+t)^{d-2j} : 0 \le j \le k \right\}. \]
	This is referred to as the \emph{Gamma basis} -- why is it a basis?

	\begin{ftheo}[\cite{eulerian-gamma-pos}]
		The Eulerian polynomial is $\gamma$-positive.
	\end{ftheo}
	That is, when the Eulerian polynomial is represented as a linear combination of the elements of the Gamma basis, all coefficients are positive. For example,
	\[ A_5(t) = 1+26t+66t^2+26t^3+t^4 = (1+t)^4 + 22t(1+t)^2 + 16t^2. \]
	We do not prove the above.

\subsection{Carlitz' identity}

	Consider the generating function
	\[ P_n(t) = \sum_{j \ge 0} j^n t^j \]

	\begin{ftheo}[Carlitz' Identity]
		\label{theo: carlitz identity}
		It is true that
		\[ P(t) = \frac{tA_n(t)}{(1-t)^{n+1}}. \]
		Equivalently,
		\[ \frac{A_n(t)}{(1-t)^{n+1}} = \sum_{j \ge 0} (j+1)^n t^j. \]
	\end{ftheo}

	\begin{proof}
		Define a \emph{barred permutation} to be a permutation of length $n$ with ``vertical bars'' between elements such that there is a bar between $\pi_i,\pi_{i+1}$ if $i \in \DES(\pi)$. There are allowed to be more than one bar between any elements of the permutation, the only constraint is that there must be at least one bar at positions of descent. Given a barred permutation, let $\bars(\pi)$ be the number of bars in it. We shall look at
		\begin{equation}
			\label{eqn: counting to carlitz identity}
			\sum_{\overline{\pi} \text{ is a barred permutation of length $n$}} t^{\bars(\overline{\pi})}.
		\end{equation}
		Also denote $\mbinom{n}{k} = \binom{n+k-1}{k}$ to be the number of $k$-sized multisets of $[n]$. So,
		\[ \frac{1}{(1-t)^{n+1}} = \sum_{k \ge 0} \mbinom{n+1}{k} t^k. \]
		Observe that $t^{\des(\pi)}/(1-t)^{n+1}$ for some permutation $\pi$ is precisely the contribution of $\pi$ to \Cref{eqn: counting to carlitz identity}! The coefficient of $t^k$ in $1/(1-t)^{n+1}$ is precisely the number of ways to insert $k$ bars in the $n$ positions. Therefore,
		\[ \sum_{\overline{\pi} \text{ is a barred permutation of length $n$}} t^{\bars(\overline{\pi})} = \sum_{\pi \in \mathfrak{S}_n} \frac{t^{\des(\pi)}}{(1-t)^{n+1}} = \frac{A_n(t)}{(1-t)^{n+1}}. \]

		Let us now count this expression in another way, looking at the coefficient of $t^k$. This amounts to just putting $n$ ``distinct balls'' in $k+1$ ``distinct bins'', which is $(k+1)^n$. Therefore,
		\[ \frac{A_n(t)}{(1-t)^{n+1}} = \sum_{k \ge 0} (k+1)^n t^k. \qedhere \] 
	\end{proof}

	\begin{proof}[Proof due to class]
		Observe that
		\[ P_{n+1}(t) = \sum_{j \ge 0} j^{n+1} t^j = t \sum_{j \ge 0} j^n (jt^j) = t P_n'(t). \]
		It is also seen that
		\[ P_0(t) = \sum_{j \ge 0} t^j = \frac{1}{1-t}. \]
		The two equations above are seen to imply that $P_n(t)$ is a rational function for any $n$. Further, the denominator of any $P_n$ is some exponent of $(1-t)$. \\
		In general, suppose $P_k(t) = p_k(t)/(1-t)^{r_k}$ for a polynomial $p_k$ such that $p_k(1) \ne 0$. Then,
		\begin{align*}
			tP_k'(t) &= \frac{t \left( p_k'(t) (1-t)^{r_k} - r_k (1-t)^{r_k - 1} p_k(t) \right)}{(1-t)^{2r_k}} \\
				&= \frac{ t(1-t)p_k'(t) - r_k t p_k(t) }{(1-t)^{r_k+1}}.
		\end{align*}
		The numerator is nonzero at $1$, so $r_{k+1} = r_k + 1$. Since $r_0 = 1$, $r_k$ is just $k+1$. We also have
		\[ p_{k+1}(t) = t (1-t) p_k'(t) - (k+1) t p_k(t). \]
		It is seen that this recurrence is satisfied by $tA_n(t)$ and $p_1(t) = tA_1(t)$, completing the proof.
	\end{proof}

	Now, consider the egf
	\[ S(t,u) = \sum_{n \ge 0} A_n(t) \frac{u^n}{n!}. \]
	We have by \Cref{theo: carlitz identity} that
	\begin{align*}
		\frac{S(t,u)}{1-t} &= \sum_{n,m \ge 0} (m+1)^n t^m \frac{\left(u(1-t)\right)^n}{n!} \\
			&= \sum_{m \ge 0} t^m \sum_{n \ge 0} \frac{\left(u(m+1)(1-t)\right)}{n!} \\
			&= \sum_{m \ge 0} t^m \exp(u(m+1)(1-t)) \\
			&= \exp(u(1-t)) \sum_{m \ge 0} \left( t \exp(u(1-t)) \right)^m \\
			&= \frac{e^{u(1-t)}}{1 - te^{u(1-t)}} \\
			&= \frac{1}{e^{u(t-1)} - t} \\
		S(t,u) &= \frac{1-t}{e^{u(t-1)}-t}.
	\end{align*}
	Despite not having anything explicit for the Eulerian polynomial itself, we do get an explicit egf for it!\\

	Recall $\gamma$-positivity of palindromic polynomials.

	\begin{definition}
		If $f(t) = \sum_{k=r}^n a_kt^k$ with $a_r,a_n \ne 0$ then $f$ is said to be \emph{palindromic} if $t^{n+r} f(1/t) = f(t)$.
	\end{definition}
	Typically, we discuss palindromic polynomials for a fixed $r$.\\
	The center of symmetry of the polynomial is roughly $(n+r)/2$, and the set of palindromic polynomials for a fixed $r$ form a vector space of dimension roughly $(n-r)/2$.\\
	Some bases of this space are
	\begin{align*}
		B_1 &= \left\{ t^\ell + t^{n+r-\ell} : k = r,\ldots,(n-r)/2 \right\} \\
		B_2 &= \Gamma_{(n-r)/2} = \left\{ t^{r+\ell} (1+t)^{n-r-2\ell} : \ell = r,\ldots,(n-r)/2 \right\}	\\
		B_3 &= G_{(n-r)/2} = \left\{ [b+1-\ell]_t - [r+\ell]_t : \ell = 0,\ldots,(n-r)/2 \right\}.
	\end{align*}
	
	\begin{fex}
		It is true that
		\phantom{pain}
		\begin{align*}
			[5]_q &= 1+q+q^2+q^3+q^4 \\
				&= (1)(1+4q+6q^2+4q^3+q^4) + (-3)(q+2q^2+q^3) + q^2.
		\end{align*}
	\end{fex}

	Let us string the coefficients that appear above as a polynomial. For example,
	\begin{equation}
		\label{eqn: gamma example}
		\gamma_{[5]_q}(t) = 1-3t+t^2 \text{ and } \gamma_{[4]_q}(t) = 1-2t.
	\end{equation}
	Do the $\gamma$-coefficients of $[n]_q$ alternate in sign?

	Recall the $1 \times n$ board $B_n$, which we saw how to tile with squares and dimers. Also recall \Cref{eqn: board tiling polynomial} and the recurrence thereafter. It is easily verified that
	\begin{align*}
		F_3(s,t) &= s^3 + 2st \\
		F_4(s,t) &= s^4 + 3s^2t + t^2.
	\end{align*}
	Observe that these coefficients match (up to sign) the coefficients in \Cref{eqn: gamma example}!

	% \begin{exerc}
	% 	Show that
	% 	\[ F_n(1+q,-q) = [n+1]_q. \]
	% \end{exerc}
	\begin{flem}
		% It is true that
		\[ F_n(1+q,-q) = [n+1]_q. \]
	\end{flem}
	\begin{proof}
		We prove this inductively. The base cases $n=1,2$ are trivially true as $F_1(1+q,-q) = 1+q = [2]_q$ and $F_2(1+q,-q) = (1+q)^2 + (-q) = [3]_q$. In general, using the inductive hypothesis,
		\begin{align*}
			F_n(1+q,-q) &= (1+q)F_{n-1}(1+q,-q) - qF_{n-2}(1+q,-q) \\
				&= (1+q)[n]_q - q[n-1]_q \\
				&= \left(1 + 2\sum_{1 \le i \le n-1} q^i + q^n\right) - \sum_{1 \le i \le n-1} q^i = [n+1]_q.
		\end{align*}
	\end{proof}

	Let
	\[ [n]_q = F_{n-1}(1+q,-q) = \sum_{k = 0}^{n-1} f_{n-1,k} (1+q)^{n-1-2k}(-q)^k. \]
	What are these $f_{n-1,k}$?\\

	Given a graph $G$ of size $n$, consider the bivariate polynomial
	\[ \Match_G(s,t) = \sum_{\substack{\text{$\mathcal{M}$ matching in $G$} \\ |\mathcal{M}| = k}} s^{n-2k} t^k = \sum_{k \ge 0} m_k(G) s^{n-2k} t^k . \]
	There is an straightforward correspondence between matchings on $P_n$ and tilings $F_n$. For each edge $\{i,i+1\}$ in a matching, consider the tiling on $B_n$ with dimers precisely at positions $\{i,i+1\}$. This is sensible because the edges form a matching.\\
	As a result,
	\[ F_n(s,t) = \Match_{P_n}(s,t) = \sum_{k \ge 0} \binom{n-k}{k} s^{n-2k} t^k \]
	and $f_{n,k} = \binom{n-k}{k}$. Consequently,

	\[ [n]_q = \sum_{k \ge 0} (-1)^k \binom{n-1-k}{k} \underbrace{(1+q)^{n-1-2k} q^k}_{\text{element of the $\Gamma$-basis!}}. \]
	The $\gamma$-coefficients of $[n]_q$ do alternate in sign.