\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{cs-305}

\renewcommand{\arraystretch}{1.2}

\begin{document}

\thispagestyle{empty}
\titleBC

\tableofcontents
\clearpage

% \setcounter{section}{-1}

\section{Introduction}

	\subsection{Overview}

		What is a computer? It includes anything from a smartphone to an iPad to a data center. Let us delay what ``computer architecture'' means to the end of the course and try to figure out what it should mean for now. Historically, the heavy lifting is done by the computer architecture. The computing stack is as follows: we have problems, for which we design algorithms, which we implement in programming languages/compilers, which are run using an operating/database/network system, which require computer architecture to run (which is the focus of this course).

		Most software companies nowadays build their own processors or chips.

		Since the dawn of time (1946 for our purposes), any computer has 5 components -- the processor which consists of control and datapath, memory, input, and output. Computer architecture changes over time depending on our requirements.

		Abstractions are useful if we only care about \emph{what} we want to do. But if we want to know how or why we are doing something, they are all but useless -- so we aim to break them in this course.\\

		\textbf{MIPS} is a simple yet expressive instruction set architecture (ISA) which we shall use in this course. It is used even today in embedded devices, routers, modems etc. The ISA provides an interface between hardware and software -- it veils complexity through a set of simple instructions.\\
		For example, \texttt{a=b+c} might be the C code, which gets converted to \texttt{add \$t1 \$t2 \$t3} (assembly language) by the compiler, which in turn gets converted to some binary string (machine language) by the assembler.\\
		Operands can be located either in registers or in memory. Registers (32-bit addresses) are closer to the processor so are easier and cheaper to access, while memory (DRAM addresses) is costlier to access. However, registers are limited -- we don't have a lot of them.

	\subsection{Introduction to MIPS}

		In 1949, \emph{EDSAC} had only 18 machine instructions. Today in 2021, x86 has over 1500 such instructions. Why do we need these instructions? Programmers must know what the processor can/cannot do, and the processor knows what it should do. In a world with no such instructions, we would have to communicate tedious binary strings to perform simple tasks. 

		Let us zoom into the processor for a moment. We have a set of registers (tens of them -- 32 or 64 for example) and an Arithmetic/Logic Unit (ALU). The processor communicates with the memory through the \emph{address bus} (the processor sends the address to the memory) and the \emph{data bus} (the memory sends data to the processor). The processor can directly access the data of registers, whereas memory has to be accessed in two steps (using the two buses).

		Let us look at the most basic operation of MIPS: \textbf{\texttt{add}}. In \texttt{add \$1, \$2, \$3}, \texttt{add} is the operation, \texttt{\$1} is the destination, and \texttt{\$2} and \texttt{\$3} are the sources. Each of these three refers to a certain register. Most ALU operations in MIPS have two sources and one destination.

		If we want to do \texttt{a=b+c-d}, we can do
		\begin{verbatim}
			add $t0, $s1, $s2
			sub $s0, $t0, $s3
		\end{verbatim}
		Here, \texttt{\$t0} is a temporary register. We also use constants in our program. For this, MIPS have instructions that end with \texttt{i}, where \texttt{i} means ``\texttt{i}mmediate''. For example, \texttt{addi \$s0, \$s0, 10} adds 10 (the \texttt{i} refers to the fact that 10 is a constant). The constants are represented in 16-bit 2s complement form.

		We do not need \texttt{subi} since we can use an appropriate constant with \textbf{\texttt{addi}} instead.

		\texttt{\$0} or \texttt{\$zero} is a special register that contains zero. In particular, \texttt{a=b} becomes \texttt{add \$s1, \$s2, \$zero}.
		% This begs the question, why would we add when can move instead?
		This leads to the \emph{pseudo-instruction} \texttt{move \$s1 \$s2}, which is not an actual instruction (meaning that when running the code, it is translated to a simpler instruction) and is merely used for programming convenience.

		Let us next look at a couple of \texttt{l}ogical operations:
		\begin{itemize}
			\item \textbf{\texttt{sll}} \texttt{s}hifts to the \texttt{l}eft,
			\item \textbf{\texttt{srl}} \texttt{s}hifts to the \texttt{r}ight, and
			\item \textbf{\texttt{and}}, \textbf{\texttt{or}}, \textbf{\texttt{nor}}, \textbf{\texttt{andi}}, and \textbf{\texttt{ori}} mean the usual thing.
		\end{itemize}
		Interestingly, there is no \texttt{not} instruction, we instead use \texttt{nor} with one operand as \texttt{0}. When we are dealing with these instructions, one must understand that we are dealing with 32 raw bits, not a 32-bit number. 

		Now, how would we store a 32-bit constant in a 32-bit register (the instructions so far take 16-bit numbers)? The operation \textbf{\texttt{lui}} loads the first 16 bits of a 32-bit number into a register setting the lower bits all 0. We then perform an \texttt{or} of this register with the other 16 bits. So, if we wanted \texttt{\$t0} to store the 32-bit constant \texttt{10101010 10101010 11110000 1111000}, then we can do
		\begin{verbatim}
			lui $t0, 0xAAAA
			ori $t0, $t0, 0xF0F0
		\end{verbatim}
		The above sequence of operations can be shortened to the pseudo-operation \texttt{li \$t0 0xAAAAF0F0}.\\
		Note that all constants used in the operations are only 16 bits long.

	\subsection{Operations on Memory}

		Before 1944, memory only stored the data required to perform an operation. So, the stored program as the binary is stored in memory. Von Neumann then came up with the idea to store instructions in memory as well. We refer to a 4-byte binary string as a  ``word''. Memory is then just a collection of words. The \textit{program counter} (PC) or \textit{instruction pointer} (IP) is a special register that stores the address of the instruction. So, if we have a 32-bit processor and the address are of width 32 bits as well, the processor fetches PC, PC+4, PC+8,$\ldots$ sequentially.

		When we want some operation done,
		\begin{enumerate}
			\item the processor gets the instruction from memory,
			\item the ALU demands the data using the address through the address bus,
			\item the memory responds with the data through the data bus, and
			\item the ALU performs the operation.
		\end{enumerate}
		We can also think of a step 0 where a request is sent based on the PC itself.

		% Suppose we have a program with only three instructions: \texttt{PCX} which points to \texttt{lw}, \texttt{PCY} which points to \texttt{add}, and \texttt{PCZ} which points to \texttt{lui}. If stored sequentially, PY=PCX+4 and PCZ=PCY+4.

		Why do we use memory and not registers? Registers are fast because they are limited -- the more registers we have, the higher the access time becomes. We shall look at this in more detail later.\\

		How do we access data from memory?\\
		The two primary instructions for this are \textbf{\texttt{lw}} (\texttt{l}oad \texttt{w}ord) and \textbf{\texttt{sw}} (\texttt{s}tore \texttt{w}ord). The former loads data from the memory to the register, while the latter writes data from the registers to the memory.\\
		For example, \texttt{lw \$t0, 1(\$a0)} performs \texttt{\$t0 = Memory[\$a0+1]}. The processor sends a ``load request'' to the address \texttt{\$a0+1} and the memory responds with the data at that address. Similarly, \texttt{sw \$t0, 1(\$a0)} does \texttt{Memory[\$a0+1] = \$t0}.

		When we do an \texttt{lw} operation, there are two fetches from memory -- one for the instruction itself and another for the data. When we do an \texttt{add} operation on the other hand, there is only one fetch since there is no memory access.

		% Recall that the load immediate (\texttt{lui}) operation is not a load from memory since we use a constant.

		Let us now move on to decision-making instructions.
		\begin{itemize}
			\item \textbf{\texttt{beq}} (\texttt{b}ranch \texttt{eq}uals to): If we do \texttt{beq \$t0, \$t1, L1}, the PC goes to ``label'' \texttt{L1} (\texttt{goto L1}) if \texttt{\$t0} and \texttt{\$t1} are equal.% We shall define what a label is later.

			\item \textbf{\texttt{bne}} (\texttt{b}ranch \texttt{n}ot \texttt{e}quals to): If we do \texttt{bne \$t0, \$t1, L1}, the PC goes to label \texttt{L1} if \texttt{\$t0} and \texttt{\$t1} are \emph{not} equal. We shall define what a label is later.

			\item \textbf{\texttt{slt}} (\texttt{set} on \texttt{l}ess \texttt{t}han): If \texttt{t1} and \texttt{t2} contain $a$ and $b$, then \texttt{slt \$t3, \$t1, \$t2} does the following: if $a < b$, it sets the content of \texttt{t3} to $1$ and otherwise, it sets the content to $0$.    
			We also have \texttt{slti}, where one of the operands is a constant.
		\end{itemize}

		Next, we look at unconditional jumps (as opposed to the conditional jumps we just looked at):

		\begin{itemize}
			\item \textbf{\texttt{j}} (\texttt{j}ump): It allows us to jump to a label. This instruction loads an immediate into the PC -- it can be specified by either an offset or the label (the assembler converts this label to an offset).

			Now, suppose are running some C code wherein we call a function, and return after the successful running of the function. How do we return to the appropriate place after the code finishes running?

			\item \texttt{\textbf{jal}} and \texttt{jr} (\texttt{j}ump \texttt{a}nd \texttt{l}ink and \texttt{j}ump \texttt{r}egister): \texttt{jal L1} jumps to the label \texttt{L1} which has to be instruction to be executed next and saves the address of the next instruction (PC + 8)\footnote{One might expect to jump to PC+4 instead. We shall look at the reason for the 8 later.} in \texttt{\$ra}. \texttt{ra} is a special register that stores the return address. \texttt{jr \$ra} then returns to the required spot after execution of the intermediate function.
		\end{itemize}

		It is possible that some code in the main function accesses, say, register \texttt{\$R2} and something in a called function accesses register \texttt{\$R2} as well. How do we coordinate this? What data is really accessed when we access a certain register (does the function then attempt to access main's data?) What is the protocol using which the caller and callee interact? MIPS allows \emph{four} arguments to be passed from the caller to the callee while using \texttt{jal}, which uses registers \texttt{\$a0} through \texttt{\$a3}. A callee returns upto two values to the caller, using registers \texttt{\$v0} and \texttt{\$v1}.\\
		How does this work out when we have nested functions? The data transferred by the second function to the third in the \texttt{\$a0} to \texttt{\$a3} registers will overwrite the data transferred by the first to the second! Similarly, the value of \texttt{\$ra} changes as well, so how do we go back to the original function and fix these issues? We might think of allotting some registers to be used by the caller and some to be used by the callee. Unfortunately, the callee does not know the registers used by callers (which may be many in number), and the caller does not know the callee's plan either. We can't just allot new registers because we do not know how many nested functions are there, and we only have a limited number of registers: 
		In MIPS, there are 32 registers:
		\begin{center}
		\begin{tabular}{|l|c|}
			Registers & Number \\ \hline
			\texttt{\$Zero} & 1 \\
			Return value registers (\texttt{\$v0}, \texttt{\$v1}) & 2 \\
			Argument registers (\texttt{\$a0} to \texttt{\$a3}) & 4 \\
			Return address (\texttt{\$ra}) & 1 \\
			Saved registers (\texttt{\$s0} to \texttt{\$s7}) & 8 \\
			Temporary registers (\texttt{\$t0} to \texttt{\$t9}) & 10 \\
			Global pointer (\texttt{\$gp}) & 1 \\
			Stack pointer (\texttt{\$sp}) & 1 \\
			Frame pointer (\texttt{\$fp} or \texttt{\$t10}) & 1 \\
			OS kernel activities (\texttt{\$k0} and \texttt{\$k1}) & 2 \\
			Assembler (\texttt{\$at}) & 1
		\end{tabular}
		\end{center}

		The above described problem is known as \textbf{register spilling}, we are running out of registers to use.\\
		So where else can we store data? The only other place to store data at all is the memory, so that is what we shall choose!\\
		The stack pointer (\texttt{\$sp}) points to the stack, which is part of the DRAM. The stack is private to each function call to ensure that other functions do not overwrite its data. \texttt{\$sp} points to the address where the stack \emph{ends}. The stack grows \emph{downwards}. When we push something to the stack, we decrement the \texttt{\$sp} by 4 and store the register content in the appropriate place in memory.\\

		\texttt{\$t0} through \texttt{\$t9} (registers R8 to R15, R24, and R25) are caller-saved registers. Their values are not preserved across function calls and are said to be \emph{call-clobbered}.\\
		\texttt{\$s0} through \texttt{\$s9} (registers R16 to R23) on the other hand are callee-saved registers. Their values are maintained across function calls and said to be \emph{call-preserved}.\\
		Are \texttt{\$sp} and \texttt{\$ra} caller- or callee-saved registers?\\

		To handle register spilling, MIPS stores the data of the registers in the stack and moves on. After the function is finished, we pop the data off the stack and change the register content back to the initial state. How does this work in MIPS? To save data to a register, we do
		\begin{verbatim}
			addi $sp, $sp, -4
			sw R4, $sp
		\end{verbatim}
		and to restore data,
		\begin{verbatim}
			lw R4, $sp
			addi $sp, $sp, 4
		\end{verbatim}
		So when we call a function, all the relevant data (\texttt{\$ra} in particular) is stored into the stack so that we know where to return to.

		The stack is also used to store local variables and data structures for a function along with the return addresses. To look at these, we have a \emph{frame pointer} (\texttt{\$fp}). It points to the highest address (on the downward growing stack) in the procedure frame and is used to look at local variables and saved registers. It stays there throughout the procedure while the stack pointer moves around. This is just to make life easier for the compiler/programmer. Technically, we do not require it and can make do with the stack pointer alone (with a suitable offset), but that is very inconvenient.

	\subsection{Instruction Decoding}

		We have seen how MIPS instructions allow the programmer to interact with the processor. How are these instructions decoded?\\
		Recall that instructions are of size 32 bits (in MIPS). How does the processor infer these bits?\\
		Since MIPS has 32 registers, any register can be specified using $5$ bits. A $32$ bit R-type instruction is split into 4 parts:
		\begin{itemize}
			\item Bits 0 through 15 specify the immediate.
			\item Bits 16 through 20 specify a register \texttt{rt}.
			\item Bits 21 through 25 specify another register \texttt{rs}.
			\item Bits 26 through 31 specify an operation \texttt{op}, such as say \texttt{add}, \texttt{mul}, \texttt{lw}, \texttt{bne}, etc.
		\end{itemize}
		A general instruction in MIPS has
		\begin{itemize}
			\item an operation code \texttt{op},
			\item up to three registers \texttt{\$rs}, \texttt{\$rt}, and \texttt{\$rd},
			\item \texttt{shamt} (\texttt{sh}ift \texttt{am}oun\texttt{t}) for logical operations, and
			\item the functionality field \texttt{funct}.
		\end{itemize}
		Let us look at the value of each of the above parameters for a couple of instructions.
		\begin{center}
		\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
			\hline
			Instruction & Format & \texttt{op} & \texttt{rs} & \texttt{rt} & \texttt{rd} & \texttt{shamt} & \texttt{funct} & \texttt{address} \\ \hline
			\texttt{add} & R & 0 & reg & reg & reg & 0 & 32 & n.a. \\
			\texttt{sub} & R & 0 & reg & reg & reg & 0 & 34 & n.a. \\
			\texttt{addi} & I & 8 & reg & reg & n.a. & n.a. & n.a. & constant \\
			\texttt{lw} & I & 35 & reg & reg & n.a. & n.a. & n.a. & address \\
			\texttt{sw} & I & 43 & reg & reg & n.a. & n.a. & n.a. & address \\ \hline
		\end{tabular}
		\end{center}
		The format R means that it is a register-type instruction, while I means that it is an immediate-type instruction.\\
		We see that the \texttt{funct} field is what differs \texttt{add} and \texttt{sub}.\\
		The lowest 16 bits are not used by I instructions since they are replaced by a constant or address, as specified. The op code informs the processor how to treat the last set of fields, as three or one.\\

		In all, the three types of instructions are:
		\begin{center}
		\begin{tabular}{|c||p{2cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{2cm}|}
			\hline
			Type & 31 \hfill 26 & 25 \hfill 21 & 20 \hfill 16 & 15 \hfill 11 & 10 \hfill 06 & 05 \hfill 00 \\ \hline
			R & \multicolumn{1}{c|}{opcode} & \multicolumn{1}{c|}{\texttt{\$rs}} & \multicolumn{1}{c|}{\texttt{\$rt}} & \multicolumn{1}{c|}{\texttt{\$rd}} & \multicolumn{1}{c|}{\texttt{shamt}} & \multicolumn{1}{c|}{\texttt{funct}} \\ \hline
			I & \multicolumn{1}{c|}{opcode} & \multicolumn{1}{c|}{\texttt{\$rs}} & \multicolumn{1}{c|}{\texttt{\$rt}} & \multicolumn{3}{c|}{immediate} \\ \hline
			J & \multicolumn{1}{c|}{opcode} & \multicolumn{5}{c|}{address} \\ \hline
		\end{tabular}
		\end{center}

		Such a format is good since
		\begin{itemize}
			\item We have fixed length instructions which allows for convenient decoding.
			\item Fields are at the same or similar location.
			\item All three formats look similar.
		\end{itemize}

		Next, let us look at 5 addressing modes of the MIPS ISA.

		\begin{itemize}
			\item Immediate: We have already seen this above. For example, \texttt{addi \$t0 \$t1 5} is in this mode.
			\item Register: We have seen this as well. For example, \texttt{add \$t0 \$t1 \$t2} is in this mode.
			\item Base: It has an opcode, \texttt{\$rs}, \texttt{\$rt}, and an address.\\
			Here, the address is given by a register. For example, \texttt{lw \$t1 4(\$s2)} or \texttt{lw \$t1 (\$s2)}. We possibly add a constant to the address in a register, and access the memory pointed at by this.
			\item PC-relative: These are essentially the J-type instructions we looked at earlier. The label gives an offset, which is what we jump to. An example of this is \texttt{beq \$t0 \$t1 end}.
			\item Pseudodirect: It has an opcode and an address.\\
			An example of this is \texttt{jal}. We concatenate the content of the PC and the address provided to get another address, using which we get the operand.
		\end{itemize}

	\subsection{Why ISAs?}

		\subsubsection{Microarchitecture v. ISAs}

			The ISA is the interface between hardware and software. It enables the programmer to not bother about what is going on under the hood at all.\\
			A \emph{microarchitecure} is a specific implementaiton of an ISA (which the programmer cannot see/access). For example, the \texttt{add} instruction would come under the ISA, but the specific implementation of an adder (ripple carry/lookahead) comes under the microarchitecture.\\
			We shall look at microarchitecture in more detail in a later part of the course.

			The actual working of the ISA can be thought of using a state machine. As long as the new state that is moved to on receiving an instruction satisfies the ISA specifications, it will work. The information held in the processor at the end of an instruction provides context for the next instruction.

			Computer architecture as a whole focuses on both ISA and microarchitecture.

			% x86 registers have 128/256-bit registers and 1-bit regs too!

			Now, should we keep the ISA closer to the hardware or closer to the high-level software? This leads to two schools of thought -- the latter being called CISC (Complex Instruction Set of Computers) and the former being RISC (Reduced Instruction Set of Computers).\\
			If we are closer to high-level language, there is a small semantic gap between the two and we have complex instructions. For example, quicksort may be an instruction. An example of a CISC architecture is something like x86.\\
			If we are closer to hardware, there is a large semantic gap and instructions are quite simple. An example of a RISC architecture is MIPS.\\
			Irrespective of whether we use CISC or RISC, an app's instruction count is defined by the compiler \emph{and} the ISA.

			x86 is slightly complicated since it converts CISC operations to RISC operations, and generates \emph{microoperations}. It is an intelligent CISC-RISC decoder. This consumes 2\% of the chip area.

			In any ISA, there are various factors we must take into account:
			\begin{itemize}
				\item Simplicity
				\item Performance, power, cost, time to market
				\item RISC v. CISC
				\item Fixed v. Variable encoding
				\item Endianness
				\item Number of registers per instruction
				\item Code size
				\item Open sourcedness
			\end{itemize}

		\subsubsection{ISAs other than MIPS}

			There are various common ISAs other than MIPS. For example,
			\begin{itemize}
				\item \emph{x86}, which is used by Intel, AMD in laptops, desktops, and servers.\\
				x86 has thousands of instructions. Some differences are:
				\begin{itemize}
					\item A single operand can act as both a source and destination. For example \texttt{add \$s0 \$s1} adds \texttt{\$s0} and \texttt{\$s1}, then stores the result in \texttt{\$s0}.
					\item An operand can be in memory as well. For example, \texttt{add \$s0 Mem[\$s1]} can be done.
					\item Fixed length instructions are not there any more.
				\end{itemize}
				In variable width instructions, different isntructions can take a different number of bytes. It occupies a smaller code footprint and is compact as a result. However, fixed length instructions (like those in MIPS, which occupy 4 bytes) lend themselves to simple decoding despite occupying a larger memory footprint.

				\item \emph{ARM}, which is used by Arm, Qualcomm, Apple, and Samsung.\\
				The primary reason one would look at ARM with the \emph{thumb instruction set} is that it is useful in embedded devices (which have low memory), where we require low code density. Instead of using normal 32-bit instructions, we use ``thumb'' instructions that are only 16 bits. 32-bit registers have 16-bit counterparts.
				\item More recently, \emph{RISC-V}, an open-source ISA, has been gaining popularity.
			\end{itemize}

			RISC was created to enable better compiler control. It was motivated by memory stalls (no work is done during a complex instruction when there is a stall). It enables the compiler to optimize the code, and allows discovery of fine-grained parallelism to reduce the stalls.

		\subsection{Endianness}

			\emph{Endianness} refers to the byte ordering within a word (or the bit ordering within a byte).
			\begin{itemize}
				\item In the \emph{big endian} notation, the address of the most significant byte is the word address. This is used in MIPS.
				\item In the \emph{little endian} notation, the address of the least significant byte is the word address. This is used in x86.
			\end{itemize}

			To understand this better, consider the following snippet of code.

			\begin{verbatim}
				unsigned int i = 1;
				char *c = (char*)&i;
				printf("%d", *c)
			\end{verbatim}

			If the ISA follows the big endian notation, the output is 0 and if it follows the little endian notation, the output is 1.

		\subsection{Alignment}

			Ideally, any address should be aligned. For example, suppose we want to access the 4th byte starting from an address \texttt{y}. This requires that \texttt{y\%4} is 0.\\
			For example, MIPS does not allow unaligned access. On the other hand, x86 does not enforce any alignment. It is the compiler's duty to generate aligned or unaligned access.\\
			Alignment is desired to enable faster transfer of data. Indeed, if a 4-byte word is not aligned, then we need to access the memory twice to get the entire word (once for each of the two parts split across). This will become clearer once we understand caches later.

			\texttt{LOAD}s and \texttt{STORE}s need an alignment network that ensures the data loaded/written is aligned. This alignment network differs based on the endianness.

\end{document}