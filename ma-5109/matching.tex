\section{Matching Theory}

\begin{fdef}
	Given a graph $G$, a \textbf{matching} $\mathcal{M}$ in $G$ is a collection of pairwise disjoint edges in $G$ (no two of the edges have a common vertex).
\end{fdef}

For example, $\{\{1,6\},\{2,5\},\{3,4\}\}$ is a matching in $K_6$.

\begin{fdef}
	Given a graph $G$, the \textbf{matching number} $\nu(G)$ of $G$ is the size of a maximum matching in $G$.
\end{fdef}

Given a graph, how do we compute a maximum matching, or simpler yet, $\nu(G)$?

	\subsection{The Bipartite Setting}

		For this section, suppose that $G = (X,Y,E)$ is bipartite, where all edges in $E$ are between $X$ and $Y$. Assume $|X| \le |Y|$.\\
		It is clear that $\nu(G) \le |X|$.\\

		The question is: under what conditions on $G$ is $\nu(G) = |X|$?\\
		This (the bipartite scenario) is sometimes referred to as a \emph{system of distinct representatives} (SDR). That is, $G$ has an SDR if $\nu(G) = |X|$.\\

		\subsubsection{Hall's Marriage Theorem}

			An obvious necessary condition is that given any $S\subseteq X$,
			\[ |\Gamma(S)| \ge |S|. \]
			Otherwise, there cannot exist a matching since two vertices in $S$ would be forced to map to the same element in $Y$.\\
			This is known as \emph{Hall's condition}.\\
			It in fact turns out that Hall's condition is sufficient for the existence of a matching too!

			\begin{ftheo}[Hall's Marriage Theorem]
				Suppose $G=(X,Y,E)$ is bipartite with $|X|\le |Y|$. Then $\nu(G) = |X|$ if and only if it satisfies Hall's condition.
			\end{ftheo}
			Much like Tur\'{a}n's theorem, this has a large number of proofs.
			\begin{proof}[Proof 1 of Hall's Marriage Theorem]
				We begin with a proof by induction over $|X|$. If $|X|=1$, the theorem obviously holds.\\
				Make the stronger assumption that for all $S\subseteq X$ of size $|X|-1$, $|\Gamma(S)| > |S|$, and $|\Gamma(X)| \ge |X|$. Pick $x\in X$ and pair it with an arbitrary neighbour $y\in Y$. Using the inductive hypothesis on the subgraph induced on $(X\setminus\{x\}) \cup (Y\setminus\{y\})$, we get a matching on $G$.\\
				Now, let $S\subseteq X$ with $|\Gamma(S)|=|S|=|X|-1$. Using the inductive hypothesis on the subgraph induced on $S\cup\Gamma(S)$, together with the edge from the (single) element in $X\setminus S$ to any element in $\Gamma(X)\setminus\Gamma(S)$, we get a matching on $G$.
			\end{proof}
			An alternate way to prove this is by doing the first part of the proof with all non-empty $S\subseteq X$ (instead of only those of size $|X|-1$). In the case where we have some non-empty $S\subseteq X$ with $|\Gamma(S)|=|S|$, we can use the inductive hypothesis twice to get two matchings $\mathcal{M}_1$ and $\mathcal{M}_2$ on the subgraphs induced by $S \cup \Gamma(S)$ and $(X\setminus S) \cup (Y\setminus\Gamma(S))$, then take the union of the two matchings to get a matching $\mathcal{M}$ on the original graph $G$.\\

			A nice consequence of the above proof is that it allows us to extend Hall's Theorem to an infinite setting as well.

			\begin{definition}
				Given a matching $\mathcal{M}$ on a graph $G=(V,E)$, call a $v\in V$ \textbf{unsaturated} if no edge of $\mathcal{M}$ is incident on $v$.
			\end{definition}

			For a matching $\mathcal{M}$, $x\in X$, $y\in Y$ such that $x,y$ are unsaturated (with respect to $\mathcal{M}$), a path $P$ from $x$ to $y$ is called $\mathcal{M}$-\textbf{augmenting} if every alternate edge in it is a $\mathcal{M}$-edge.\\
			Observe that if $\mathcal{M}$ admits an augmenting path, then $\mathcal{M}$ is not maximal. Indeed, we can `flip' the edges in the path to show this. That is, given an augmenting path $\mathcal{P}$, where every $y_ix_i$ is in $\mathcal{M}$, it is not too difficult to show that $\mathcal{M} \triangle \mathcal{P}$ is a matching that has strictly more edges.\\

			\begin{proof}[Proof 2 of Hall's Marriage Theorem]
				Let $\mathcal{M}$ be a maximum matching of a bipartite graph $G=(X,Y,E)$ that satisfies Hall's condition. Suppose there exists $x_0 \in X$ such that $x_0$ is unsaturated by $\mathcal{M}$. Let $y_1$ be a neighbour of $x_0$ (such a $y_1$ exists by Hall's condition).\\
				If $y_1$ is unsaturated by $\mathcal{M}$, then $x_0y_1$ is a $\mathcal{M}$-augmenting path, contradicting its maximality. So, suppose $x_1y_1 \in \mathcal{M}$.\\
				In general, if we have $y_1,\ldots,y_r,x_1,\ldots,x_r$, we can pick $y_{r+1}\in \Gamma(\{x_0,\ldots,x_r\})$ (distinct from all the $y_i$ for $1\le i\le r$).\\
				If $y_{r+1}$ is unsaturated, we have a $\mathcal{M}$-augmenting path from $x_0$ to $y_{r+1}$, contradicting the maximality of $\mathcal{M}$.\\
				If it is not, we can jump back to the $x_{r+1}\in X$ (distinct from the $x_i$ for $1\le i\le r$) such that $y_{r+1}x_{r+1} \in E$, then continue the process. This must terminate at some point since the number of vertices in $Y$ incident on some element of $\mathcal{M}$ is at most $|X\setminus\{x_0\}|< |Y|$, completing the proof.
			\end{proof}

		\subsubsection{Some applications}

			Next, let us look at a few applications of Hall's Theorem.

			\begin{fdef}[Perfect Matching]
				A matching $\mathcal{M}$ in a graph $G=(V,E)$ is said to be a \textbf{perfect matching} if $|\mathcal{M}| = |V|/2$, that is, every vertex in $V$ is saturated by $\mathcal{M}$.
			\end{fdef}

			\begin{ftheo}
				\label{ftheo: regular bipartite graph has a perfect matching}
				If a bipartite graph $G=(X,Y,E)$ is $d$($>0$)-regular, it has a perfect matching.
			\end{ftheo}
			\begin{proof}
				It suffices to check that Hall's condition holds. Let $S\subseteq X$. We clearly have $e(S,\Gamma(S))=d|S|$. However, the total number of edges coming into $\Gamma(S)$ must include all the edges coming from $S$, that is, $S\subseteq\Gamma(\Gamma(S))$. So,
				\begin{align*}
					d|\Gamma(S)| &= e(\Gamma(S),\Gamma(\Gamma(S))) \\
						&\ge e(\Gamma(S),S) \\
						&= d|S|,
				\end{align*}
				completing the proof.
			\end{proof}

			For the next result, consider the following definition.

			\begin{fdef}
				A matrix $A\in\R^{n\times n}$ is said to be \textbf{doubly stochastic}\footnotemark\ if for all $i,j$,
				\[ 0\le a_{ij} \le 1 \text{ and } \sum_{k} a_{ik} = \sum_{k} a_{kj} = 1. \]
			\end{fdef}
			\footnotetext{These are interesting to study since they arise as the transition matrices of a certain class of discrete Markov chains. The stationary distribution of a discrete Markov chain with a doubly stochastic transition matrix is the uniform distribution.}

			It is not too difficult to see that any permutation matrix is doubly stochastic.\\
			Suppose $A_1,A_2$ are doubly stochastic and $0\le\lambda\le 1$. Then observe that $\lambda A_1 + (1-\lambda)A_2$ is doubly stochastic too (Why?).\\
			As a result, a convex combination of doubly stochastic matrices is doubly stochastic.

			\begin{ftheo}[Birkhoff-von Neumann Theorem]
				A matrix is doubly stochastic iff it is a convex combination of permutation matrices.
			\end{ftheo}
			\begin{proof}
				We want to show that if $A$ is doubly stochastic, then $A = \sum_{i=1}^k \lambda_i P_i$, where the $P_i$ are permutation matrices, $\sum_i \lambda_i = 1$, and $\lambda_i \ge 0$.\\
				The idea is something like performing induction on $k$. If $A$ is doubly stochastic, $P$ is a permutation matrix, and $0 < \lambda < 1$ such that every entry of $B = A - \lambda P$ is non-negative, then every row sum and column sum of $B$ is equal to $1-\lambda$.
				So, if we can find such $\lambda$ and $P$ with $\lambda$ chosen `maximally' (in the sense that if we increase it any more, some entry will become negative), we can ensure that $B$ has more zero elements than $A$. This then allows us to induct on the number of non-zero entries in $A$.\\
				The base case is when $A$ has exactly $n$ non-zero entries and in this case, $A$ is equal to a permutation matrix (Why?). \\
				Given the earlier claim about the existence of $\lambda$ and $P$, the result follows-near directly on applying the inductive hypothesis to $(1/(1-\lambda)) B$.\\
				To prove the claim, consider the bipartite graph $G= (X,Y,E)$ with $X$ and $Y$ being the rows and columns of $B$ respectively, and $xy\in E(G)$ iff $B_{xy} > 0$. If the graph has a perfect matching, then there exist $\lambda,P$ of the required form -- set $P$ as the permutation matrix that has $1$s at the edges corresponding to the matching, and let $\lambda$ be equal to
				\[ \min\{ b_{xy} : xy \text{ is an edge in the matching} \}. \]
				To show that the graph admits a perfect matching, we check Hall's condition. For all $S\subseteq X$, we want to show that $|N(S)| \ge |S|$. Now, by definition, the submatrix corresponding to the rows indexed by $S$ and columns indexed by $Y\setminus S$ is then the zero submatrix. Using the row sum condition,
				\[ \sum_{\substack{x\in S \\ y \in N(s )}} b_{xy} = \alpha |S|. \]
				Since $B$ is non-negative, this sum is at most
				\[ \sum_{\substack{x\in X \\ y\in N(S)}} b_{xy} = \alpha |N(S)| \]
				by the column sum condition. The claim follows.
			\end{proof}

			Now, let us look for a moment at matchings in graphs in general (that need not be bipartite).

			\begin{ftheo}
				A matching $\mathcal{M}$ in a graph $G$ is maximum iff it admits no $\mathcal{M}$-augmenting path.
			\end{ftheo}
			\begin{proof}
				The proof we gave earlier to show that admitting a $\mathcal{M}$-augmenting implies non-maximality works out even in the non-bipartite scenario.\\
				For the converse, suppose that $\mathcal{M}$ is a matching that admits no $\mathcal{M}$-augmenting path, and that $\mathcal{N}$ is a matching with $|\mathcal{N}| > |\mathcal{M}|$. Consider the subgraph $H$ of $G$ that retains only those edges in $\mathcal{M}$ or $\mathcal{N}$, but not both. Note that for any vertex of $G$, $d_H(v) \le 2$.\\
				It is not too difficult to show that $H$ is a disjoint union of cycles and paths. Since the $\mathcal{M}$ edges and $\mathcal{N}$ edges are individually pairwise disjoint, there cannot be an odd cycle in $H$. Since $\mathcal{N} > \mathcal{M}$, there must be a path that contains more $\mathcal{N}$ edges than $\mathcal{M}$ edges, and this is just an augmenting path(!), thus completing the proof.
			\end{proof}

			The above proposition allows us to find maximum matchings using a polynomial time algorithm.\\
			We give such an algorithm in the bipartite scenario.

			\begin{fdef}
				A \textbf{directed graph} is a pair $D=(V,E)$, where $V$ is the vertex set of $D$, and $E\subseteq V\times V$ is the set of \emph{directed edges} or \emph{arcs}. An edge $e = (u,v)$ is said to be directed from $u$ to $v$.
			\end{fdef}

			We often abuse notation and denote an edge $(u,v)$ by $\vv{uv}$ or $uv$.\\
			A \textbf{loop} is an edge of the form $(v,v)$.\\
			We can define several things here similar to in ordinary simple graphs. For example, a \emph{directed path} is a sequence $v_1,\ldots,v_n$ of vertices such that $(v_i, v_{i+1})$ is an edge for all valid $i$.

			\begin{ftheo}
				Suppose $G = (X,Y,E)$ is bipartite with $|X| \le |Y|$. There exists a polynomial time algorithm to find a maximum matching in $G$.
			\end{ftheo}
			\begin{proof}
				The idea of the proof is to construct augmenting paths. Given an augmenting path $P$ for a matching $\mathcal{M}$, $\mathcal{M}\triangle P$ is a matching with strictly more edges. If we begin with an arbitrary matching and perform this operation repeatedly, we must terminate within $|X|/2$ iterations.\\
				Let $\mathcal{M}$ be a matching. Our objective is to either produce an augmenting path, or show that there exists no $\mathcal{M}$-augmenting path. Let $X_\mathcal{M}$ and $Y_\mathcal{M}$ be the vertices in $X$ and $Y$ respectively saturated by $\mathcal{M}$, and let $X_U = X \setminus X_\mathcal{M}$ and $Y_U = Y \setminus Y_\mathcal{M}$. Notice that an augmenting path (if it exists) is uniquely determined by its sequence in $X_\mathcal{M}$ (since the edges from $X_\mathcal{M}$ to $Y_\mathcal{M}$ are fixed).\\
				Now, define the directed graph $D_\mathcal{M} = (X,\mathcal{E})$ with $(x_1, x_2) \in \mathcal{E}$ iff there exists $y \in Y_\mathcal{M}$ such that $x_2y_2\in\mathcal{M}$ and $x_1y_2\in E(G)$.\\
				Let $X^* = N(Y_U)$. Observe that $G$ has a $\mathcal{M}$-augmenting path iff $D_\mathcal{M}$ has a path from $X_U$ to $X^*$. This is easily resolved by just finding the set of vertices `reachable' from $X_U$ in $D_\mathcal{M}$. This is possible to do efficiently using the \emph{breadth-first-search} (BFS) algorithm, which we shall detail next.
			\end{proof}


			% Let $D = (V,\mathcal{E})$ be a directed graph. For a vertex $u$, let us call $v$ an \emph{out-neighbour} of $u$ if $(u,v)\in\mathcal{E}$, and an \emph{in-neighbour} of $u$ if $(v,u)\in\mathcal{E}$.\\
			The BFS algorithm is as follows.

			\begin{algorithm}[H]
				\DontPrintSemicolon
				\SetNoFillComment		
				\KwIn{A directed graph $D = (V,E)$ and a set $X \subseteq V$.}
				\KwOut{The set of vertices in $D$ reachable from $X$}
				$S\gets X$\;
				$\mathsf{Queue}\; q \gets X$ \tcp*{in any arbitrary order}
				\While{$q\ne\emptyset$} {
					$v \gets \texttt{pop}(q)$\;
					\For{$u\in N(v)$}{
						\If{$u\not\in S$} {
							$S \gets S \cup \{u\}$\;
							$\texttt{push}(q,u)$
						}
					}
				}
				\Return{$S$}
				\caption{BFS algorithm}\label{algo: bfs}
			\end{algorithm}

			If $X = \{v\}$, then this algorithm in fact finds a shortest path from $v$ to every reachable vertex from it. The correctness of the algorithm follows by a simple induction on the distance from $v$ to $u$.\\

			It is not too difficult to see that the BFS algorithm runs in $O(|V|+|E|)$, where $m$ is the number of edges in the graph, since each edge is checked at most twice. So, BFS runs linearly in the input size.

	\subsection{Flow}

		\subsubsection{Flows and Cuts}

			\begin{fdef}[Network]
				A \textbf{network} is a tuple $(D,s,t,C)$, such that
				\begin{itemize}
					\item $D$ is a directed graph,
					\item $s$ and $t$ are (distinct) specified vertices known as the \textbf{source} and \textbf{sink} respectively, and
					\item $C : E(D) \to \R_{\ge 0}$ is known as the \textbf{capacity function}.
				\end{itemize}
			\end{fdef}

			Given an edge $e$, $C(e)$ is referred to as the capacity of the edge $e$.\\

			This has a very simple-to-understand physical meaning. We can think of $s$ as a source of water and $t$ as a reservoir, with the intermediate edges being pipes that have a limit on how much they can carry and the intermediate nodes being junctions that transmit water. The main question we wish to answer then is: what is the maximum rate of water flow that can be sent from the source to the sink without violating any capacity constraints?\\
			More concretely,

			\begin{fdef}[Flow]
				Given a network $\mathcal{N} = (D,s,t,C)$, a \textbf{flow} is a function $f: E(D) \to \R_{\ge 0}$ such that
				\begin{itemize}
					\item For all $e\in E(D)$, $f(e) \le C(e)$,
					\item For every $v \ne s,t$,
					\[ \sum_{v \in V : uv \in E} f(uv) = \sum_{u \in V : vu \in E} f(vu). \]
					This is known as \textbf{Kirchhoff's Law}.
				\end{itemize}

				Given a flow $f$, we define the value $\Val(f)$ of the flow by
				\[ \Val(f) = \sum_{u \in V : su \in E} f(su) - \sum_{u \in V : us \in E} f(us). \]
			\end{fdef}

			Given $A,B\subseteq V$, denote
			\[ f(A,B) = \sum_{\substack{e = uv \in E \\ u \in A, v \in B }} f(e) - \sum_{\substack{e = vu \in E \\ u \in A, v \in B }} f(e). \]

			\begin{fdef}[Cut]
				Given a network $(D,s,t,C)$, a \textbf{cut} is the ordered pair $(S,\overline{S})$ for some $S \subseteq V$ with $s\in S$ and $t\not\in S$. We further define the \textbf{capacity} of this cut by
				\[ C(S,\overline{S}) = \sum_{\substack{e = uv \in E \\ u \in S, v \in \overline{S}}} f(e). \]
			\end{fdef}

			Since Kirchhoff's law is satisfied, we get the following.

			\begin{ftheo}
				For all $S \subseteq V$ such that $s \in S$ and $t\not\in S$,
				\[ \Val(f) = f(S,\overline{S}). \]
			\end{ftheo}
			Note that the claim follows by definition for $S = \{s\}$.
			\begin{proof}
				For $v\in V$ and $e\in E$, let
				\[
					\phi(v,e) =
					\begin{cases}
						1, & e = vu \text{ for some $u\in V$}, \\
						-1, & e = uv \text{ for some $u\in V$}, \\
						0, & e\text{ is not incident on }v. \\
					\end{cases}
				\]
				Note that Kirchhoff's law then just says that for any $v\in V\setminus\{s,t\}$,
				\[ \sum_{e\in E} \phi(v,e) f(e) = 0. \]
				Denote by $E(S,\overline{S})$ the set of all edges between $S$ and $\overline{S}$ (in either direction).\\
				We have
				\begin{align*}
					f(S,\overline{S}) &= \sum_{\substack{e = uv \in E \\ u \in S, v \in \overline{S}}} f(e) - \sum_{\substack{e = vu \in E \\ u \in S, v \in \overline{S}}} f(e) \\
						&= \sum_{e \in E(S,\overline{S})} \sum_{v \in S} f(e) \phi(v,e) \\
						&= \sum_{v\in S} \sum_{e \in E(S,\overline{S})} f(e) \phi(v,e) \\
						&= \sum_{v\in S} \sum_{e \in E} f(e) \phi(v,e) - sum_{v \in S} \sum_{\substack{e \in E(S,S): \\ \phi(v,e) = 1}} f(e) + sum_{v \in S} \sum_{\substack{e \in E(S,S): \\ \phi(v,e) = -1}} f(e) \\
						&= \sum_{v\in S} \sum_{e\in E} f(e) \phi(v,e),
				\end{align*}
				where the last step follows since for any edge $uv$ in $E(S,S)$, $\phi(u,e) = 1$, $\phi(v,e) = -1$, and $\phi(w,e) = 0$ for all other vertices $w$.\\
				By Kirchhoff's law,
				\[ \sum_{v\in S} \sum_{e \in E} f(e) \phi(v,e) = \sum_{e \in E} f(e) \phi(s,e) = \Val(f), \]
				completing the proof.
			\end{proof}

			\begin{corollary}
				For a flow $f$,
				\[ \Val(f) = \sum_{u \in V : ut \in E} f(ut) - \sum_{u \in V : tu \in E} f(tu). \]
			\end{corollary}

			The above is sometimes taken as an alternate definition for the value of a flow.

		\subsubsection{The Max-Flow Min-Cut Theorem}

			\begin{fcor}
				For a network $\mathcal{N}$, a flow $f$, and any cut $(S,\overline{S})$,
				\[ \Val(f) \le C(S,\overline{S}). \]
			\end{fcor}

			Observe that for any network $\mathcal{N}$, there exists at least one flow (namely the zero flow), and the flow value is bounded above.

			\begin{definition}
				Given a network $\mathcal{N}$, a \textbf{maximum flow} is a flow such that $\Val(f)$ is the maximum among all possible flows.
			\end{definition}

			\begin{theorem}
				Any network $\mathcal{N}$ on a finite directed graph has a maximum flow.
			\end{theorem}
			\begin{proof}
				It is clear that
				\[ \sup\{\Val(f) : f \text{ is a flow on }\mathcal{N}\} \]
				is well-defined and finite since for any flow $f$
				\begin{equation}
					\label{min-cut ge max-flow}
					\Val(f) \le \min_{(S,\overline{S}) \text{ is a cut}} C(S,\overline{S}).
				\end{equation}
				It is easy to show that the supremum is attained by a flow by considering a sequence of flows that converge (in value) to the supremum flow value, considering an appropriate subsequence such that the flow in each edge converges (this is possible since the set $[0,C(e)]$ is compact for each edge $e$, so we can apply the Bolzano-Weierstrass Theorem), and considering the flow whose value in each edge is equal to the limit of the sequence of flow values in this edge. Since the capacity constraint is a weak one and not strong, this is indeed a flow that satisfies the capacity constraints.
			\end{proof}

			It in fact turns out that the bound in \eqref{min-cut ge max-flow} is attained!

			\begin{ftheo}[Ford-Fulkerson Theorem]
				For a network $\mathcal{N} = (D,s,t,C)$ (where $D$ is finite),
				\[ \max_{\substack{f\text{ is a flow} \\ \text{on }\mathcal{N}}} \Val(f) = \min_{(S,\overline{S}) \text{ is a cut}} C(S,\overline{S}). \]
			\end{ftheo}
			The above is also referred to as the \emph{max-flow min-cut} theorem.
			\begin{proof}
				\eqref{min-cut ge max-flow} shows that the term on the right is at least the quantity on the right. Therefore, it suffices to show that if $f$ is a max-flow, there exists a cut $(S,\overline{S})$ such that $\Val(f) = C(S,\overline{S})$.\\
				Now, suppose there is a sequence $s = v_0 v_1 v_2 \cdots v_k v_{k+1} = t$ of vertices such that
				\begin{itemize}
					\item for each $i$, $v_i v_{i+1} \in E$ or $v_{i+1} v_i \in E$. In the former case, we call it a \emph{forward edge} and in the latter, a \emph{backward edge}.
					\item if $v_i v_{i+1}$ is a forward edge, then $f(v_iv_{i+1}) < C(v_i, v_{i+1})$.
					\item if $v_{i+1} v_i$ is a backward edge, then $f(v_{i+1},v_i) > 0$.
				\end{itemize}
				We call such a sequence an \textbf{$f$-augmenting path}.\\
				Suppose for a moment that such a path exists. Then, let
				\[ \delta = \min \left(\{ c(e) - f(e) : e \text{ is a forward edge in $P$} \} \cup \{ f(e) : e \text{ is a backward edge in $P$} \}\right) \]
				By definition, $\delta > 0$. Define a new function $f' : E \to \R$ by
				\[
					f'(e) =
					\begin{cases}
						f(e), & e \not\in P, \\
						f(e) + \delta, & e \in P\text{ is a forward edge}, \\
						f(e) - \delta, & e \in P\text{ is a forward edge}. \\
					\end{cases}
				\]
				It is not too difficult to check that $f'$ is a flow as well. Further,
				\[ \Val(f') = \Val(f) + \delta > \Val(f). \]
				Therefore, if $f$ is a maximum flow, there is no $f$-augmenting path.\\
				Now, let $f$ be a maximum flow. For each vertex $v$, we say that a path from $s$ to $v$ is $f$-augmenting if the earlier definition holds, except that the final vertex is $v$ instead of $t$.\\
				Let
				\[ S = \{ v: \text{ there is an $f$-augmenting path from $s$ to $v$} \}. \]
				Clearly, $s\in S$. Since $f$ is a maximal flow, $t\not\in S$. Therefore, $(S,\overline{S})$ is a cut.\\
				Suppose $e = uv$ is an edge with $u \in S$ and $v \not\in S$. If $f(e) < c(e)$, then $v\in S$ as well due to the existence of a path $s u_1 \cdots u_k u v$ (since $u$ is $f$-augmenting), leading to a contradiction. So, $f(e) = c(e)$.\\
				On the other hand, if $e = vu$ is an edge with $u \in S$ and $v \not\in S$ and $f(e) > 0$, $v \in S$, again leading to a contradiction. So, $f(e) = 0$.\\
				However, we then have
				\[ \Val(f) = f(S,\overline{S}) = C(S,\overline{S}), \]
				completing the proof.
			\end{proof}

			The above proof is easily modified to an algorithm in the case where $C$ is integral.

			\begin{fcor}
				\label{integral network integral maxflow}
				Suppose $\mathcal{N}$ is an integral network. That is, $C(e) \in \N_0$ for all $e \in E(D)$. Then, there is an integral maximum flow $f$ on $\mathcal{N}$ (a flow which has maximum value and only takes integral values).
			\end{fcor}
			\begin{proof}
				Begin with the zero flow $f_0$. Given $f_k$, choose an $f_k$-augmenting path, and increase the value of the flow by $\delta$ to get $f_{k+1}$. If there exists no $f_k$-augmenting path, then we must have attained the maximum flow possible since we must have saturated some cut. Further, due to the integral nature of the network and the flow at each step, $\delta$ is a positive integer, so this process terminates after a finite number of time steps.
			\end{proof}

		\subsubsection{Applications}
		\label{subsubsec: applications of max-flow}

			Here, we give two applications of flow.\\

			Consider a bipartite graph $G = (X,Y,E)$. Define the network $\mathcal{N} = (D,s,t,C)$ as follows:
			\begin{itemize}
				\item $s$ and $t$ are `new' vertices (not in $X\cup Y$),
				\item $D = (X\cup Y, E_D)$, where
				\[ E_D = \underbrace{\{\vv{uv} : uv \in E\}}_{E_1} \cup \underbrace{\{ \vv{su} : u \in X \}}_{E_2} \cup \underbrace{\{ \vv{vt} : v \in Y \}}_{E_3}, \]
				\item the capacity function is defined by
				\begin{align*}
					C(e) &=
					\begin{cases}
						1, & e \in E_1 \\
						\infty, & \text{otherwise}.
					\end{cases}
				\end{align*}
				If $\infty$ is problematic to think about, we can just choose a quantity that is greater than $C(X,Y)$ (no flow can have value greater than this anyway).
			\end{itemize}
			If there is a matching $\mathcal{M}$ of size $m$ on $G$, then there is a flow $f_\mathcal{M}$ of value $m$ that is $1$ on all edges in $\mathcal{M}$, and the flow in each edge of $E_2 \cup E_3$ is chosen such that Kirchhoff's law is satisfied.\\
			Conversely, if $f$ is a maximum integral flow of value $m$, we can get a matching $\mathcal{M}$ with $m$ edges by considering exactly those edges in $E_1$ that have flow $1$ in them.\\
			Therefore, to find a maximum matching on a bipartite graph, we may merely find a maximum flow in the corresponding network $\mathcal{N}$.\\

			For the second application, we give a result of Schrijver's.\\
			Suppose $A$ is a $m\times n$ $\{0,1\}$-matrix that has $k$ $1$s in each row and $r$ $1$s in each column (this implies that $mk=nr$). Suppose $\alpha \in (0,1) \cap \Q$ such that $\alpha k = k'$ and $\alpha r = r'$ are integers.\\
			Then, one can change some of the $1$s in $A$ to $0$s such that in the resulting array $A'$, there are $k'$ $1$s in each row and $r'$ $1$s in each column.\\
			To prove this, assign a bipartite graph $G = (X,Y,E)$ to $A$ as follows. $X$ is the rows of $A$, $Y$ is the columns of $A$, and $xy\in E(G)$ (with $x\in X$, $y\in Y$) iff $A_{xy} = 1$. We have that $d(x) = k$ and $d(y) = r$ for all $x\in X$, $y\in Y$.\\
			Craft a network $\mathcal{N}$ using $G$ exactly as we did above in the first application, with
			\[
				C(e) = 
				\begin{cases}
					1, & e = xy\text{ for }x\in X, y\in Y, \\
					k, & e = sx\text{ for }x\in X, \\
					r, & e = yt\text{ for }y\in Y.
				\end{cases}
			\]
			Clearly, the flow $f$ that saturates the capacity of every single edge is a maximum flow. Consider another capacity function $C'$ by
			\[
				C'(e) = 
				\begin{cases}
					1, & e = xy\text{ for }x\in X, y\in Y, \\
					k', & e = sx\text{ for }x\in X, \\
					r', & e = yt\text{ for }y\in Y.
				\end{cases}	
			\]
			Note that $f' = \alpha f$ is a maximum flow in $\mathcal{N}' = (D,s,t,C')$. Since $\mathcal{N}'$ is integral, there is an integral max flow $f''$ in it. Note that for each $e$ of the form $sx$, $f'(e) = k' = C'(e)$, so we must have $f''(e) = k'$ as well. Similarly, $f''(e) = r'$ for every edge of the form $yt$. Changing a $1$ in $A$ to a $0$ iff $f''(e) = 0$ gives the required.

		\subsubsection{Algorithms for finding max-flow}

			Now, how do we actually determine a max-flow?\\
			A basic idea comes from the proof of \Cref{integral network integral maxflow}.

			% We saw earlier that in an integral network, a max-flow can be determined in $O(C_{\text{max}}|E|)$, where $C_\text{max}$ is the value of the max-flow. However, this algorithm is quite inefficient. Is it possible to come up with a better algorithm?\\
			To do so, let us rephrase the definition of an augmenting path into terms closer to that of Dijkstra's algorithm.
			Given a network $\mathcal{N}=(D,s,t,C)$ and a flow $f$ on it, define the auxiliary \emph{residual} graph $D_f$ on the vertex set of $D$ such that $e = (u,v)\in E(D_f)$ iff
			\begin{itemize}
				\item $uv$ is an edge in $D$ and $c_f(e) = C(e) - f(e) > 0$ or
				\item $vu$ is an edge in $D$ and $c_f(e) = f(e) > 0$.
			\end{itemize}
			If we find a path in this residual graph, then we get an augmenting path to the flow $f$ (if one exists), and the corresponding value of $\delta$ by which we augment the flow is just equal to the maximum value of $c_f(e)$ along edges $e$ in this path.

			\begin{algorithm}[H]
				\DontPrintSemicolon
				\SetNoFillComment
				\SetKwProg{Fn}{}{}{}
				\For{$e\in E(G)$} {
					$f(e)\gets 0$
				}
				\While{there exists an $s$-$t$ path $P$ in $G_f$} {
					% $f'\gets\aug{$P,f$}$\;
					$c_f(P)\gets\min_{e \in P} c_f(e)$\;
					\ForEach{$e=uv\in P$} {
						\eIf{$e$ is a forward edge} {
							$f(uv)\gets f(uv) + c_f(P)$
						} {
							$f(vu) \gets f(vu) - c_f(P)$
						}
					}
				}
				\Return{$f$}\;
				\caption{Ford and Fulkerson's Algorithm}\label{algo: FF max flow}
			\end{algorithm}

			There are two important things to note:
			\begin{itemize}
				\item The choice of the path at each step affects how many augmentations we perform.\\
				To illustrate this, consider the graph on $\{s,u,v,t\}$ with edges $su,sv,uv,ut,vt$ and capacities $2^{10},2^{10},1,2^{10},2^{10}$ respectively. If we pick the augmenting paths $sut$ and $svt$ in the beginning, we immediately arrive at the max-flow value. However, if we pick the path from $s$ to $t$ containing $uv$ at each step, we take a very large amount of time ($2^{11}$ time steps) to converge since the flow only increases by $1$ each augmentation.

				\item In the case where capacities are irrational and we choose an arbitrary path at each step, we need not even converge to the max-flow value. If the capacities are integral (or rational), this process terminates as seen in the proof of \Cref{integral network integral maxflow}.
			\end{itemize}

			This algorithm (for an integral network) takes $O(F_\text{max}E)$, where $F_\text{max}$ is the value of a max-flow in the graph.\\

			Henceforth, we abuse notation and denote by $E$ (resp. $V$) the size of the set $E$ (resp. $V$).\\

			The first of the two points above leads to the \textbf{Edmonds-Karp algorithm}. It is nearly the same as the Ford and Fulkerson algorithm, except that at each step we choose the shortest path from $s$ to $t$ in $G_f$. \\
			Further, it resolves the second issue as well, with the algorithm working even in the irrational scenario.

			\begin{ftheo}
				The Edmonds-Karp algorithm for finding a max-flow runs in $O(VE^2)$.
			\end{ftheo}
			Note in particular that the runtime is independent of the value of the max-flow.
			\begin{proof}
				Since each augmentation takes $O(E)$ time, it suffices to show that the number of augmentations is $O(VE)$.\\
				First, we claim that the distance $\delta_f(s,v)$ between $s,v$ in the residual graph $G_f$ monotonically increases for all $v\in V$. That is, if $f'$ is obtained by augmenting $f$ using a shortest path in the residual graph, $\delta_f(s,v) \le \delta_{f'}(s,v)$.\\
				For now, suppose the claim is true. Suppose we have a flow $f$ and corresponding residual graph $G_f$. If $P$ is a shortest $s$-$t$ augmenting path, define the \emph{critical capacity} $c_f(P)$ of $P$ as in \Cref{algo: FF max flow}. Also call an edge $e$ \emph{critical} if $c_f(P) = c_f(e)$. We shall show that every edge $e = uv$ in $D$ becomes critical in an implementation of Edmonds-Karp at most $|V|/2$ times. This implies that there are at most $|E||V|/2$ augmentations, thus completing the proof.\\
				Suppose that in some augmentation, $e = uv$ is critical for the first time. Then, $\delta_f(s,v) = \delta_f(s,u) + 1$ since we are using a shortest path. Further, after the augmentation, the edge $uv$ disappears. To become critical again, it has to reappear, and this only happens after $vu$ appears in a subsequent augmenting path for a flow $f'$. But by our earlier claim,
				\[ \delta_{f'}(s,u) = \delta_{f'}(s,v) + 1 \ge \delta_f(s,v) + 1 = \delta_f(s,u) + 2, \]
				thus proving our second claim since $\delta_{f'}(s,u) \le |V|-1$, so any edge becomes critical at most $(|V|-1)/2$ times.\\

				It remains to prove our first claim. Suppose it is not true. Then, there is a first instance and a vertex $v$ such that $f$ is augmented to $f'$ but $\delta_{f'}(s,v) < \delta_{f}(s,v)$. Pick such a $v$ with minimal $\delta_{f'}(s,v)$.\\
				Let $P$ be a shortest path in $G_{f'}$ from $s$ to $v$, and let the penultimate vertex in it (before $v$) be $u$. Then, $\delta_{f'}(s,v) = \delta_{f'}(s,u) + 1$. By the choice of $v$, $\delta_{f'}(s,u) \ge \delta_{f}(s,u)$.\\
				Now, suppose that $uv \in E(G_f)$. Then,
				\[ \delta_f(s,v) \le \delta_f(s,u) + 1 \le \delta_{f'}(s,u) + 1 = \delta_{f'}(s,v), \]
				contradicting our assumption. Therefore, $uv \not\in E(G_f)$. However, $uv \in E(G_{f'})$. This implies that an $s$-$t$ augmenting path $P$ in $G_f$ includes the edge $vu$. Since Edmonds-Karp uses shortest paths, this implies that $\delta_f(s,u) = \delta_f(s,v) + 1$, so
				\[ \delta_f(s,v) = \delta_f(s,u) - 1 \le \delta_{f'}(s,u) - 1 = \delta_{f'}(s,v) - 2, \]
				contradicting our assumption once more and concluding the proof. 
			\end{proof}

			Next, we give a more recent result on finding perfect matchings in regular bipartite graphs. Let $G = (X,Y,E)$ be $d$-regular with $|V| = n = 2|X|$. \Cref{ftheo: regular bipartite graph has a perfect matching} says that $G$ has a perfect matching. The Edmonds-Karp algorithm together with the first application in \Cref{subsubsec: applications of max-flow} gives a $O(n^3 d)$ algorithm.\\
			We give a far more efficient \emph{randomized} algorithm due to \cite{Goel11perfectmatchings} with expected runtime $O(n\log n)$.\\
			First, what are randomized algorithms? They utilize sources of randomness, and either
			\begin{itemize}
				\item the output is a random variable (that need not always be correct),
				\item the output is definitely correct, but the runtime is a random variable,
			\end{itemize}
			or some combination of the two.\\
			The algorithm we describe is of the second variety.\\
			Create the corresponding network for $G$, adding source and sink vertices $s$ and $t$. Beginning with the $0$ flow, we find an augmenting path by performing the following on the residual graph. Beginning from vertex $s$, if we are at vertex $u$, then choose an arbitrary outneighbour $v$ of $u$ and move to it. This algorithm gives a flow of value $n$,\footnote{If any loops are formed during the creation of this augmenting path, delete them afterwards.} and thus a perfect matching in the graph, with expected runtime $O(n\log n)$.
			\begin{remark}
				The expected runtime for the algorithm is independent of the degree $d$ of the graph. While the \emph{expected} time is of the order of $O(n\log n)$, it is possible for the algorithm to take much longer to terminate. One way to deal with this is that if the algorithm does not terminate in, say, $\lceil10 n\log n\rceil$ steps, restart the algorithm.
			\end{remark}

			Now, let us give a proof of the runtime.

			\begin{proof}
				Suppose we have found a flow of value $k<n$. We shall determine the expected number of steps to reach a flow of size $k+1$.\\
				Suppose without loss of generality that our size $k$ matching $\mathcal{M}$ has edges from $X_\mathcal{M}$ to $Y_\mathcal{M}$, each of size $k$. Let $X_U = X \setminus X_\mathcal{M}$ and $Y_U = Y \setminus Y_\mathcal{M}$. \\
				Observe that the only edges from $Y$ to $X$ in the residual graph come from the $\mathcal{M}$-edges.\\
				Also note that the time to reach the size $k+1$ matching is just the length of the augmenting path (up to some multiplicative constant). Further, the length of an augmenting path is
				\[ \le 2 + 1 + 2 \times (\text{the number of backward edges in the walk}). \]
				Therefore, it suffices to bound the expected number of backward edges in a random walk from $s$ to $t$ in this residual graph.\\
				For each $v\in X_\mathcal{M} \cup Y_\mathcal{M}$, denote by $\mathcal{M}(v)$ the vertex in $X_\mathcal{M} \cup Y_\mathcal{M}$ that it has a $\mathcal{M}$-edge to.\\
				Denote by $b(v)$ the expected number of backward edges in a random walk starting at some $v$ and terminating at $t$. We wish to determine $b(s)$. \\
				We have
				\[ b(s) = \frac{1}{n-k} \sum_{x\in X_U} b(x). \]
				For each $x\in X_U$,
				\[ b(x) = \frac{1}{d} \sum_{y \in N(x)} b(y). \]
				For each $y\in Y_U$, $b(y) = 0$ and for each $y\in Y_\mathcal{M}$,
				\[ b(y) = 1 + b(\mathcal{M}(y)). \]
				Finally, for $x\in X_\mathcal{M}$,
				\[ b(x) = \frac{1}{d-1} \sum_{y: xy \in E \setminus \mathcal{M}} b(y). \]
				So, if $x \in X_\mathcal{M}$,
				\begin{align*}
					d \cdot b(x) &= \sum_{y: xy \in E \setminus \mathcal{M}} b(y) + b(x) \\
						&= \left(\sum_{y: xy \in E \setminus \mathcal{M}} b(y)\right) + b(\mathcal{M}(x)) - 1 \\
						&= \left(\sum_{y: xy \in E} b(y)\right) - 1
				\end{align*}
				and if $x \in X_U$,
				\[ d \cdot b(x) = \sum_{xy \in E} b(y) \]
				Summing over all $x \in X$,
				\begin{align*}
					d \sum_{x \in X} b(x) &= \sum_{xy \in E} b(y) - |X_\mathcal{M}| \\
						&= \sum_{xy \in E} b(y) - k \\
						&= d \sum_{y \in Y} b(y) - k \\
						&= d \sum_{y \in Y_\mathcal{M}} b(y) - k \\
						&= \left(d \sum_{y \in Y_\mathcal{M}} (1 + b(\mathcal{M}(y)))\right) - k \\
						&= (d-1)k + d \sum_{x \in X_\mathcal{M}} b(x) \\
					d \sum_{x \in X_U} b(x) &= (d-1)k.
				\end{align*}
				Therefore,
				\[ b(s) = \frac{1}{n-k} \sum_{x \in X_U} b(x) = \frac{k(d-1)}{d(n-k)} < \frac{n}{n-k} - 1 \]
				and expected runtime of the algorithm is
				\[ O\left(\sum_{k=0}^{n-1} \left( \frac{n}{n-k} - 1 \right)\right) = O(n\log n). \qedhere \]
			\end{proof}

		\subsubsection{Baranyai's Theorem and Menger's Theorem}

			In this section, we give another application of flow due to Zsolt Baranyai. The problem is as follows.

			\begin{quote}
				Suppose $n > k \ge 2$ are integers. Can we partition $\binom{[n]}{k}$ into subcollections $\mathcal{A}_1,\ldots,\mathcal{A}_M$ such that each of the sets within each $A_i$ is itself a partition of $[n]$. 
			\end{quote}

			For example, consider the scenario where $k=2$. If $n$ is odd, the above is clearly impossible. So, let $n = 2m$. The problem is then essentially equivalent to partitioning $E(K_{2m})$ into perfect matchings. This isn't too hard to do, and answers the problem affirmatively in this case.\\
			Note that in genereal, we must have $k\mid n$.

			\begin{ftheo}[Baranyai's Theorem]
				If $k\mid n$, there exists a partition of $\binom{[n]}{k}$ into subfamilies $\mathcal{A}_1, \ldots, \mathcal{A}_M$ with $|\mathcal{A}_i| = m$, and the sets of each $\mathcal{A}_i$ partition $[n]$.
			\end{ftheo}
			Above, we have
			\[ M = \frac{binom{n}{k}}{n/k} = \binom{n-1}{k-1} \text{ and } m = \frac{n}{k}. \]
			\begin{proof}
				We prove this by induction. Suppose we have families $\mathcal{A}_1,\mathcal{A}_M$, each of size $m$ satisfying the required.\\
				Suppose that $n$ is deleted from every set that it appears in. It is easy to retrieve the original $\{\mathcal{A}_i\}$ since exactly one set from each $\mathcal{A}_i$ has size $k-1$ now, namely that from which $n$ was deleted.\\
				Now, suppose that both $n$ and $n-1$ are deleted from every set they appear in. Now, it is slightly more non-trivial. How would we retrieve $\mathcal{A}_i$ (or another valid solution)? 
				\begin{itemize}
					\item Any set from the $\mathcal{A}_i$ of size $k-2$ gets both $n-1$ and $n$.
					\item Each set of size $k-1$ gets either $n$ or $n-1$. The question is: which of the size $k-1$ sets do we assign $n$, $n-1$ to? Note that each set of size $k-1$ appears exactly twice on scanning across all the $\mathcal{A}_i$. So, we just assign $n$ to one of these two subsets and $n-1$ to the other. Why is this a valid solution?
				\end{itemize}
				Suppose now that we delete all occurrences of $\ell+1,\ell+2,\ldots,n$ for some $\ell$. The resulting tampered collection is such that
				\begin{enumerate}
					\item $|\mathcal{A}_i| = M$.
					\item Each $\mathcal{A}_i$ consists of sets that constitute a partition of $[\ell]$.
					\item Each set in a $\mathcal{A}_i$ has size at most $k$, and there may be multiple instances of $\emptyset$.
				\end{enumerate}
				These tampered collections $\{\mathcal{A}_i\}$ are also such that for any $S \subseteq [\ell]$, $S$ appears $\binom{n-|S|}{k-\ell}$ times. We wish to choose a $B_i \in \mathcal{A}_i$ for each $i \in [M]$ as the set into which $\ell+1$ should be added, and the above conditions are satisfied for the new collection $\{\mathcal{A}_i^*\}$ of sets, where $\mathcal{A}_i^* = \mathcal{A}_i \setminus \{B_i\} \cup \{B_i \cup \{\ell+1\}\}$. That is, each susbet $T \subseteq [\ell+1]$ appears exactly $\binom{n-\ell-1}{k-|T|}$ times across the sets of $\{\mathcal{A}_i^*\}$. \\
				We can then apply the inductive hypothesis to build up to the original collection of partitions of $[n]$. If we are able to do this, then since the hypothesis is satisfied for the case where $\ell=0$ (so $\mathcal{A}_i$ just has $m$ copies of $\emptyset$), the proof is complete.\\
				This is where graph theory enters the picture. Consider the bipartite graph $(X,Y,E)$, where
				\[ X = \{\mathcal{A}_i\}_{i=1}^M, Y = \{ S \in 2^{[\ell]} : |S| \le k \}, \]
				and $\mathcal{A}_i$ is adjacent to $S\subseteq[\ell]$ if $S \in \mathcal{A}_i$.\\
				Note that the degree of any set $S$ is equal to $\binom{n-\ell}{k-|S|}$.
				The idea of choosing one set for each $\mathcal{A}_i$ lends itself to a flow analogue. Put in a source $s$ and sink $t$, similar to what we've done in the past, and get a directed graph $G$. To get a network $\mathcal{N}$, for any $\mathcal{A}_i\in X$ and $S \in Y$, we set the capacity as
				\[ C(s,\mathcal{A}_i) = 1 \text{ and } C(\mathcal{A}_i, S) = 1. \]
				If we have $T = S \cup \{\ell+1\}$, we want $T$ to appear $\binom{n-\ell-1}{k-|S|-1}$ times. So, we set
				\[ C(S,t) = \binom{n-\ell-1}{k-|S|-1} = \frac{k-|S|}{n-\ell} \binom{n-\ell}{k-|S|}. \]
				Consider the following flow $f$. Set $f(S,\mathcal{A}_i) = 1$ for each $i$, $f(S,t) = C(S,t)$ for each $S$, and to make it a flow,
				\[ f(\mathcal{A}_i, S) = \frac{k-|S|}{n-\ell}. \]
				It is clear Kirchhoff's law is satisfied at the subsets $S$, and at the $\mathcal{A}_i$, we have
				\begin{align*}
					 \sum_S f(\mathcal{A}_i, S) &= \frac{k}{n-\ell} \cdot \frac{n}{k} - \frac{1}{n-\ell} \sum_{S \in \mathcal{A}_i} |S| \\
					 	&= \frac{n}{n-\ell} - \frac{\ell}{n-\ell} = 1. (\text{since $\mathcal{A}_i$ forms a partition})
				\end{align*}
				Further, this is a max-flow! By \Cref{integral network integral maxflow}, there must exist an integral max-flow $g$ on this graph, such that $g(s,\mathcal{A}_i) = 1$, $g(S,t) = \binom{n-\ell-1}{k-|S|-1}$, and $g(\mathcal{A}_i, S) \in \{0,1\}$.\\
				If for each $\mathcal{A}_i,S$ such that $g(\mathcal{A}_i, S) = 1$, we add in $\ell+1$.\\
				To conclude, we need to verify that for each $T \subseteq [\ell+1]$, $T$ appears exactly $\binom{n-\ell-1}{k-|T|}$. If $\ell+1 \in T$, then this follows by design. Otherwise, $T$ appeared $\binom{n-\ell}{k-|T|}$ times originally. Since $\binom{n-\ell-1}{k-|T|-1}$ of these copies were altered to include $\ell+1$, the number of copies of $T$ is now exactly
				\[ \binom{n-\ell}{k-|T|} - \binom{n-\ell-1}{k-|T|-1} = \binom{n-\ell-1}{k-|T|}, \]
				completing the proof.
			\end{proof}

			To conclude the topic of flows, we discuss a result regarding connectivity.

			\begin{ftheo}
				A graph $G$ is said to be \textbf{$k$-connected} if on the deletion of any $<k$ vertices from $G$, and any vertices $u$, $v$, there exists a path from $u$ to $v$ in the remaining graph.
				A $1$-connected graph is said to be \textbf{connected}. \\
				The \textbf{connectivity} $\kappa(G)$ of $G$ is the largest integer $r$ such that $G$ is $r$-connected.
			\end{ftheo}